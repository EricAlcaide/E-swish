{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\nImportError: DLL load failed: El archivo de paginación es demasiado pequeño para completar la operación.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n    return importlib.import_module('_pywrap_tensorflow_internal')\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nImportError: No module named '_pywrap_tensorflow_internal'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[1;34m(self, spec)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: El archivo de paginación es demasiado pequeño para completar la operación.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named '_pywrap_tensorflow_internal'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ca36e9591232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown backend: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 72\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\nImportError: DLL load failed: El archivo de paginación es demasiado pequeño para completar la operación.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\n    return importlib.import_module('_pywrap_tensorflow_internal')\n  File \"c:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nImportError: No module named '_pywrap_tensorflow_internal'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "\"\"\" Initial Notebook to demonstrate the power \n",
    "    of the Cutout technique.\n",
    "    Prev step for further implementation in \n",
    "    NASNet Architectures to try to achieve SOTA results\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Swish activation function\n",
    "# x*sigmoid(x)\n",
    "def swish(x):\n",
    "    return x*K.sigmoid(x)\n",
    "\n",
    "# Custom activation function 1\n",
    "# mix between relu and positive part of swish mirrored across x=1\n",
    "def e_swish_1(x):\n",
    "    return K.maximum(0.0, x*(2-K.sigmoid(x)))\n",
    "\n",
    "# Custom activation function 2\n",
    "# positive part of swish mirrored across x=1\n",
    "def e_swish_2(x):\n",
    "    return K.maximum(x*K.sigmoid(x), x*(2-K.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act, act_name = e_swish_2, \"e_swish_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "390/390 [==============================] - 181s - loss: 2.0026 - acc: 0.4027 - val_loss: 1.2514 - val_acc: 0.5859\n",
      "Epoch 2/75\n",
      "390/390 [==============================] - 176s - loss: 1.3454 - acc: 0.5611 - val_loss: 1.0567 - val_acc: 0.6536\n",
      "Epoch 3/75\n",
      "390/390 [==============================] - 176s - loss: 1.1593 - acc: 0.6284 - val_loss: 0.9671 - val_acc: 0.6908\n",
      "Epoch 4/75\n",
      "390/390 [==============================] - 178s - loss: 1.0554 - acc: 0.6648 - val_loss: 0.8845 - val_acc: 0.7268\n",
      "Epoch 5/75\n",
      "390/390 [==============================] - 177s - loss: 0.9784 - acc: 0.6909 - val_loss: 0.8051 - val_acc: 0.7498\n",
      "Epoch 6/75\n",
      "390/390 [==============================] - 176s - loss: 0.9357 - acc: 0.7096 - val_loss: 0.7286 - val_acc: 0.7776\n",
      "Epoch 7/75\n",
      "390/390 [==============================] - 175s - loss: 0.8916 - acc: 0.7245 - val_loss: 0.7278 - val_acc: 0.7797\n",
      "Epoch 8/75\n",
      "390/390 [==============================] - 175s - loss: 0.8553 - acc: 0.7363 - val_loss: 0.7305 - val_acc: 0.7808\n",
      "Epoch 9/75\n",
      "390/390 [==============================] - 175s - loss: 0.8259 - acc: 0.7454 - val_loss: 0.6805 - val_acc: 0.8026\n",
      "Epoch 10/75\n",
      "390/390 [==============================] - 175s - loss: 0.8002 - acc: 0.7569 - val_loss: 0.6698 - val_acc: 0.8034\n",
      "Epoch 11/75\n",
      "390/390 [==============================] - 175s - loss: 0.7795 - acc: 0.7634 - val_loss: 0.6501 - val_acc: 0.8101\n",
      "Epoch 12/75\n",
      "390/390 [==============================] - 175s - loss: 0.7680 - acc: 0.7664 - val_loss: 0.6479 - val_acc: 0.8058\n",
      "Epoch 13/75\n",
      "390/390 [==============================] - 175s - loss: 0.7439 - acc: 0.7770 - val_loss: 0.6228 - val_acc: 0.8222\n",
      "Epoch 14/75\n",
      "390/390 [==============================] - 175s - loss: 0.7346 - acc: 0.7790 - val_loss: 0.5980 - val_acc: 0.8262\n",
      "Epoch 15/75\n",
      "390/390 [==============================] - 175s - loss: 0.7231 - acc: 0.7860 - val_loss: 0.5857 - val_acc: 0.8333\n",
      "Epoch 16/75\n",
      "390/390 [==============================] - 175s - loss: 0.7137 - acc: 0.7889 - val_loss: 0.6158 - val_acc: 0.8248\n",
      "Epoch 17/75\n",
      "390/390 [==============================] - 175s - loss: 0.7018 - acc: 0.7944 - val_loss: 0.5952 - val_acc: 0.8376\n",
      "Epoch 18/75\n",
      "390/390 [==============================] - 175s - loss: 0.6929 - acc: 0.7967 - val_loss: 0.6133 - val_acc: 0.8276\n",
      "Epoch 19/75\n",
      "390/390 [==============================] - 174s - loss: 0.6915 - acc: 0.7971 - val_loss: 0.5704 - val_acc: 0.8420\n",
      "Epoch 20/75\n",
      "390/390 [==============================] - 174s - loss: 0.6782 - acc: 0.8020 - val_loss: 0.5694 - val_acc: 0.8450\n",
      "Epoch 21/75\n",
      "390/390 [==============================] - 174s - loss: 0.6705 - acc: 0.8065 - val_loss: 0.6108 - val_acc: 0.8332\n",
      "Epoch 22/75\n",
      "390/390 [==============================] - 174s - loss: 0.6708 - acc: 0.8084 - val_loss: 0.5858 - val_acc: 0.8391\n",
      "Epoch 23/75\n",
      "390/390 [==============================] - 174s - loss: 0.6621 - acc: 0.8108 - val_loss: 0.5530 - val_acc: 0.8515\n",
      "Epoch 24/75\n",
      "390/390 [==============================] - 174s - loss: 0.6575 - acc: 0.8131 - val_loss: 0.5471 - val_acc: 0.8542\n",
      "Epoch 25/75\n",
      "390/390 [==============================] - 174s - loss: 0.6508 - acc: 0.8153 - val_loss: 0.5337 - val_acc: 0.8594\n",
      "Epoch 26/75\n",
      "390/390 [==============================] - 174s - loss: 0.6496 - acc: 0.8160 - val_loss: 0.5482 - val_acc: 0.8561\n",
      "Epoch 27/75\n",
      "390/390 [==============================] - 174s - loss: 0.6401 - acc: 0.8199 - val_loss: 0.5375 - val_acc: 0.8544\n",
      "Epoch 28/75\n",
      "390/390 [==============================] - 174s - loss: 0.6385 - acc: 0.8222 - val_loss: 0.5427 - val_acc: 0.8569\n",
      "Epoch 29/75\n",
      "390/390 [==============================] - 174s - loss: 0.6351 - acc: 0.8193 - val_loss: 0.5337 - val_acc: 0.8555\n",
      "Epoch 30/75\n",
      "390/390 [==============================] - 174s - loss: 0.6339 - acc: 0.8227 - val_loss: 0.5301 - val_acc: 0.8597\n",
      "Epoch 31/75\n",
      "390/390 [==============================] - 174s - loss: 0.6292 - acc: 0.8227 - val_loss: 0.5236 - val_acc: 0.8700\n",
      "Epoch 32/75\n",
      "390/390 [==============================] - 174s - loss: 0.6279 - acc: 0.8251 - val_loss: 0.5379 - val_acc: 0.8575\n",
      "Epoch 33/75\n",
      "390/390 [==============================] - 174s - loss: 0.6178 - acc: 0.8283 - val_loss: 0.5410 - val_acc: 0.8590\n",
      "Epoch 34/75\n",
      "390/390 [==============================] - 174s - loss: 0.6147 - acc: 0.8301 - val_loss: 0.5238 - val_acc: 0.8668\n",
      "Epoch 35/75\n",
      "390/390 [==============================] - 174s - loss: 0.6129 - acc: 0.8309 - val_loss: 0.5171 - val_acc: 0.8693\n",
      "Epoch 36/75\n",
      "390/390 [==============================] - 174s - loss: 0.6112 - acc: 0.8316 - val_loss: 0.5050 - val_acc: 0.8689\n",
      "Epoch 37/75\n",
      "390/390 [==============================] - 174s - loss: 0.6071 - acc: 0.8343 - val_loss: 0.5090 - val_acc: 0.8688\n",
      "Epoch 38/75\n",
      "390/390 [==============================] - 174s - loss: 0.6114 - acc: 0.8322 - val_loss: 0.5226 - val_acc: 0.8670\n",
      "Epoch 39/75\n",
      "390/390 [==============================] - 174s - loss: 0.6013 - acc: 0.8347 - val_loss: 0.5109 - val_acc: 0.8696\n",
      "Epoch 40/75\n",
      "390/390 [==============================] - 174s - loss: 0.6038 - acc: 0.8339 - val_loss: 0.5137 - val_acc: 0.8707\n",
      "Epoch 41/75\n",
      "390/390 [==============================] - 174s - loss: 0.5956 - acc: 0.8390 - val_loss: 0.5003 - val_acc: 0.8738\n",
      "Epoch 42/75\n",
      "390/390 [==============================] - 174s - loss: 0.6023 - acc: 0.8368 - val_loss: 0.4990 - val_acc: 0.8754\n",
      "Epoch 43/75\n",
      "390/390 [==============================] - 174s - loss: 0.5882 - acc: 0.8416 - val_loss: 0.4988 - val_acc: 0.8718\n",
      "Epoch 44/75\n",
      "390/390 [==============================] - 174s - loss: 0.5931 - acc: 0.8387 - val_loss: 0.5043 - val_acc: 0.8721\n",
      "Epoch 45/75\n",
      "390/390 [==============================] - 174s - loss: 0.5890 - acc: 0.8398 - val_loss: 0.5194 - val_acc: 0.8717\n",
      "Epoch 46/75\n",
      "390/390 [==============================] - 174s - loss: 0.5894 - acc: 0.8402 - val_loss: 0.5017 - val_acc: 0.8741\n",
      "Epoch 47/75\n",
      "390/390 [==============================] - 174s - loss: 0.5875 - acc: 0.8428 - val_loss: 0.5054 - val_acc: 0.8721\n",
      "Epoch 48/75\n",
      "390/390 [==============================] - 174s - loss: 0.5801 - acc: 0.8426 - val_loss: 0.5061 - val_acc: 0.8714\n",
      "Epoch 49/75\n",
      "390/390 [==============================] - 174s - loss: 0.5847 - acc: 0.8431 - val_loss: 0.4892 - val_acc: 0.8775\n",
      "Epoch 50/75\n",
      "390/390 [==============================] - 174s - loss: 0.5829 - acc: 0.8436 - val_loss: 0.5048 - val_acc: 0.8738\n",
      "Epoch 51/75\n",
      "390/390 [==============================] - 174s - loss: 0.5856 - acc: 0.8424 - val_loss: 0.4945 - val_acc: 0.8758\n",
      "Epoch 52/75\n",
      "390/390 [==============================] - 174s - loss: 0.5761 - acc: 0.8464 - val_loss: 0.5091 - val_acc: 0.8731\n",
      "Epoch 53/75\n",
      "390/390 [==============================] - 174s - loss: 0.5740 - acc: 0.8461 - val_loss: 0.4998 - val_acc: 0.8752\n",
      "Epoch 54/75\n",
      "390/390 [==============================] - 174s - loss: 0.5790 - acc: 0.8467 - val_loss: 0.4835 - val_acc: 0.8802\n",
      "Epoch 55/75\n",
      "390/390 [==============================] - 174s - loss: 0.5686 - acc: 0.8495 - val_loss: 0.4832 - val_acc: 0.8792\n",
      "Epoch 56/75\n",
      "390/390 [==============================] - 174s - loss: 0.5789 - acc: 0.8472 - val_loss: 0.5155 - val_acc: 0.8669\n",
      "Epoch 57/75\n",
      "390/390 [==============================] - 174s - loss: 0.5738 - acc: 0.8473 - val_loss: 0.4845 - val_acc: 0.8795\n",
      "Epoch 58/75\n",
      "390/390 [==============================] - 174s - loss: 0.5697 - acc: 0.8502 - val_loss: 0.4965 - val_acc: 0.8781\n",
      "Epoch 59/75\n",
      "390/390 [==============================] - 174s - loss: 0.5706 - acc: 0.8478 - val_loss: 0.4884 - val_acc: 0.8779\n",
      "Epoch 60/75\n",
      "390/390 [==============================] - 174s - loss: 0.5725 - acc: 0.8468 - val_loss: 0.4895 - val_acc: 0.8789\n",
      "Epoch 61/75\n",
      "390/390 [==============================] - 174s - loss: 0.5693 - acc: 0.8492 - val_loss: 0.4990 - val_acc: 0.8777\n",
      "Epoch 62/75\n",
      "390/390 [==============================] - 174s - loss: 0.5665 - acc: 0.8504 - val_loss: 0.4894 - val_acc: 0.8790\n",
      "Epoch 63/75\n",
      "390/390 [==============================] - 174s - loss: 0.5710 - acc: 0.8480 - val_loss: 0.4883 - val_acc: 0.8831\n",
      "Epoch 64/75\n",
      "390/390 [==============================] - 174s - loss: 0.5628 - acc: 0.8516 - val_loss: 0.4946 - val_acc: 0.8778\n",
      "Epoch 65/75\n",
      "390/390 [==============================] - 174s - loss: 0.5638 - acc: 0.8508 - val_loss: 0.4877 - val_acc: 0.8786\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 173s - loss: 0.5586 - acc: 0.8518 - val_loss: 0.4937 - val_acc: 0.8801\n",
      "Epoch 67/75\n",
      "390/390 [==============================] - 173s - loss: 0.5629 - acc: 0.8524 - val_loss: 0.4980 - val_acc: 0.8792\n",
      "Epoch 68/75\n",
      "390/390 [==============================] - 173s - loss: 0.5575 - acc: 0.8537 - val_loss: 0.4805 - val_acc: 0.8825\n",
      "Epoch 69/75\n",
      "390/390 [==============================] - 173s - loss: 0.5630 - acc: 0.8523 - val_loss: 0.5168 - val_acc: 0.8714\n",
      "Epoch 70/75\n",
      "390/390 [==============================] - 173s - loss: 0.5601 - acc: 0.8539 - val_loss: 0.5028 - val_acc: 0.8732\n",
      "Epoch 71/75\n",
      "390/390 [==============================] - 173s - loss: 0.5602 - acc: 0.8540 - val_loss: 0.5084 - val_acc: 0.8738\n",
      "Epoch 72/75\n",
      "390/390 [==============================] - 173s - loss: 0.5545 - acc: 0.8536 - val_loss: 0.4763 - val_acc: 0.8866\n",
      "Epoch 73/75\n",
      "390/390 [==============================] - 173s - loss: 0.5563 - acc: 0.8535 - val_loss: 0.4910 - val_acc: 0.8794\n",
      "Epoch 74/75\n",
      "390/390 [==============================] - 173s - loss: 0.5567 - acc: 0.8539 - val_loss: 0.4913 - val_acc: 0.8775\n",
      "Epoch 75/75\n",
      "390/390 [==============================] - 173s - loss: 0.5522 - acc: 0.8555 - val_loss: 0.4818 - val_acc: 0.8832\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep75'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 175s - loss: 0.5211 - acc: 0.8667 - val_loss: 0.4567 - val_acc: 0.8931\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 174s - loss: 0.5072 - acc: 0.8693 - val_loss: 0.4436 - val_acc: 0.8944\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 174s - loss: 0.5010 - acc: 0.8718 - val_loss: 0.4408 - val_acc: 0.8969\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 174s - loss: 0.4922 - acc: 0.8735 - val_loss: 0.4411 - val_acc: 0.8982\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 174s - loss: 0.4918 - acc: 0.8740 - val_loss: 0.4431 - val_acc: 0.8934\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 174s - loss: 0.4858 - acc: 0.8737 - val_loss: 0.4335 - val_acc: 0.8986\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 174s - loss: 0.4844 - acc: 0.8746 - val_loss: 0.4353 - val_acc: 0.8974\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 174s - loss: 0.4801 - acc: 0.8765 - val_loss: 0.4349 - val_acc: 0.8960\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 174s - loss: 0.4761 - acc: 0.8758 - val_loss: 0.4312 - val_acc: 0.8980\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 174s - loss: 0.4734 - acc: 0.8786 - val_loss: 0.4272 - val_acc: 0.8997\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 174s - loss: 0.4700 - acc: 0.8780 - val_loss: 0.4306 - val_acc: 0.8972\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 174s - loss: 0.4649 - acc: 0.8798 - val_loss: 0.4215 - val_acc: 0.8980\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 174s - loss: 0.4707 - acc: 0.8757 - val_loss: 0.4166 - val_acc: 0.8992\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 174s - loss: 0.4679 - acc: 0.8763 - val_loss: 0.4177 - val_acc: 0.8977\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 174s - loss: 0.4674 - acc: 0.8782 - val_loss: 0.4222 - val_acc: 0.8962\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 174s - loss: 0.4636 - acc: 0.8787 - val_loss: 0.4183 - val_acc: 0.8992\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 174s - loss: 0.4676 - acc: 0.8776 - val_loss: 0.4218 - val_acc: 0.8981\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 174s - loss: 0.4632 - acc: 0.8779 - val_loss: 0.4195 - val_acc: 0.8986\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 174s - loss: 0.4626 - acc: 0.8787 - val_loss: 0.4272 - val_acc: 0.8950\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 174s - loss: 0.4540 - acc: 0.8816 - val_loss: 0.4423 - val_acc: 0.8946\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 174s - loss: 0.4525 - acc: 0.8815 - val_loss: 0.4233 - val_acc: 0.8973\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 174s - loss: 0.4551 - acc: 0.8813 - val_loss: 0.4200 - val_acc: 0.8964\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 174s - loss: 0.4529 - acc: 0.8815 - val_loss: 0.4135 - val_acc: 0.8986\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 174s - loss: 0.4527 - acc: 0.8801 - val_loss: 0.4177 - val_acc: 0.8989\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 174s - loss: 0.4477 - acc: 0.8830 - val_loss: 0.4263 - val_acc: 0.8971\n"
     ]
    }
   ],
   "source": [
    "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep100'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 175s - loss: 0.4333 - acc: 0.8878 - val_loss: 0.4092 - val_acc: 0.9013\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 174s - loss: 0.4283 - acc: 0.8865 - val_loss: 0.4042 - val_acc: 0.9035\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 174s - loss: 0.4299 - acc: 0.8873 - val_loss: 0.3997 - val_acc: 0.9033\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 174s - loss: 0.4191 - acc: 0.8905 - val_loss: 0.4022 - val_acc: 0.9060\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 174s - loss: 0.4199 - acc: 0.8894 - val_loss: 0.4046 - val_acc: 0.9019\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 174s - loss: 0.4196 - acc: 0.8914 - val_loss: 0.3904 - val_acc: 0.9086\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 174s - loss: 0.4151 - acc: 0.8918 - val_loss: 0.3944 - val_acc: 0.9033\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 174s - loss: 0.4123 - acc: 0.8929 - val_loss: 0.3958 - val_acc: 0.9046\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 174s - loss: 0.4197 - acc: 0.8902 - val_loss: 0.3912 - val_acc: 0.9057\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 174s - loss: 0.4111 - acc: 0.8938 - val_loss: 0.3995 - val_acc: 0.9025\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 174s - loss: 0.4146 - acc: 0.8902 - val_loss: 0.3885 - val_acc: 0.9031\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 174s - loss: 0.4084 - acc: 0.8936 - val_loss: 0.3836 - val_acc: 0.9064\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 174s - loss: 0.4079 - acc: 0.8916 - val_loss: 0.3959 - val_acc: 0.9026\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 174s - loss: 0.4081 - acc: 0.8928 - val_loss: 0.3859 - val_acc: 0.9046\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 174s - loss: 0.4075 - acc: 0.8919 - val_loss: 0.3867 - val_acc: 0.9051\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 174s - loss: 0.4045 - acc: 0.8925 - val_loss: 0.3960 - val_acc: 0.9027\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 174s - loss: 0.3988 - acc: 0.8947 - val_loss: 0.3939 - val_acc: 0.9023\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 174s - loss: 0.4002 - acc: 0.8947 - val_loss: 0.3840 - val_acc: 0.9066\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 174s - loss: 0.3995 - acc: 0.8949 - val_loss: 0.3867 - val_acc: 0.9051\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 174s - loss: 0.4013 - acc: 0.8944 - val_loss: 0.3853 - val_acc: 0.9036\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 174s - loss: 0.4004 - acc: 0.8931 - val_loss: 0.3750 - val_acc: 0.9089\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 174s - loss: 0.3995 - acc: 0.8933 - val_loss: 0.3871 - val_acc: 0.9031\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 174s - loss: 0.3960 - acc: 0.8932 - val_loss: 0.3872 - val_acc: 0.9025\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 174s - loss: 0.3964 - acc: 0.8942 - val_loss: 0.3899 - val_acc: 0.9048\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 174s - loss: 0.3939 - acc: 0.8956 - val_loss: 0.3877 - val_acc: 0.9042\n"
     ]
    }
   ],
   "source": [
    "opt_rms = keras.optimizers.rmsprop(lr=0.0003,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep125'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "Test result: 90.420 loss: 0.388\n"
     ]
    }
   ],
   "source": [
    "#testing - no kaggle eval\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.load_weights(\"models/cifar10_normal_rms_ep125e_swish_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 180s - loss: 0.3801 - acc: 0.9008 - val_loss: 0.3775 - val_acc: 0.9082\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 176s - loss: 0.3807 - acc: 0.8987 - val_loss: 0.3783 - val_acc: 0.9074\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 177s - loss: 0.3759 - acc: 0.9002 - val_loss: 0.3702 - val_acc: 0.9105\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 175s - loss: 0.3682 - acc: 0.9027 - val_loss: 0.3748 - val_acc: 0.9084\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 176s - loss: 0.3704 - acc: 0.9028 - val_loss: 0.3752 - val_acc: 0.9079\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 176s - loss: 0.3726 - acc: 0.9018 - val_loss: 0.3718 - val_acc: 0.9076\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 175s - loss: 0.3682 - acc: 0.9018 - val_loss: 0.3698 - val_acc: 0.9086\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 175s - loss: 0.3659 - acc: 0.9063 - val_loss: 0.3711 - val_acc: 0.9068\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 176s - loss: 0.3683 - acc: 0.9010 - val_loss: 0.3649 - val_acc: 0.9096\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 176s - loss: 0.3653 - acc: 0.9031 - val_loss: 0.3710 - val_acc: 0.9079\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 176s - loss: 0.3680 - acc: 0.9023 - val_loss: 0.3666 - val_acc: 0.9097\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 176s - loss: 0.3648 - acc: 0.9032 - val_loss: 0.3729 - val_acc: 0.9073\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 176s - loss: 0.3582 - acc: 0.9056 - val_loss: 0.3683 - val_acc: 0.9111\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 176s - loss: 0.3599 - acc: 0.9056 - val_loss: 0.3696 - val_acc: 0.9062\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 176s - loss: 0.3593 - acc: 0.9045 - val_loss: 0.3687 - val_acc: 0.9081\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 175s - loss: 0.3600 - acc: 0.9041 - val_loss: 0.3710 - val_acc: 0.9087\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 176s - loss: 0.3561 - acc: 0.9077 - val_loss: 0.3678 - val_acc: 0.9097\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 175s - loss: 0.3544 - acc: 0.9059 - val_loss: 0.3653 - val_acc: 0.9094\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 176s - loss: 0.3531 - acc: 0.9066 - val_loss: 0.3640 - val_acc: 0.9079\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 176s - loss: 0.3555 - acc: 0.9067 - val_loss: 0.3619 - val_acc: 0.9109\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 175s - loss: 0.3501 - acc: 0.9090 - val_loss: 0.3644 - val_acc: 0.9104\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 175s - loss: 0.3576 - acc: 0.9042 - val_loss: 0.3601 - val_acc: 0.9103\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 174s - loss: 0.3522 - acc: 0.9077 - val_loss: 0.3652 - val_acc: 0.9089\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 174s - loss: 0.3525 - acc: 0.9069 - val_loss: 0.3649 - val_acc: 0.9085\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 176s - loss: 0.3581 - acc: 0.9036 - val_loss: 0.3592 - val_acc: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.00015,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep150'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.38010832655888338, 0.38059011425848072, 0.37581690261484074, 0.368176707538382, 0.37017986682274423, 0.37254608362043062, 0.36825345507752716, 0.36586236074103123, 0.36835219947466452, 0.36540139775112496, 0.36795008319251077, 0.36476327673456477, 0.35827566924713189, 0.35989203835895212, 0.35931508206273255, 0.36002793946364081, 0.35606365378636523, 0.35441921553360867, 0.35313691828432164, 0.35572445975843053, 0.35002056396194936, 0.35759680327368654, 0.3520439212755167, 0.3523508579370721, 0.357923946703402], 'acc': [0.90080128205128207, 0.89880093038177733, 0.90024462628142743, 0.90269088867500802, 0.90287135065768365, 0.90186878410638582, 0.90172842476740456, 0.90626002570394903, 0.90098652552441594, 0.90309191530317612, 0.90226981073455392, 0.90323227458479005, 0.9055983317101044, 0.90563843439204361, 0.90443535446929446, 0.90413458457465812, 0.90768367017657858, 0.90591915305088377, 0.90654074432454435, 0.90666105231299476, 0.90900705806865578, 0.90423484121257769, 0.90776387552133464, 0.90692171956393675, 0.90367340395226481], 'val_acc': [0.90820000000000001, 0.90739999999999998, 0.91049999999999998, 0.90839999999999999, 0.90790000000000004, 0.90759999999999996, 0.90859999999999996, 0.90680000000000005, 0.90959999999999996, 0.90790000000000004, 0.90969999999999995, 0.9073, 0.91110000000000002, 0.90620000000000001, 0.90810000000000002, 0.90869999999999995, 0.90969999999999995, 0.90939999999999999, 0.90790000000000004, 0.91090000000000004, 0.91039999999999999, 0.9103, 0.90890000000000004, 0.90849999999999997, 0.91110000000000002], 'val_loss': [0.37748282060623167, 0.37827485151290896, 0.37020716938972476, 0.37484987926483154, 0.37516544327735901, 0.37175945513248443, 0.36976128311157225, 0.37106223592758181, 0.3649494920730591, 0.37098409647941588, 0.36655388550758361, 0.37294182949066162, 0.36829786491394045, 0.369594190120697, 0.36868031935691836, 0.37100869159698485, 0.36781552014350893, 0.36527028124332428, 0.36397040891647336, 0.36192989993095398, 0.3644059095144272, 0.36014858989715576, 0.36519740533828737, 0.36489077274799347, 0.3591508780479431]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 177s - loss: 0.3417 - acc: 0.9097 - val_loss: 0.3624 - val_acc: 0.9101\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 176s - loss: 0.3459 - acc: 0.9081 - val_loss: 0.3563 - val_acc: 0.9127\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 176s - loss: 0.3417 - acc: 0.9096 - val_loss: 0.3592 - val_acc: 0.9112\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 174s - loss: 0.3390 - acc: 0.9102 - val_loss: 0.3569 - val_acc: 0.9110\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 174s - loss: 0.3422 - acc: 0.9091 - val_loss: 0.3555 - val_acc: 0.9119\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 174s - loss: 0.3417 - acc: 0.9093 - val_loss: 0.3577 - val_acc: 0.9110\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 174s - loss: 0.3409 - acc: 0.9103 - val_loss: 0.3574 - val_acc: 0.9103\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 176s - loss: 0.3412 - acc: 0.9099 - val_loss: 0.3589 - val_acc: 0.9104\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 176s - loss: 0.3404 - acc: 0.9086 - val_loss: 0.3592 - val_acc: 0.9114\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 176s - loss: 0.3348 - acc: 0.9125 - val_loss: 0.3593 - val_acc: 0.9109\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 176s - loss: 0.3396 - acc: 0.9097 - val_loss: 0.3578 - val_acc: 0.9124\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 176s - loss: 0.3326 - acc: 0.9123 - val_loss: 0.3566 - val_acc: 0.9103\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 177s - loss: 0.3327 - acc: 0.9114 - val_loss: 0.3550 - val_acc: 0.9111\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 178s - loss: 0.3336 - acc: 0.9122 - val_loss: 0.3568 - val_acc: 0.9118\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 176s - loss: 0.3351 - acc: 0.9123 - val_loss: 0.3562 - val_acc: 0.9130\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 176s - loss: 0.3297 - acc: 0.9130 - val_loss: 0.3573 - val_acc: 0.9117\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 175s - loss: 0.3363 - acc: 0.9117 - val_loss: 0.3573 - val_acc: 0.9124\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 175s - loss: 0.3296 - acc: 0.9118 - val_loss: 0.3556 - val_acc: 0.9116\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 175s - loss: 0.3350 - acc: 0.9101 - val_loss: 0.3570 - val_acc: 0.9104\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 176s - loss: 0.3323 - acc: 0.9115 - val_loss: 0.3567 - val_acc: 0.9109\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 176s - loss: 0.3291 - acc: 0.9122 - val_loss: 0.3585 - val_acc: 0.9117\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 175s - loss: 0.3331 - acc: 0.9115 - val_loss: 0.3555 - val_acc: 0.9111\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 183s - loss: 0.3355 - acc: 0.9099 - val_loss: 0.3567 - val_acc: 0.9114\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 184s - loss: 0.3279 - acc: 0.9133 - val_loss: 0.3573 - val_acc: 0.9120\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 177s - loss: 0.3273 - acc: 0.9142 - val_loss: 0.3538 - val_acc: 0.9140\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000075,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep175'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.3416514161687631, 0.34592436800448223, 0.34168121668058671, 0.33898520258362569, 0.34227173389878301, 0.34165925709222961, 0.3406958215160939, 0.3412170304313546, 0.34046834132630815, 0.33479592906843597, 0.33958635353720795, 0.33263544211947538, 0.33267546005076154, 0.3336410946405427, 0.33516422297505566, 0.32974200762920669, 0.33638574250393816, 0.32969633701867235, 0.33488592188022515, 0.33229776942504308, 0.32904149725301779, 0.33312008897769441, 0.33543938234864346, 0.32791112526357269, 0.32727195544811943], 'acc': [0.90969551282051286, 0.90816490213038026, 0.909568495386336, 0.91014998397805735, 0.90902710938094178, 0.90932787935206782, 0.9103103946293245, 0.90988931661238071, 0.908525826114854, 0.91247593844055475, 0.90968880329829671, 0.91235563037561462, 0.91141321785678686, 0.9121751684694287, 0.91229547645787912, 0.91301732438858174, 0.91175409047160727, 0.91175409047160727, 0.91010988129611803, 0.91151347449470643, 0.9122754250882259, 0.91151347451382891, 0.90992941935168725, 0.91329804297093209, 0.91420035290343282], 'val_acc': [0.91010000000000002, 0.91269999999999996, 0.91120000000000001, 0.91100000000000003, 0.91190000000000004, 0.91100000000000003, 0.9103, 0.91039999999999999, 0.91139999999999999, 0.91090000000000004, 0.91239999999999999, 0.9103, 0.91110000000000002, 0.91180000000000005, 0.91300000000000003, 0.91169999999999995, 0.91239999999999999, 0.91159999999999997, 0.91039999999999999, 0.91090000000000004, 0.91169999999999995, 0.91110000000000002, 0.91139999999999999, 0.91200000000000003, 0.91400000000000003], 'val_loss': [0.36244561343193055, 0.35626765682697298, 0.35918336796760558, 0.35685447709560392, 0.35546256237030027, 0.35773414199352266, 0.35742037882804872, 0.35889779813289641, 0.35921857421398162, 0.35933903093338015, 0.35775527074337005, 0.3565589636325836, 0.35501668128967284, 0.35680122885704041, 0.35619233572483061, 0.35729598309993743, 0.35730983862876892, 0.35560753595829009, 0.35699430162906648, 0.35672531857490541, 0.35845015339851377, 0.35549484755992888, 0.35668950152397155, 0.35734321308135986, 0.35380221362113951]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.load_weights(\"models/cifar10_normal_rms_ep175e_swish_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 180s - loss: 0.3250 - acc: 0.9144 - val_loss: 0.3514 - val_acc: 0.9133\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 177s - loss: 0.3270 - acc: 0.9136 - val_loss: 0.3519 - val_acc: 0.9134\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 176s - loss: 0.3290 - acc: 0.9134 - val_loss: 0.3481 - val_acc: 0.9139\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 175s - loss: 0.3191 - acc: 0.9149 - val_loss: 0.3498 - val_acc: 0.9123\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 175s - loss: 0.3212 - acc: 0.9137 - val_loss: 0.3481 - val_acc: 0.9139\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 175s - loss: 0.3213 - acc: 0.9154 - val_loss: 0.3493 - val_acc: 0.9147\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 175s - loss: 0.3206 - acc: 0.9160 - val_loss: 0.3511 - val_acc: 0.9128\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 175s - loss: 0.3241 - acc: 0.9149 - val_loss: 0.3497 - val_acc: 0.9136\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 174s - loss: 0.3225 - acc: 0.9154 - val_loss: 0.3486 - val_acc: 0.9144\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 174s - loss: 0.3217 - acc: 0.9146 - val_loss: 0.3492 - val_acc: 0.9132\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 174s - loss: 0.3222 - acc: 0.9150 - val_loss: 0.3492 - val_acc: 0.9137\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 174s - loss: 0.3180 - acc: 0.9159 - val_loss: 0.3496 - val_acc: 0.9137\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 174s - loss: 0.3164 - acc: 0.9169 - val_loss: 0.3517 - val_acc: 0.9137\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 174s - loss: 0.3188 - acc: 0.9163 - val_loss: 0.3504 - val_acc: 0.9130\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 174s - loss: 0.3176 - acc: 0.9159 - val_loss: 0.3502 - val_acc: 0.9140\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 174s - loss: 0.3199 - acc: 0.9159 - val_loss: 0.3502 - val_acc: 0.9128\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 174s - loss: 0.3202 - acc: 0.9148 - val_loss: 0.3512 - val_acc: 0.9134\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 174s - loss: 0.3204 - acc: 0.9141 - val_loss: 0.3504 - val_acc: 0.9134\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 174s - loss: 0.3196 - acc: 0.9147 - val_loss: 0.3490 - val_acc: 0.9138\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 174s - loss: 0.3156 - acc: 0.9174 - val_loss: 0.3492 - val_acc: 0.9116\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 174s - loss: 0.3227 - acc: 0.9133 - val_loss: 0.3493 - val_acc: 0.9134\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 174s - loss: 0.3136 - acc: 0.9175 - val_loss: 0.3488 - val_acc: 0.9137\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 174s - loss: 0.3179 - acc: 0.9159 - val_loss: 0.3479 - val_acc: 0.9134\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 174s - loss: 0.3167 - acc: 0.9165 - val_loss: 0.3487 - val_acc: 0.9138\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 174s - loss: 0.3118 - acc: 0.9175 - val_loss: 0.3505 - val_acc: 0.9132\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep200'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.32497953054232476, 0.3268954772328887, 0.32900361266891887, 0.31903057407024848, 0.3210659807295152, 0.32132476578739388, 0.3204213489715893, 0.323988143845862, 0.32260833378017123, 0.32160424921311437, 0.32220951239956391, 0.3180055212603573, 0.31643503513288757, 0.31885946512145802, 0.31768857720458893, 0.32003850741075868, 0.32013782567231364, 0.32047912141892021, 0.3197004017173613, 0.31571276059967607, 0.32262027566732027, 0.31353503315541315, 0.31782353619447612, 0.3165854238951325, 0.31178254181657189], 'val_loss': [0.3513798889398575, 0.35189285843372348, 0.34809259591102598, 0.34983294553756716, 0.34807854878902433, 0.34934413838386535, 0.35108818295001981, 0.34973235950469972, 0.34861552507877352, 0.34923649826049807, 0.34915909974575043, 0.34956117551326754, 0.35169509420394895, 0.35042487893104551, 0.35019190847873688, 0.35019364681243897, 0.35118910489082339, 0.35044241397380826, 0.34895255875587461, 0.34918565249443057, 0.34934101433753967, 0.34877361824512482, 0.34789760053157809, 0.34873230404853822, 0.35054063978195188], 'acc': [0.91436298076923073, 0.9135787616680171, 0.91333814561462645, 0.91492220079589048, 0.91373917228103951, 0.91540343278793712, 0.91606512676265939, 0.91494225212729896, 0.91532322742405858, 0.91458132818107007, 0.91498235486660551, 0.91590471607314727, 0.91686717999987322, 0.91628569133166204, 0.91590471605402479, 0.91586461344857528, 0.91482194417709339, 0.9140800449149824, 0.9146815848572345, 0.91740856590965525, 0.91333814567199378, 0.917528873955473, 0.91594481875508649, 0.91654635865909384, 0.9175088225666973], 'val_acc': [0.9133, 0.91339999999999999, 0.91390000000000005, 0.9123, 0.91390000000000005, 0.91469999999999996, 0.91279999999999994, 0.91359999999999997, 0.91439999999999999, 0.91320000000000001, 0.91369999999999996, 0.91369999999999996, 0.91369999999999996, 0.91300000000000003, 0.91400000000000003, 0.91279999999999994, 0.91339999999999999, 0.91339999999999999, 0.91379999999999995, 0.91159999999999997, 0.91339999999999999, 0.91369999999999996, 0.91339999999999999, 0.91379999999999995, 0.91320000000000001]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 174s - loss: 0.3173 - acc: 0.9159 - val_loss: 0.3473 - val_acc: 0.9139\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 173s - loss: 0.3156 - acc: 0.9171 - val_loss: 0.3480 - val_acc: 0.9135\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 173s - loss: 0.3125 - acc: 0.9180 - val_loss: 0.3486 - val_acc: 0.9130\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 173s - loss: 0.3173 - acc: 0.9160 - val_loss: 0.3487 - val_acc: 0.9125\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 173s - loss: 0.3148 - acc: 0.9184 - val_loss: 0.3485 - val_acc: 0.9132\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 173s - loss: 0.3139 - acc: 0.9173 - val_loss: 0.3481 - val_acc: 0.9141\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 173s - loss: 0.3166 - acc: 0.9160 - val_loss: 0.3489 - val_acc: 0.9136\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 173s - loss: 0.3167 - acc: 0.9175 - val_loss: 0.3479 - val_acc: 0.9134\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 173s - loss: 0.3173 - acc: 0.9165 - val_loss: 0.3474 - val_acc: 0.9135\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 173s - loss: 0.3089 - acc: 0.9185 - val_loss: 0.3465 - val_acc: 0.9133\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 173s - loss: 0.3099 - acc: 0.9180 - val_loss: 0.3480 - val_acc: 0.9132\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 173s - loss: 0.3129 - acc: 0.9185 - val_loss: 0.3467 - val_acc: 0.9137\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 173s - loss: 0.3115 - acc: 0.9174 - val_loss: 0.3470 - val_acc: 0.9142\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 173s - loss: 0.3103 - acc: 0.9171 - val_loss: 0.3465 - val_acc: 0.9138\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 173s - loss: 0.3147 - acc: 0.9164 - val_loss: 0.3484 - val_acc: 0.9136\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 173s - loss: 0.3094 - acc: 0.9184 - val_loss: 0.3480 - val_acc: 0.9137\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 173s - loss: 0.3134 - acc: 0.9178 - val_loss: 0.3473 - val_acc: 0.9131\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 173s - loss: 0.3128 - acc: 0.9168 - val_loss: 0.3472 - val_acc: 0.9140\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 173s - loss: 0.3142 - acc: 0.9162 - val_loss: 0.3490 - val_acc: 0.9139\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 173s - loss: 0.3081 - acc: 0.9194 - val_loss: 0.3472 - val_acc: 0.9130\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 173s - loss: 0.3104 - acc: 0.9187 - val_loss: 0.3474 - val_acc: 0.9127\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 173s - loss: 0.3096 - acc: 0.9179 - val_loss: 0.3470 - val_acc: 0.9137\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 173s - loss: 0.3087 - acc: 0.9193 - val_loss: 0.3456 - val_acc: 0.9142\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 173s - loss: 0.3155 - acc: 0.9168 - val_loss: 0.3472 - val_acc: 0.9134\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 173s - loss: 0.3125 - acc: 0.9174 - val_loss: 0.3472 - val_acc: 0.9141\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs, verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep225'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31727638405102948, 0.31561774019251126, 0.3124858672931709, 0.31737174290206366, 0.31492614628968807, 0.31390394682030592, 0.31654564044320282, 0.31657746264978137, 0.31717048882290766, 0.30884037000229619, 0.30987050729682136, 0.3129799327752435, 0.31159984844596028, 0.31039160581823722, 0.31485962236696302, 0.30941637642956482, 0.31340564601422122, 0.31277442488067608, 0.31427529290734402, 0.30812994131378002, 0.31034299415734323, 0.30964733333705441, 0.30867676487097495, 0.31554977012093649, 0.31249697585307828], 'val_loss': [0.34732628731727599, 0.34799878382682803, 0.34861354596614835, 0.34870175282955168, 0.34849497473239899, 0.34807915220260621, 0.3489204283237457, 0.34789902646541593, 0.34736662652492523, 0.34648163759708406, 0.34800496101379397, 0.34665943956375123, 0.34696761023998263, 0.34648124432563782, 0.34843088185787202, 0.34802374372482298, 0.34725667047500608, 0.34719141507148743, 0.34898651800155639, 0.34721481277942656, 0.34740361545085907, 0.34700736472606658, 0.34556088278293612, 0.34717672238349917, 0.34715988669395448], 'acc': [0.91590544871794877, 0.91710779599589642, 0.91797000324645794, 0.91600497269194436, 0.91837102985550356, 0.9173283606413889, 0.91604507539300606, 0.91746871988475798, 0.91650625605364433, 0.9185715431313427, 0.91801010590927468, 0.91849133782483161, 0.91742861727930847, 0.91708774458799835, 0.91634584540237707, 0.91843118381148392, 0.91784969520064019, 0.91682707733705637, 0.9162054860633958, 0.91939364777645471, 0.91877205644542681, 0.91792990054539625, 0.91931344239345381, 0.91682707731793389, 0.91740856589053277], 'val_acc': [0.91390000000000005, 0.91349999999999998, 0.91300000000000003, 0.91249999999999998, 0.91320000000000001, 0.91410000000000002, 0.91359999999999997, 0.91339999999999999, 0.91349999999999998, 0.9133, 0.91320000000000001, 0.91369999999999996, 0.91420000000000001, 0.91379999999999995, 0.91359999999999997, 0.91369999999999996, 0.91310000000000002, 0.91400000000000003, 0.91390000000000005, 0.91300000000000003, 0.91269999999999996, 0.91369999999999996, 0.91420000000000001, 0.91339999999999999, 0.91410000000000002]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 175s - loss: 0.3153 - acc: 0.9175 - val_loss: 0.3461 - val_acc: 0.9143\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 173s - loss: 0.3114 - acc: 0.9176 - val_loss: 0.3468 - val_acc: 0.9141\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 173s - loss: 0.3104 - acc: 0.9180 - val_loss: 0.3467 - val_acc: 0.9140\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 173s - loss: 0.3127 - acc: 0.9171 - val_loss: 0.3471 - val_acc: 0.9146\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 173s - loss: 0.3129 - acc: 0.9176 - val_loss: 0.3461 - val_acc: 0.9144\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 173s - loss: 0.3070 - acc: 0.9190 - val_loss: 0.3459 - val_acc: 0.9146\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 173s - loss: 0.3098 - acc: 0.9178 - val_loss: 0.3460 - val_acc: 0.9139\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 173s - loss: 0.3134 - acc: 0.9172 - val_loss: 0.3453 - val_acc: 0.9143\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 173s - loss: 0.3038 - acc: 0.9199 - val_loss: 0.3464 - val_acc: 0.9144\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 173s - loss: 0.3087 - acc: 0.9197 - val_loss: 0.3469 - val_acc: 0.9139\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 173s - loss: 0.3099 - acc: 0.9171 - val_loss: 0.3452 - val_acc: 0.9142\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 173s - loss: 0.3095 - acc: 0.9186 - val_loss: 0.3456 - val_acc: 0.9142\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 173s - loss: 0.3105 - acc: 0.9190 - val_loss: 0.3461 - val_acc: 0.9134\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 173s - loss: 0.3102 - acc: 0.9178 - val_loss: 0.3467 - val_acc: 0.9126\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 173s - loss: 0.3082 - acc: 0.9187 - val_loss: 0.3465 - val_acc: 0.9130\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 173s - loss: 0.3104 - acc: 0.9184 - val_loss: 0.3457 - val_acc: 0.9136\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 175s - loss: 0.3085 - acc: 0.9188 - val_loss: 0.3465 - val_acc: 0.9134\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 175s - loss: 0.3077 - acc: 0.9186 - val_loss: 0.3455 - val_acc: 0.9134\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 175s - loss: 0.3080 - acc: 0.9177 - val_loss: 0.3466 - val_acc: 0.9135\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 175s - loss: 0.3139 - acc: 0.9165 - val_loss: 0.3453 - val_acc: 0.9132\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 174s - loss: 0.3038 - acc: 0.9198 - val_loss: 0.3452 - val_acc: 0.9135\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 174s - loss: 0.3095 - acc: 0.9166 - val_loss: 0.3450 - val_acc: 0.9138\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 174s - loss: 0.3094 - acc: 0.9179 - val_loss: 0.3449 - val_acc: 0.9143\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 174s - loss: 0.3064 - acc: 0.9196 - val_loss: 0.3455 - val_acc: 0.9142\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 174s - loss: 0.3072 - acc: 0.9182 - val_loss: 0.3452 - val_acc: 0.9145\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep250'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31532534131636986, 0.31148696546662413, 0.31027973789146857, 0.31263186666190645, 0.31303368962495648, 0.30709080504690334, 0.30980688957859009, 0.31329367650905249, 0.30371297877263975, 0.30863798877961135, 0.30986028685950684, 0.3094718975251326, 0.31050371855047981, 0.31021416679689201, 0.30827013545400406, 0.31038330870635394, 0.30838648754509357, 0.30769229149413024, 0.30801393638102337, 0.31398063793869252, 0.30393243365690115, 0.30953163447806881, 0.30943142808435969, 0.30648464539091597, 0.30703077386654759], 'val_loss': [0.34605934839248659, 0.34679098236560824, 0.34668390643596647, 0.34712314009666445, 0.34605145404338838, 0.3459210314273834, 0.34598773038387298, 0.34528314518928527, 0.34643940141201018, 0.34685458023548127, 0.34517234613895414, 0.34559510135650634, 0.34606379618644717, 0.34674582428932188, 0.34646046094894412, 0.34573349885940552, 0.34654088706970215, 0.34549609107971191, 0.34657563149929049, 0.34528551223278048, 0.34524284818172457, 0.34498537423610687, 0.34486500430107114, 0.34550482177734376, 0.34520779452323913], 'acc': [0.91754807692307694, 0.91754892521039166, 0.91801010590927468, 0.91714789862046842, 0.91754892524863652, 0.91895251844722492, 0.91780959259519068, 0.91726820658979635, 0.91995508505589008, 0.91977462301584711, 0.91714789860134593, 0.91859159452011852, 0.91895251846634729, 0.9177895412637822, 0.91869185113891561, 0.91841113251832041, 0.91881215908912117, 0.91859159450099603, 0.91768928454937293, 0.91650625601539937, 0.91973452033390779, 0.91658646132191057, 0.91794995191504947, 0.91961421236457985, 0.91827077317933914], 'val_acc': [0.9143, 0.91410000000000002, 0.91400000000000003, 0.91459999999999997, 0.91439999999999999, 0.91459999999999997, 0.91390000000000005, 0.9143, 0.91439999999999999, 0.91390000000000005, 0.91420000000000001, 0.91420000000000001, 0.91339999999999999, 0.91259999999999997, 0.91300000000000003, 0.91359999999999997, 0.91339999999999999, 0.91339999999999999, 0.91349999999999998, 0.91320000000000001, 0.91349999999999998, 0.91379999999999995, 0.9143, 0.91420000000000001, 0.91449999999999998]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swish\n"
     ]
    }
   ],
   "source": [
    "act, act_name = swish, \"swish\"\n",
    "print(act_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.load_weights(\"models/cifar10_normal_rms_ep175swish.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 151s - loss: 0.3941 - acc: 0.8989 - val_loss: 0.3821 - val_acc: 0.9062\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 150s - loss: 0.3861 - acc: 0.9016 - val_loss: 0.3830 - val_acc: 0.9041\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 150s - loss: 0.3868 - acc: 0.9008 - val_loss: 0.3825 - val_acc: 0.9059\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 150s - loss: 0.3893 - acc: 0.9009 - val_loss: 0.3825 - val_acc: 0.9048\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 150s - loss: 0.3877 - acc: 0.9001 - val_loss: 0.3804 - val_acc: 0.9059\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 150s - loss: 0.3866 - acc: 0.9023 - val_loss: 0.3808 - val_acc: 0.9056\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 150s - loss: 0.3914 - acc: 0.8993 - val_loss: 0.3804 - val_acc: 0.9075\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 150s - loss: 0.3899 - acc: 0.9009 - val_loss: 0.3788 - val_acc: 0.9061\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 150s - loss: 0.3891 - acc: 0.9009 - val_loss: 0.3802 - val_acc: 0.9057\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 150s - loss: 0.3815 - acc: 0.9013 - val_loss: 0.3815 - val_acc: 0.9061\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 150s - loss: 0.3868 - acc: 0.9021 - val_loss: 0.3809 - val_acc: 0.9066\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 150s - loss: 0.3890 - acc: 0.9002 - val_loss: 0.3830 - val_acc: 0.9038\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 150s - loss: 0.3863 - acc: 0.9013 - val_loss: 0.3778 - val_acc: 0.9073\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 150s - loss: 0.3865 - acc: 0.9018 - val_loss: 0.3841 - val_acc: 0.9056\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 150s - loss: 0.3798 - acc: 0.9033 - val_loss: 0.3814 - val_acc: 0.9064\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 150s - loss: 0.3840 - acc: 0.9017 - val_loss: 0.3793 - val_acc: 0.9079\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 150s - loss: 0.3862 - acc: 0.9006 - val_loss: 0.3799 - val_acc: 0.9068\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 150s - loss: 0.3824 - acc: 0.9015 - val_loss: 0.3806 - val_acc: 0.9072\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 150s - loss: 0.3861 - acc: 0.9018 - val_loss: 0.3800 - val_acc: 0.9081\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 150s - loss: 0.3826 - acc: 0.9005 - val_loss: 0.3815 - val_acc: 0.9068\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 150s - loss: 0.3870 - acc: 0.9004 - val_loss: 0.3800 - val_acc: 0.9075\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 150s - loss: 0.3947 - acc: 0.9007 - val_loss: 0.3778 - val_acc: 0.9069\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 150s - loss: 0.3808 - acc: 0.9039 - val_loss: 0.3786 - val_acc: 0.9069\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 150s - loss: 0.3820 - acc: 0.9029 - val_loss: 0.3763 - val_acc: 0.9080\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 150s - loss: 0.3840 - acc: 0.9008 - val_loss: 0.3821 - val_acc: 0.9062\n"
     ]
    }
   ],
   "source": [
    "# Continue for 5 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep200'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.39412982085576426, 0.38619856505314432, 0.38696966682407463, 0.38933971848363941, 0.3877398362135252, 0.38676630266974055, 0.39132739771318847, 0.38993927025626707, 0.38914730230852468, 0.38150240027219928, 0.38691549099214495, 0.38911181786789278, 0.38639568362742382, 0.38652952284548275, 0.37973694018075432, 0.38414320427617238, 0.3862733311728862, 0.38243836588992652, 0.38606563618751455, 0.38247265888782583, 0.38711140737688077, 0.39436690299450528, 0.38074350534894352, 0.38152226026447528, 0.38416170836795321], 'val_loss': [0.38209436135292052, 0.38296386077404021, 0.38250734906196593, 0.38247535512447356, 0.3803700690984726, 0.38077830927371981, 0.38043556652069094, 0.37884703214168547, 0.38018875663280488, 0.381479208612442, 0.38093609778881071, 0.38297155227661134, 0.37779230394363406, 0.38410715236663817, 0.38143224673271181, 0.37926607537269591, 0.37992875471115112, 0.38060249269008639, 0.38004936945438383, 0.3815449747800827, 0.37999954714775086, 0.37775407214164736, 0.37864244210720061, 0.37627028555870057, 0.38214458737373352], 'acc': [0.89887820512820515, 0.90162816814860736, 0.90074590950927025, 0.90090632014141503, 0.90010426690420131, 0.90222970801436986, 0.89926211098504827, 0.90088626881000666, 0.90082611481578145, 0.9012672441067664, 0.90212945143381751, 0.90012431825473216, 0.9012672441832561, 0.9017484761179354, 0.90327237724760689, 0.90160811674070929, 0.90052534488290026, 0.90144770616593173, 0.90184873273673249, 0.90056544752659462, 0.90038498558216384, 0.90072585821610673, 0.90391401991004316, 0.90295155594507237, 0.90078601219120946], 'val_acc': [0.90620000000000001, 0.90410000000000001, 0.90590000000000004, 0.90480000000000005, 0.90590000000000004, 0.90559999999999996, 0.90749999999999997, 0.90610000000000002, 0.90569999999999995, 0.90610000000000002, 0.90659999999999996, 0.90380000000000005, 0.9073, 0.90559999999999996, 0.90639999999999998, 0.90790000000000004, 0.90680000000000005, 0.90720000000000001, 0.90810000000000002, 0.90680000000000005, 0.90749999999999997, 0.90690000000000004, 0.90690000000000004, 0.90800000000000003, 0.90620000000000001]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 151s - loss: 0.3761 - acc: 0.9024 - val_loss: 0.3774 - val_acc: 0.9066\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 150s - loss: 0.3824 - acc: 0.9011 - val_loss: 0.3782 - val_acc: 0.9069\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 150s - loss: 0.3865 - acc: 0.9034 - val_loss: 0.3821 - val_acc: 0.9061\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 150s - loss: 0.3840 - acc: 0.9022 - val_loss: 0.3778 - val_acc: 0.9064\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 150s - loss: 0.3883 - acc: 0.9011 - val_loss: 0.3778 - val_acc: 0.9082\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 150s - loss: 0.3846 - acc: 0.9021 - val_loss: 0.3764 - val_acc: 0.9074\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 150s - loss: 0.3788 - acc: 0.9021 - val_loss: 0.3733 - val_acc: 0.9085\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 150s - loss: 0.3820 - acc: 0.9026 - val_loss: 0.3768 - val_acc: 0.9068\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 150s - loss: 0.3833 - acc: 0.9033 - val_loss: 0.3760 - val_acc: 0.9071\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 150s - loss: 0.3860 - acc: 0.9024 - val_loss: 0.3784 - val_acc: 0.9076\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 150s - loss: 0.3755 - acc: 0.9046 - val_loss: 0.3788 - val_acc: 0.9066\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 150s - loss: 0.3771 - acc: 0.9043 - val_loss: 0.3780 - val_acc: 0.9063\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 150s - loss: 0.3844 - acc: 0.9034 - val_loss: 0.3771 - val_acc: 0.9066\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 150s - loss: 0.3769 - acc: 0.9027 - val_loss: 0.3774 - val_acc: 0.9062\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 150s - loss: 0.3774 - acc: 0.9010 - val_loss: 0.3782 - val_acc: 0.9064\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 150s - loss: 0.3848 - acc: 0.9015 - val_loss: 0.3766 - val_acc: 0.9076\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 150s - loss: 0.3798 - acc: 0.9024 - val_loss: 0.3771 - val_acc: 0.9078\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 150s - loss: 0.3813 - acc: 0.9028 - val_loss: 0.3755 - val_acc: 0.9078\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 150s - loss: 0.3780 - acc: 0.9049 - val_loss: 0.3775 - val_acc: 0.9067\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 150s - loss: 0.3748 - acc: 0.9045 - val_loss: 0.3770 - val_acc: 0.9070\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 150s - loss: 0.3814 - acc: 0.9019 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 150s - loss: 0.3797 - acc: 0.9039 - val_loss: 0.3773 - val_acc: 0.9072\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 150s - loss: 0.3820 - acc: 0.9029 - val_loss: 0.3770 - val_acc: 0.9078\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 150s - loss: 0.3816 - acc: 0.9036 - val_loss: 0.3780 - val_acc: 0.9089\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 150s - loss: 0.3769 - acc: 0.9031 - val_loss: 0.3789 - val_acc: 0.9070\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs, verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep225'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.37612891888771299, 0.38237484615507666, 0.38653761260319031, 0.38393559995506832, 0.38829550985575562, 0.38452999681511635, 0.37875335450580877, 0.3820052532324395, 0.38333845660592408, 0.38571225304155349, 0.37563527415855824, 0.37684882803914788, 0.38438353195839065, 0.37680718528371537, 0.37752403808894508, 0.38486625526170909, 0.37963854949138542, 0.38108867353302261, 0.37801456817610735, 0.37481612600039549, 0.38131736210802253, 0.37975518757768423, 0.38175198213006961, 0.38148173895408449, 0.3769784731038075], 'val_loss': [0.3773943742752075, 0.37822800655364991, 0.38213611381053925, 0.37782376208305357, 0.3777864230632782, 0.37636971549987791, 0.37325618700981139, 0.37679366078376769, 0.37601043767929077, 0.37842002351284026, 0.37880641300678253, 0.37800729222297669, 0.37706602993011473, 0.37744025473594667, 0.37818286128044126, 0.37658985910415649, 0.37713133444786073, 0.37546124300956724, 0.377480361366272, 0.37702953739166262, 0.37778443861007688, 0.37727997338771818, 0.37699603965282441, 0.37795861225128174, 0.37889610245227812], 'acc': [0.90240384615384617, 0.9011068334746215, 0.90337263398113865, 0.90222970807173708, 0.9011268847869075, 0.90200914338799976, 0.90208934871363344, 0.90267083734359965, 0.90325232599268823, 0.90243022132845385, 0.90455566251511221, 0.90423484119345521, 0.90343278797536386, 0.90269088863676317, 0.90092637147282351, 0.90140760344574766, 0.90245027273635203, 0.90279114535117244, 0.90485643248623826, 0.90447545713211119, 0.90194898937465218, 0.90387391724722643, 0.90289140200821449, 0.90365335254436663, 0.90311196667282945], 'val_acc': [0.90659999999999996, 0.90690000000000004, 0.90610000000000002, 0.90639999999999998, 0.90820000000000001, 0.90739999999999998, 0.90849999999999997, 0.90680000000000005, 0.90710000000000002, 0.90759999999999996, 0.90659999999999996, 0.90629999999999999, 0.90659999999999996, 0.90620000000000001, 0.90639999999999998, 0.90759999999999996, 0.90780000000000005, 0.90780000000000005, 0.90669999999999995, 0.90700000000000003, 0.90739999999999998, 0.90720000000000001, 0.90780000000000005, 0.90890000000000004, 0.90700000000000003]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 151s - loss: 0.3767 - acc: 0.9032 - val_loss: 0.3783 - val_acc: 0.9067\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 150s - loss: 0.3724 - acc: 0.9045 - val_loss: 0.3778 - val_acc: 0.9073\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 150s - loss: 0.3834 - acc: 0.9033 - val_loss: 0.3767 - val_acc: 0.9066\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 150s - loss: 0.3776 - acc: 0.9039 - val_loss: 0.3783 - val_acc: 0.9067\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 150s - loss: 0.3811 - acc: 0.9011 - val_loss: 0.3780 - val_acc: 0.9063\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 150s - loss: 0.3854 - acc: 0.9023 - val_loss: 0.3790 - val_acc: 0.9067\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 150s - loss: 0.3767 - acc: 0.9038 - val_loss: 0.3777 - val_acc: 0.9064\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 150s - loss: 0.3768 - acc: 0.9030 - val_loss: 0.3764 - val_acc: 0.9067\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 150s - loss: 0.3731 - acc: 0.9045 - val_loss: 0.3789 - val_acc: 0.9065\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 150s - loss: 0.3815 - acc: 0.9029 - val_loss: 0.3774 - val_acc: 0.9077\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 150s - loss: 0.3757 - acc: 0.9045 - val_loss: 0.3781 - val_acc: 0.9068\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 150s - loss: 0.3735 - acc: 0.9023 - val_loss: 0.3768 - val_acc: 0.9067\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 150s - loss: 0.3708 - acc: 0.9047 - val_loss: 0.3781 - val_acc: 0.9075\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 150s - loss: 0.3710 - acc: 0.9038 - val_loss: 0.3772 - val_acc: 0.9070\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 150s - loss: 0.3702 - acc: 0.9061 - val_loss: 0.3798 - val_acc: 0.9063\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 150s - loss: 0.3749 - acc: 0.9037 - val_loss: 0.3800 - val_acc: 0.9062\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 150s - loss: 0.3716 - acc: 0.9055 - val_loss: 0.3774 - val_acc: 0.9069\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 150s - loss: 0.3796 - acc: 0.9019 - val_loss: 0.3766 - val_acc: 0.9071\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 150s - loss: 0.3731 - acc: 0.9063 - val_loss: 0.3782 - val_acc: 0.9064\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 150s - loss: 0.3739 - acc: 0.9035 - val_loss: 0.3784 - val_acc: 0.9066\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 150s - loss: 0.3750 - acc: 0.9040 - val_loss: 0.3774 - val_acc: 0.9074\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 150s - loss: 0.3740 - acc: 0.9039 - val_loss: 0.3777 - val_acc: 0.9075\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 150s - loss: 0.3729 - acc: 0.9044 - val_loss: 0.3792 - val_acc: 0.9068\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 150s - loss: 0.3753 - acc: 0.9038 - val_loss: 0.3770 - val_acc: 0.9068\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 150s - loss: 0.3741 - acc: 0.9046 - val_loss: 0.3768 - val_acc: 0.9058\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep250'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.37665859686258513, 0.37234173525324377, 0.383419515155698, 0.37777850921524231, 0.38122818237281131, 0.3855380183244157, 0.37682802612329469, 0.37662868401084071, 0.37312193545233491, 0.38148873084471857, 0.37577662262007866, 0.3735294281231657, 0.37083160772054363, 0.37115676281331328, 0.37003692773278035, 0.37474872356888417, 0.37168858261264437, 0.37974291710965252, 0.37314224893327014, 0.37387847676658081, 0.37503603681142722, 0.37398154783562509, 0.37295200676921092, 0.3752203719199832, 0.37400490181316809], 'val_loss': [0.37827535803318024, 0.37775505878925325, 0.3766703224658966, 0.37830858163833619, 0.37795998544692994, 0.37901801338195801, 0.37769617788791654, 0.37644589314460752, 0.37885511789321902, 0.37738699972629547, 0.37808929982185363, 0.37682319374084472, 0.37807148866653445, 0.37715971713066099, 0.37978829243183138, 0.38002009096145628, 0.37741174790859222, 0.37659371478557585, 0.37822762763500212, 0.37842267546653746, 0.3773623633861542, 0.37767037255764008, 0.37922431986331939, 0.37697366828918455, 0.37681904044151304], 'acc': [0.90322516025641031, 0.90457571378915325, 0.90331247996779107, 0.90385386589669559, 0.90110683349374399, 0.90222970803349223, 0.90381376325300122, 0.90307186397176775, 0.90443535452666179, 0.90289140200821449, 0.90449550854000937, 0.90230991334000343, 0.90473612444042051, 0.90373355790824506, 0.90605951238986504, 0.90379371186422541, 0.90547802375989883, 0.90186878408726334, 0.90628007701623503, 0.90355309594469191, 0.90393407124145164, 0.90393407126057401, 0.90441530319525332, 0.90389396852126747, 0.90461581649021494], 'val_acc': [0.90669999999999995, 0.9073, 0.90659999999999996, 0.90669999999999995, 0.90629999999999999, 0.90669999999999995, 0.90639999999999998, 0.90669999999999995, 0.90649999999999997, 0.90769999999999995, 0.90680000000000005, 0.90669999999999995, 0.90749999999999997, 0.90700000000000003, 0.90629999999999999, 0.90620000000000001, 0.90690000000000004, 0.90710000000000002, 0.90639999999999998, 0.90659999999999996, 0.90739999999999998, 0.90749999999999997, 0.90680000000000005, 0.90680000000000005, 0.90580000000000005]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act, act_name = \"relu\", \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.load_weights(\"models/cifar10_normal_rms_ep175relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 143s - loss: 0.3586 - acc: 0.9046 - val_loss: 0.3708 - val_acc: 0.9092\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 141s - loss: 0.3677 - acc: 0.9018 - val_loss: 0.3668 - val_acc: 0.9093\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 141s - loss: 0.3641 - acc: 0.9032 - val_loss: 0.3639 - val_acc: 0.9107\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 141s - loss: 0.3643 - acc: 0.9042 - val_loss: 0.3654 - val_acc: 0.9089\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 141s - loss: 0.3636 - acc: 0.9042 - val_loss: 0.3658 - val_acc: 0.9095\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 141s - loss: 0.3625 - acc: 0.9025 - val_loss: 0.3626 - val_acc: 0.9108\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 141s - loss: 0.3642 - acc: 0.9029 - val_loss: 0.3648 - val_acc: 0.9091\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 141s - loss: 0.3565 - acc: 0.9050 - val_loss: 0.3638 - val_acc: 0.9096\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 141s - loss: 0.3641 - acc: 0.9022 - val_loss: 0.3632 - val_acc: 0.9102\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 141s - loss: 0.3624 - acc: 0.9027 - val_loss: 0.3657 - val_acc: 0.9101\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 141s - loss: 0.3599 - acc: 0.9029 - val_loss: 0.3637 - val_acc: 0.9095\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 141s - loss: 0.3551 - acc: 0.9051 - val_loss: 0.3663 - val_acc: 0.9083\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 141s - loss: 0.3547 - acc: 0.9058 - val_loss: 0.3649 - val_acc: 0.9111\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 141s - loss: 0.3594 - acc: 0.9032 - val_loss: 0.3629 - val_acc: 0.9106\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 141s - loss: 0.3580 - acc: 0.9045 - val_loss: 0.3613 - val_acc: 0.9108\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 141s - loss: 0.3604 - acc: 0.9038 - val_loss: 0.3606 - val_acc: 0.9102\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 141s - loss: 0.3585 - acc: 0.9043 - val_loss: 0.3623 - val_acc: 0.9118\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 141s - loss: 0.3598 - acc: 0.9038 - val_loss: 0.3612 - val_acc: 0.9112\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 141s - loss: 0.3564 - acc: 0.9042 - val_loss: 0.3606 - val_acc: 0.9125\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 141s - loss: 0.3553 - acc: 0.9072 - val_loss: 0.3595 - val_acc: 0.9095\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 141s - loss: 0.3546 - acc: 0.9051 - val_loss: 0.3622 - val_acc: 0.9094\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 141s - loss: 0.3621 - acc: 0.9028 - val_loss: 0.3600 - val_acc: 0.9092\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 141s - loss: 0.3568 - acc: 0.9042 - val_loss: 0.3586 - val_acc: 0.9117\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 141s - loss: 0.3572 - acc: 0.9047 - val_loss: 0.3602 - val_acc: 0.9101\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 141s - loss: 0.3544 - acc: 0.9043 - val_loss: 0.3610 - val_acc: 0.9102\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep200'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.35863410941301249, 0.36761078774871681, 0.36411287321239699, 0.36428461082095631, 0.36363602404530171, 0.36248967431086471, 0.36407770658671418, 0.35653694661947866, 0.36419756784628782, 0.36239192836323647, 0.35997956222473598, 0.35509070498766637, 0.35466437712479065, 0.35944894783229908, 0.35795885798714655, 0.36056737453558141, 0.35834044491514244, 0.35985855975707909, 0.35615672214619426, 0.35525705451417666, 0.35470440996201863, 0.36222093944600042, 0.35675454828117303, 0.35720475436327814, 0.35435940311396391], 'val_loss': [0.37081043334007263, 0.36676424188613893, 0.36388615217208864, 0.36536678619384766, 0.3658167081832886, 0.36255363192558288, 0.36480727949142455, 0.3637794457435608, 0.36316330881118775, 0.36566277966499328, 0.36372964625358584, 0.36629474325180056, 0.36488103117942811, 0.36294798626899721, 0.36126550855636597, 0.36062889738082887, 0.36230903615951537, 0.36115114951133725, 0.36058671202659609, 0.3595221517562866, 0.36215190916061402, 0.36000098295211791, 0.35859313983917235, 0.36020069017410278, 0.36096166076660158], 'acc': [0.90460737179487183, 0.90182868144356898, 0.90315206933564618, 0.90419473849239351, 0.90419473849239351, 0.90251042669233239, 0.90287135063856128, 0.90489653509168777, 0.90222970809085956, 0.90269088863676317, 0.90287135063856128, 0.90501684308013819, 0.90579884504331087, 0.90321222331074902, 0.90449550848264204, 0.90371350659595917, 0.90433509785049726, 0.90373355792736754, 0.90431504651908889, 0.90726259221700201, 0.90505694578119988, 0.90277109401976408, 0.90423484119345521, 0.90471607312813451, 0.90435514918190563], 'val_acc': [0.90920000000000001, 0.9093, 0.91069999999999995, 0.90890000000000004, 0.90949999999999998, 0.91080000000000005, 0.90910000000000002, 0.90959999999999996, 0.91020000000000001, 0.91010000000000002, 0.90949999999999998, 0.9083, 0.91110000000000002, 0.91059999999999997, 0.91080000000000005, 0.91020000000000001, 0.91180000000000005, 0.91120000000000001, 0.91249999999999998, 0.90949999999999998, 0.90939999999999999, 0.90920000000000001, 0.91169999999999995, 0.91010000000000002, 0.91020000000000001]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 142s - loss: 0.3585 - acc: 0.9044 - val_loss: 0.3611 - val_acc: 0.9106\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 141s - loss: 0.3534 - acc: 0.9056 - val_loss: 0.3593 - val_acc: 0.9109\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 141s - loss: 0.3536 - acc: 0.9043 - val_loss: 0.3586 - val_acc: 0.9097\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 141s - loss: 0.3513 - acc: 0.9065 - val_loss: 0.3586 - val_acc: 0.9103\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 141s - loss: 0.3530 - acc: 0.9058 - val_loss: 0.3583 - val_acc: 0.9108\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 141s - loss: 0.3495 - acc: 0.9067 - val_loss: 0.3596 - val_acc: 0.9109\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 141s - loss: 0.3540 - acc: 0.9056 - val_loss: 0.3587 - val_acc: 0.9110\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 141s - loss: 0.3560 - acc: 0.9044 - val_loss: 0.3576 - val_acc: 0.9108\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 141s - loss: 0.3486 - acc: 0.9074 - val_loss: 0.3590 - val_acc: 0.9119\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 141s - loss: 0.3482 - acc: 0.9067 - val_loss: 0.3601 - val_acc: 0.9117\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 141s - loss: 0.3492 - acc: 0.9052 - val_loss: 0.3589 - val_acc: 0.9117\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 141s - loss: 0.3495 - acc: 0.9070 - val_loss: 0.3586 - val_acc: 0.9119\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 141s - loss: 0.3514 - acc: 0.9055 - val_loss: 0.3590 - val_acc: 0.9112\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 141s - loss: 0.3541 - acc: 0.9060 - val_loss: 0.3597 - val_acc: 0.9107\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 141s - loss: 0.3584 - acc: 0.9034 - val_loss: 0.3585 - val_acc: 0.9109\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 141s - loss: 0.3535 - acc: 0.9048 - val_loss: 0.3589 - val_acc: 0.9118\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 141s - loss: 0.3521 - acc: 0.9057 - val_loss: 0.3575 - val_acc: 0.9119\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 141s - loss: 0.3528 - acc: 0.9066 - val_loss: 0.3587 - val_acc: 0.9116\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 141s - loss: 0.3468 - acc: 0.9076 - val_loss: 0.3605 - val_acc: 0.9107\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 141s - loss: 0.3470 - acc: 0.9067 - val_loss: 0.3583 - val_acc: 0.9113\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 141s - loss: 0.3488 - acc: 0.9064 - val_loss: 0.3590 - val_acc: 0.9113\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 141s - loss: 0.3523 - acc: 0.9062 - val_loss: 0.3589 - val_acc: 0.9110\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 141s - loss: 0.3503 - acc: 0.9065 - val_loss: 0.3580 - val_acc: 0.9113\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 141s - loss: 0.3535 - acc: 0.9036 - val_loss: 0.3588 - val_acc: 0.9110\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 141s - loss: 0.3484 - acc: 0.9053 - val_loss: 0.3603 - val_acc: 0.9115\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs, verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep225'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.35849674898080336, 0.35332353366733094, 0.35354996436025454, 0.35119763614276989, 0.35307955891037357, 0.34942077494677265, 0.3539578927645593, 0.35597149415355789, 0.34863466750095395, 0.34822655914492967, 0.34922413330526353, 0.34959173869887794, 0.35150743715457899, 0.35402944267159436, 0.35843517127655083, 0.35335460323380247, 0.35215127823786513, 0.35275647805254928, 0.34677800019849825, 0.34706804337010461, 0.34876875881013636, 0.3522931215451014, 0.35037970352161379, 0.35338714433894314, 0.34842204886978928], 'val_loss': [0.36114409170150757, 0.35927454557418825, 0.35855784831047061, 0.35858815083503726, 0.35833728528022768, 0.35958353538513183, 0.35866288299560545, 0.35761373586654666, 0.35901649770736693, 0.36012180533409116, 0.35891139965057373, 0.35857394495010375, 0.35903637375831604, 0.35974616384506225, 0.35852182936668398, 0.35892169294357301, 0.35746674070358275, 0.35871968293190004, 0.36049105806350706, 0.35830280680656434, 0.35899145426750184, 0.35893010625839233, 0.35801607751846315, 0.35875134344100951, 0.36031350617408753], 'acc': [0.90440705128205123, 0.90553817775412404, 0.90427494387539453, 0.90646053894154333, 0.90579884506243336, 0.90674125760038349, 0.90557828041694088, 0.90441530319525332, 0.90738290018633005, 0.9066811035870358, 0.90517725375052782, 0.90694177095271244, 0.90545797237112313, 0.9059993583382725, 0.90337263396201628, 0.90481632980429905, 0.90573869108733052, 0.90660089831876955, 0.90762351623972071, 0.90662094963105555, 0.90640038494731812, 0.90615976902778461, 0.90646053896066581, 0.90359319860750875, 0.90533766438267271], 'val_acc': [0.91059999999999997, 0.91090000000000004, 0.90969999999999995, 0.9103, 0.91080000000000005, 0.91090000000000004, 0.91100000000000003, 0.91080000000000005, 0.91190000000000004, 0.91169999999999995, 0.91169999999999995, 0.91190000000000004, 0.91120000000000001, 0.91069999999999995, 0.91090000000000004, 0.91180000000000005, 0.91190000000000004, 0.91159999999999997, 0.91069999999999995, 0.9113, 0.9113, 0.91100000000000003, 0.9113, 0.91100000000000003, 0.91149999999999998]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 143s - loss: 0.3481 - acc: 0.9054 - val_loss: 0.3575 - val_acc: 0.9116\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 141s - loss: 0.3516 - acc: 0.9066 - val_loss: 0.3583 - val_acc: 0.9113\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 141s - loss: 0.3495 - acc: 0.9055 - val_loss: 0.3574 - val_acc: 0.9123\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 141s - loss: 0.3476 - acc: 0.9056 - val_loss: 0.3587 - val_acc: 0.9119\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 141s - loss: 0.3493 - acc: 0.9067 - val_loss: 0.3570 - val_acc: 0.9119\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 141s - loss: 0.3493 - acc: 0.9069 - val_loss: 0.3577 - val_acc: 0.9127\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 141s - loss: 0.3463 - acc: 0.9068 - val_loss: 0.3579 - val_acc: 0.9122\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 141s - loss: 0.3513 - acc: 0.9059 - val_loss: 0.3580 - val_acc: 0.9127\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 141s - loss: 0.3534 - acc: 0.9034 - val_loss: 0.3559 - val_acc: 0.9114\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 141s - loss: 0.3466 - acc: 0.9079 - val_loss: 0.3574 - val_acc: 0.9118\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 141s - loss: 0.3448 - acc: 0.9072 - val_loss: 0.3572 - val_acc: 0.9116\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 141s - loss: 0.3488 - acc: 0.9080 - val_loss: 0.3577 - val_acc: 0.9120\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 141s - loss: 0.3431 - acc: 0.9079 - val_loss: 0.3567 - val_acc: 0.9114\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 141s - loss: 0.3491 - acc: 0.9060 - val_loss: 0.3584 - val_acc: 0.9116\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 141s - loss: 0.3474 - acc: 0.9066 - val_loss: 0.3583 - val_acc: 0.9116\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 141s - loss: 0.3466 - acc: 0.9072 - val_loss: 0.3566 - val_acc: 0.9120\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 141s - loss: 0.3461 - acc: 0.9061 - val_loss: 0.3570 - val_acc: 0.9121\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 141s - loss: 0.3446 - acc: 0.9067 - val_loss: 0.3579 - val_acc: 0.9113\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 141s - loss: 0.3447 - acc: 0.9079 - val_loss: 0.3587 - val_acc: 0.9117\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 141s - loss: 0.3497 - acc: 0.9062 - val_loss: 0.3579 - val_acc: 0.9120\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 141s - loss: 0.3469 - acc: 0.9070 - val_loss: 0.3575 - val_acc: 0.9115\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 141s - loss: 0.3464 - acc: 0.9068 - val_loss: 0.3578 - val_acc: 0.9116\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 141s - loss: 0.3479 - acc: 0.9068 - val_loss: 0.3572 - val_acc: 0.9119\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 141s - loss: 0.3445 - acc: 0.9074 - val_loss: 0.3571 - val_acc: 0.9112\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 141s - loss: 0.3473 - acc: 0.9055 - val_loss: 0.3571 - val_acc: 0.9117\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep250'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.34810607773371233, 0.35138586392033966, 0.34953483685798509, 0.34752439708712779, 0.34931986505762674, 0.34922149476233988, 0.34630748995764726, 0.35121101468925792, 0.35347617426896116, 0.34658742805761827, 0.34467299244783994, 0.34877391668669411, 0.34320509611106964, 0.34916385509166958, 0.34738369218653731, 0.34666278344490303, 0.34604907650614075, 0.34460145845067475, 0.34465208503348649, 0.34976887376904298, 0.34687432562612669, 0.34631407375629414, 0.34782490212641198, 0.344395155072174, 0.347328924486413], 'val_loss': [0.35749570937156677, 0.35832439503669739, 0.3574199802875519, 0.35866549687385557, 0.35695563735961916, 0.35765517764091492, 0.35791251111030581, 0.35802639589309693, 0.3559468081474304, 0.35741621446609495, 0.3571682225704193, 0.3576563786506653, 0.35665819444656371, 0.35839104590415954, 0.35833122329711914, 0.35664679379463193, 0.35700391139984133, 0.35787611017227172, 0.35865389232635497, 0.35792678694725039, 0.35745957026481628, 0.35780669312477109, 0.35723590245246889, 0.35713028674125669, 0.35709174952507017], 'acc': [0.90540865384615388, 0.90660089831876955, 0.9055782803978184, 0.90557828037869592, 0.90668110364440313, 0.9068816169011199, 0.90678136026320033, 0.90595925571370051, 0.90335258264973028, 0.90792428615347942, 0.90724254092383849, 0.90798444012858215, 0.90784408080872336, 0.90595925571370051, 0.90658084692999386, 0.9071823869104908, 0.90613971765813128, 0.90670115495668913, 0.90790423486031591, 0.9062199230411323, 0.90700192488957032, 0.90688161695848724, 0.90676130891266948, 0.9074029515368609, 0.90545797237112313], 'val_acc': [0.91159999999999997, 0.9113, 0.9123, 0.91190000000000004, 0.91190000000000004, 0.91269999999999996, 0.91220000000000001, 0.91269999999999996, 0.91139999999999999, 0.91180000000000005, 0.91159999999999997, 0.91200000000000003, 0.91139999999999999, 0.91159999999999997, 0.91159999999999997, 0.91200000000000003, 0.91210000000000002, 0.9113, 0.91169999999999995, 0.91200000000000003, 0.91149999999999998, 0.91159999999999997, 0.91190000000000004, 0.91120000000000001, 0.91169999999999995]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act, act_name = \"elu\", \"elu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.load_weights(\"models/cifar10_normal_rms_ep175elu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 145s - loss: 0.3245 - acc: 0.9141 - val_loss: 0.3557 - val_acc: 0.9091\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 144s - loss: 0.3215 - acc: 0.9135 - val_loss: 0.3539 - val_acc: 0.9103\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 144s - loss: 0.3265 - acc: 0.9144 - val_loss: 0.3530 - val_acc: 0.9104\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 144s - loss: 0.3226 - acc: 0.9141 - val_loss: 0.3528 - val_acc: 0.9094\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 144s - loss: 0.3218 - acc: 0.9145 - val_loss: 0.3534 - val_acc: 0.9099\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 144s - loss: 0.3268 - acc: 0.9121 - val_loss: 0.3545 - val_acc: 0.9087\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 144s - loss: 0.3227 - acc: 0.9139 - val_loss: 0.3533 - val_acc: 0.9112\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 144s - loss: 0.3209 - acc: 0.9141 - val_loss: 0.3541 - val_acc: 0.9084\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 144s - loss: 0.3249 - acc: 0.9128 - val_loss: 0.3526 - val_acc: 0.9090\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 144s - loss: 0.3230 - acc: 0.9144 - val_loss: 0.3549 - val_acc: 0.9093\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 144s - loss: 0.3202 - acc: 0.9136 - val_loss: 0.3547 - val_acc: 0.9086\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 144s - loss: 0.3192 - acc: 0.9154 - val_loss: 0.3531 - val_acc: 0.9098\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 147s - loss: 0.3214 - acc: 0.9145 - val_loss: 0.3548 - val_acc: 0.9108\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 146s - loss: 0.3256 - acc: 0.9135 - val_loss: 0.3566 - val_acc: 0.9085\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 145s - loss: 0.3207 - acc: 0.9149 - val_loss: 0.3539 - val_acc: 0.9092\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 145s - loss: 0.3191 - acc: 0.9155 - val_loss: 0.3552 - val_acc: 0.9083\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 145s - loss: 0.3190 - acc: 0.9155 - val_loss: 0.3542 - val_acc: 0.9089\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 145s - loss: 0.3161 - acc: 0.9160 - val_loss: 0.3526 - val_acc: 0.9088\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 145s - loss: 0.3181 - acc: 0.9147 - val_loss: 0.3548 - val_acc: 0.9085\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 145s - loss: 0.3217 - acc: 0.9139 - val_loss: 0.3510 - val_acc: 0.9099\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 145s - loss: 0.3185 - acc: 0.9158 - val_loss: 0.3515 - val_acc: 0.9096\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 144s - loss: 0.3151 - acc: 0.9162 - val_loss: 0.3532 - val_acc: 0.9089\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 144s - loss: 0.3177 - acc: 0.9134 - val_loss: 0.3541 - val_acc: 0.9100\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 144s - loss: 0.3189 - acc: 0.9161 - val_loss: 0.3520 - val_acc: 0.9094\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 144s - loss: 0.3226 - acc: 0.9134 - val_loss: 0.3517 - val_acc: 0.9094\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep200'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.32453279506701688, 0.32143914584819805, 0.32653529805788289, 0.32267823546197422, 0.32162800166405736, 0.32663138723732915, 0.32256662661080027, 0.32084873917204543, 0.32488743058756298, 0.32304859467335989, 0.32022138855416765, 0.31899666038506452, 0.32133641365747018, 0.32559632541737882, 0.3205411987576991, 0.3190436038712412, 0.31898388143223677, 0.31608372064290002, 0.31814502304396569, 0.32174669897896685, 0.31838298782844898, 0.31502851453736153, 0.31775641757821593, 0.31888222993663157, 0.32270030646244607], 'val_loss': [0.35574207878112796, 0.35390210909843445, 0.35298403992652894, 0.35280957531929014, 0.35342182736396788, 0.35454408106803892, 0.35326489195823668, 0.35409231400489805, 0.35258970160484315, 0.35486466403007505, 0.35472660508155823, 0.35305192379951478, 0.35479889755249022, 0.35658984661102294, 0.3539429906845093, 0.3552165518760681, 0.35418814134597776, 0.35262117938995363, 0.35476137390136719, 0.35101899428367617, 0.35145990695953372, 0.35315772123336792, 0.35413700752258298, 0.35198576135635373, 0.35173238482475283], 'acc': [0.91414262820512826, 0.91349855630413856, 0.9144008662366393, 0.91401989088251223, 0.91456127688790656, 0.91209496308642779, 0.91387953156265345, 0.91408004495322726, 0.91279675974308927, 0.9143808148478636, 0.91353865896695541, 0.91544353543163148, 0.91448107150490554, 0.9134785049727302, 0.91494225214642133, 0.91544353546987633, 0.91546358680128481, 0.91600497269194436, 0.91474173883233734, 0.91385948026948993, 0.91582451078575855, 0.91618543475110981, 0.91341835097850499, 0.91606512668616957, 0.9133381456528713], 'val_acc': [0.90910000000000002, 0.9103, 0.91039999999999999, 0.90939999999999999, 0.90990000000000004, 0.90869999999999995, 0.91120000000000001, 0.90839999999999999, 0.90900000000000003, 0.9093, 0.90859999999999996, 0.90980000000000005, 0.91080000000000005, 0.90849999999999997, 0.90920000000000001, 0.9083, 0.90890000000000004, 0.90880000000000005, 0.90849999999999997, 0.90990000000000004, 0.90959999999999996, 0.90890000000000004, 0.91000000000000003, 0.90939999999999999, 0.90939999999999999]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 145s - loss: 0.3157 - acc: 0.9162 - val_loss: 0.3518 - val_acc: 0.9090\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 144s - loss: 0.3162 - acc: 0.9152 - val_loss: 0.3495 - val_acc: 0.9104\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 144s - loss: 0.3138 - acc: 0.9150 - val_loss: 0.3508 - val_acc: 0.9100\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 144s - loss: 0.3129 - acc: 0.9178 - val_loss: 0.3496 - val_acc: 0.9099\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 144s - loss: 0.3170 - acc: 0.9164 - val_loss: 0.3502 - val_acc: 0.9105\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 144s - loss: 0.3093 - acc: 0.9180 - val_loss: 0.3503 - val_acc: 0.9089\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 144s - loss: 0.3199 - acc: 0.9139 - val_loss: 0.3489 - val_acc: 0.9100\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 144s - loss: 0.3114 - acc: 0.9164 - val_loss: 0.3507 - val_acc: 0.9095\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 144s - loss: 0.3111 - acc: 0.9181 - val_loss: 0.3495 - val_acc: 0.9098\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 144s - loss: 0.3124 - acc: 0.9177 - val_loss: 0.3495 - val_acc: 0.9107\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 145s - loss: 0.3175 - acc: 0.9147 - val_loss: 0.3501 - val_acc: 0.9099\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 145s - loss: 0.3148 - acc: 0.9158 - val_loss: 0.3504 - val_acc: 0.9094\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 145s - loss: 0.3155 - acc: 0.9162 - val_loss: 0.3502 - val_acc: 0.9095\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 145s - loss: 0.3116 - acc: 0.9179 - val_loss: 0.3490 - val_acc: 0.9094\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 144s - loss: 0.3168 - acc: 0.9165 - val_loss: 0.3491 - val_acc: 0.9094\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 144s - loss: 0.3127 - acc: 0.9166 - val_loss: 0.3493 - val_acc: 0.9107\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 144s - loss: 0.3147 - acc: 0.9170 - val_loss: 0.3485 - val_acc: 0.9112\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 144s - loss: 0.3119 - acc: 0.9163 - val_loss: 0.3507 - val_acc: 0.9092\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 144s - loss: 0.3132 - acc: 0.9166 - val_loss: 0.3490 - val_acc: 0.9095\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 144s - loss: 0.3141 - acc: 0.9154 - val_loss: 0.3491 - val_acc: 0.9104\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 144s - loss: 0.3094 - acc: 0.9184 - val_loss: 0.3491 - val_acc: 0.9101\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 144s - loss: 0.3151 - acc: 0.9159 - val_loss: 0.3494 - val_acc: 0.9102\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 144s - loss: 0.3142 - acc: 0.9160 - val_loss: 0.3491 - val_acc: 0.9092\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 144s - loss: 0.3153 - acc: 0.9165 - val_loss: 0.3496 - val_acc: 0.9098\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 144s - loss: 0.3106 - acc: 0.9158 - val_loss: 0.3475 - val_acc: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs, verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep225'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31567269575137358, 0.31610616589342128, 0.31383253281645029, 0.31289104146379138, 0.31712547025410531, 0.30917761073037525, 0.31997448344585566, 0.3113973187948979, 0.31114958067486442, 0.31237842230067103, 0.31740318178021454, 0.31489319615078004, 0.31540722306011043, 0.31165223067909009, 0.31678808028016442, 0.31276246912975819, 0.31472104319326766, 0.31192162030585346, 0.31321665008824567, 0.31405101575490407, 0.30944889153774863, 0.31516015072606257, 0.31423071257227464, 0.31529466786329507, 0.31068680791335496], 'val_loss': [0.35175775070190429, 0.34952708339691163, 0.35079614658355712, 0.34956477518081663, 0.35021549549102782, 0.35029060001373291, 0.34886617379188539, 0.35069285516738891, 0.34947038040161132, 0.34949517798423768, 0.35013490667343139, 0.35044514989852904, 0.3501631995201111, 0.34898224282264712, 0.34909034485816953, 0.349342809343338, 0.34851333103179932, 0.35065612058639528, 0.34896073918342591, 0.34914244742393491, 0.34912447052001955, 0.34942393922805787, 0.34909778461456298, 0.34955683803558352, 0.34747367076873781], 'acc': [0.91624599358974357, 0.91528312483773155, 0.91502245751029987, 0.91782964385010934, 0.91636589665729573, 0.91799005455874383, 0.91389958297055163, 0.91644610200205179, 0.91813041385948024, 0.91768928458761778, 0.91470163616952049, 0.91574430540275753, 0.91618543473198732, 0.91794995191504947, 0.91654635865909384, 0.91654635863997136, 0.91700753933885448, 0.91628569136990701, 0.91664661537350312, 0.91538338145652876, 0.91839108114866708, 0.91584456209804443, 0.91604507535476121, 0.91646615339082749, 0.91576435675328838], 'val_acc': [0.90900000000000003, 0.91039999999999999, 0.91000000000000003, 0.90990000000000004, 0.91049999999999998, 0.90890000000000004, 0.91000000000000003, 0.90949999999999998, 0.90980000000000005, 0.91069999999999995, 0.90990000000000004, 0.90939999999999999, 0.90949999999999998, 0.90939999999999999, 0.90939999999999999, 0.91069999999999995, 0.91120000000000001, 0.90920000000000001, 0.90949999999999998, 0.91039999999999999, 0.91010000000000002, 0.91020000000000001, 0.90920000000000001, 0.90980000000000005, 0.91110000000000002]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 145s - loss: 0.3133 - acc: 0.9165 - val_loss: 0.3478 - val_acc: 0.9108\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 144s - loss: 0.3123 - acc: 0.9167 - val_loss: 0.3475 - val_acc: 0.9105\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 144s - loss: 0.3107 - acc: 0.9173 - val_loss: 0.3488 - val_acc: 0.9106\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 144s - loss: 0.3095 - acc: 0.9172 - val_loss: 0.3479 - val_acc: 0.9104\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 144s - loss: 0.3082 - acc: 0.9182 - val_loss: 0.3476 - val_acc: 0.9114\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 144s - loss: 0.3111 - acc: 0.9171 - val_loss: 0.3480 - val_acc: 0.9111\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 144s - loss: 0.3134 - acc: 0.9158 - val_loss: 0.3468 - val_acc: 0.9111\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 144s - loss: 0.3119 - acc: 0.9178 - val_loss: 0.3465 - val_acc: 0.9125\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 144s - loss: 0.3145 - acc: 0.9159 - val_loss: 0.3467 - val_acc: 0.9107\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 144s - loss: 0.3112 - acc: 0.9173 - val_loss: 0.3473 - val_acc: 0.9096\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 144s - loss: 0.3126 - acc: 0.9167 - val_loss: 0.3473 - val_acc: 0.9110\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 144s - loss: 0.3075 - acc: 0.9185 - val_loss: 0.3472 - val_acc: 0.9109\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 144s - loss: 0.3080 - acc: 0.9184 - val_loss: 0.3481 - val_acc: 0.9118\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 144s - loss: 0.3081 - acc: 0.9181 - val_loss: 0.3476 - val_acc: 0.9120\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 144s - loss: 0.3078 - acc: 0.9184 - val_loss: 0.3481 - val_acc: 0.9115\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 144s - loss: 0.3067 - acc: 0.9182 - val_loss: 0.3479 - val_acc: 0.9109\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 144s - loss: 0.3085 - acc: 0.9180 - val_loss: 0.3482 - val_acc: 0.9114\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 144s - loss: 0.3130 - acc: 0.9169 - val_loss: 0.3488 - val_acc: 0.9099\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 144s - loss: 0.3100 - acc: 0.9172 - val_loss: 0.3486 - val_acc: 0.9096\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 144s - loss: 0.3084 - acc: 0.9186 - val_loss: 0.3478 - val_acc: 0.9110\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 144s - loss: 0.3068 - acc: 0.9179 - val_loss: 0.3476 - val_acc: 0.9104\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 144s - loss: 0.3085 - acc: 0.9170 - val_loss: 0.3485 - val_acc: 0.9101\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 144s - loss: 0.3076 - acc: 0.9175 - val_loss: 0.3477 - val_acc: 0.9100\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 144s - loss: 0.3102 - acc: 0.9166 - val_loss: 0.3485 - val_acc: 0.9100\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 144s - loss: 0.3103 - acc: 0.9177 - val_loss: 0.3477 - val_acc: 0.9105\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep250'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31327724972596538, 0.31235648829813834, 0.31088374752072062, 0.30938334914595417, 0.30824440700486949, 0.3111090928478657, 0.3133987674814101, 0.31196197519365088, 0.31460941669686238, 0.31123022855112176, 0.31260097204663639, 0.30757417979437762, 0.30799399973644748, 0.3081738044139396, 0.30791696369705346, 0.30665402527914087, 0.30848530747586805, 0.31305200927602506, 0.31009206495148883, 0.30851918168277515, 0.30688732810363883, 0.3085370226609313, 0.30765039821083362, 0.31033121158880111, 0.3101602103758363], 'val_loss': [0.34783371143341063, 0.34750686979293821, 0.34876850872039794, 0.34792288560867307, 0.34755793852806094, 0.34802917079925538, 0.3468428948402405, 0.34654914445877077, 0.34668494849205017, 0.34729678306579592, 0.34734247965812681, 0.34716258525848387, 0.348064603471756, 0.34761709947586061, 0.34810173788070681, 0.34786185646057127, 0.34821912465095523, 0.34883771495819094, 0.34855658164024356, 0.34784901890754699, 0.34764116630554198, 0.34852477560043332, 0.34770473804473878, 0.34852295165061953, 0.3477267735481262], 'acc': [0.91646634615384615, 0.91666666666666663, 0.91722810396522447, 0.91724815525838799, 0.91815046519088872, 0.91712784728905994, 0.91576435677241086, 0.91774943854359814, 0.91584456205979958, 0.91730830930998053, 0.91670676934860595, 0.91847128649342313, 0.91839108118691193, 0.91805020853384667, 0.91835097846672786, 0.91823067053564478, 0.91801010583278497, 0.91688723129303673, 0.91720805261469363, 0.91859159446275118, 0.91782964386923171, 0.9169874879309563, 0.91752887393635052, 0.91656640997137973, 0.91770933586165893], 'val_acc': [0.91080000000000005, 0.91049999999999998, 0.91059999999999997, 0.91039999999999999, 0.91139999999999999, 0.91110000000000002, 0.91110000000000002, 0.91249999999999998, 0.91069999999999995, 0.90959999999999996, 0.91100000000000003, 0.91090000000000004, 0.91180000000000005, 0.91200000000000003, 0.91149999999999998, 0.91090000000000004, 0.91139999999999999, 0.90990000000000004, 0.90959999999999996, 0.91100000000000003, 0.91039999999999999, 0.91010000000000002, 0.91000000000000003, 0.91000000000000003, 0.91049999999999998]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act, act_name = e_swish_1, \"e_swish_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "390/390 [==============================] - 161s - loss: 2.0026 - acc: 0.3992 - val_loss: 1.6780 - val_acc: 0.4448\n",
      "Epoch 2/75\n",
      "390/390 [==============================] - 159s - loss: 1.4469 - acc: 0.5484 - val_loss: 1.2390 - val_acc: 0.5980\n",
      "Epoch 3/75\n",
      "390/390 [==============================] - 159s - loss: 1.2738 - acc: 0.6046 - val_loss: 0.9542 - val_acc: 0.6945\n",
      "Epoch 4/75\n",
      "390/390 [==============================] - 159s - loss: 1.1172 - acc: 0.6430 - val_loss: 0.9364 - val_acc: 0.7268\n",
      "Epoch 5/75\n",
      "390/390 [==============================] - 159s - loss: 1.0373 - acc: 0.6752 - val_loss: 0.9232 - val_acc: 0.7215\n",
      "Epoch 6/75\n",
      "390/390 [==============================] - 159s - loss: 0.9766 - acc: 0.6940 - val_loss: 0.9129 - val_acc: 0.7504\n",
      "Epoch 7/75\n",
      "390/390 [==============================] - 159s - loss: 0.9340 - acc: 0.7095 - val_loss: 0.7632 - val_acc: 0.7738\n",
      "Epoch 8/75\n",
      "390/390 [==============================] - 159s - loss: 0.8966 - acc: 0.7262 - val_loss: 0.7136 - val_acc: 0.7866\n",
      "Epoch 9/75\n",
      "390/390 [==============================] - 159s - loss: 0.8712 - acc: 0.7334 - val_loss: 0.6977 - val_acc: 0.7961\n",
      "Epoch 10/75\n",
      "390/390 [==============================] - 159s - loss: 0.8524 - acc: 0.7449 - val_loss: 0.7042 - val_acc: 0.7918\n",
      "Epoch 11/75\n",
      "390/390 [==============================] - 160s - loss: 0.8260 - acc: 0.7519 - val_loss: 0.6506 - val_acc: 0.8057\n",
      "Epoch 12/75\n",
      "390/390 [==============================] - 162s - loss: 0.8067 - acc: 0.7586 - val_loss: 0.6923 - val_acc: 0.8008\n",
      "Epoch 13/75\n",
      "390/390 [==============================] - 161s - loss: 0.7994 - acc: 0.7630 - val_loss: 0.6424 - val_acc: 0.8156\n",
      "Epoch 14/75\n",
      "390/390 [==============================] - 161s - loss: 0.7815 - acc: 0.7706 - val_loss: 0.6243 - val_acc: 0.8217\n",
      "Epoch 15/75\n",
      "390/390 [==============================] - 161s - loss: 0.7693 - acc: 0.7742 - val_loss: 0.6337 - val_acc: 0.8266\n",
      "Epoch 16/75\n",
      "390/390 [==============================] - 161s - loss: 0.7552 - acc: 0.7813 - val_loss: 0.6237 - val_acc: 0.8203\n",
      "Epoch 17/75\n",
      "390/390 [==============================] - 161s - loss: 0.7507 - acc: 0.7829 - val_loss: 0.6336 - val_acc: 0.8276\n",
      "Epoch 18/75\n",
      "390/390 [==============================] - 161s - loss: 0.7433 - acc: 0.7869 - val_loss: 0.6350 - val_acc: 0.8187\n",
      "Epoch 19/75\n",
      "390/390 [==============================] - 161s - loss: 0.7315 - acc: 0.7887 - val_loss: 0.5887 - val_acc: 0.8387\n",
      "Epoch 20/75\n",
      "390/390 [==============================] - 161s - loss: 0.7192 - acc: 0.7939 - val_loss: 0.6015 - val_acc: 0.8325\n",
      "Epoch 21/75\n",
      "390/390 [==============================] - 161s - loss: 0.7181 - acc: 0.7957 - val_loss: 0.6114 - val_acc: 0.8315\n",
      "Epoch 22/75\n",
      "390/390 [==============================] - 161s - loss: 0.7085 - acc: 0.7998 - val_loss: 0.5779 - val_acc: 0.8453\n",
      "Epoch 23/75\n",
      "390/390 [==============================] - 162s - loss: 0.7004 - acc: 0.8026 - val_loss: 0.5759 - val_acc: 0.8460\n",
      "Epoch 24/75\n",
      "390/390 [==============================] - 162s - loss: 0.6959 - acc: 0.8032 - val_loss: 0.5751 - val_acc: 0.8448\n",
      "Epoch 25/75\n",
      "390/390 [==============================] - 162s - loss: 0.6943 - acc: 0.8035 - val_loss: 0.5929 - val_acc: 0.8420\n",
      "Epoch 26/75\n",
      "390/390 [==============================] - 163s - loss: 0.6875 - acc: 0.8066 - val_loss: 0.6127 - val_acc: 0.8342\n",
      "Epoch 27/75\n",
      "390/390 [==============================] - 162s - loss: 0.6763 - acc: 0.8108 - val_loss: 0.5532 - val_acc: 0.8545\n",
      "Epoch 28/75\n",
      "390/390 [==============================] - 160s - loss: 0.6823 - acc: 0.8099 - val_loss: 0.5834 - val_acc: 0.8421\n",
      "Epoch 29/75\n",
      "390/390 [==============================] - 160s - loss: 0.6619 - acc: 0.8149 - val_loss: 0.5505 - val_acc: 0.8520\n",
      "Epoch 30/75\n",
      "390/390 [==============================] - 161s - loss: 0.6672 - acc: 0.8146 - val_loss: 0.5715 - val_acc: 0.8491\n",
      "Epoch 31/75\n",
      "390/390 [==============================] - 161s - loss: 0.6618 - acc: 0.8159 - val_loss: 0.5607 - val_acc: 0.8503\n",
      "Epoch 32/75\n",
      "390/390 [==============================] - 161s - loss: 0.6516 - acc: 0.8180 - val_loss: 0.5583 - val_acc: 0.8523\n",
      "Epoch 33/75\n",
      "390/390 [==============================] - 161s - loss: 0.6523 - acc: 0.8194 - val_loss: 0.5810 - val_acc: 0.8453\n",
      "Epoch 34/75\n",
      "390/390 [==============================] - 161s - loss: 0.6446 - acc: 0.8208 - val_loss: 0.5472 - val_acc: 0.8574\n",
      "Epoch 35/75\n",
      "390/390 [==============================] - 161s - loss: 0.6493 - acc: 0.8207 - val_loss: 0.5706 - val_acc: 0.8538\n",
      "Epoch 36/75\n",
      "390/390 [==============================] - 160s - loss: 0.6369 - acc: 0.8239 - val_loss: 0.5893 - val_acc: 0.8468\n",
      "Epoch 37/75\n",
      "390/390 [==============================] - 160s - loss: 0.6381 - acc: 0.8261 - val_loss: 0.5617 - val_acc: 0.8523\n",
      "Epoch 38/75\n",
      "390/390 [==============================] - 160s - loss: 0.6357 - acc: 0.8256 - val_loss: 0.5630 - val_acc: 0.8492\n",
      "Epoch 39/75\n",
      "390/390 [==============================] - 160s - loss: 0.6344 - acc: 0.8264 - val_loss: 0.5449 - val_acc: 0.8590\n",
      "Epoch 40/75\n",
      "390/390 [==============================] - 159s - loss: 0.6283 - acc: 0.8291 - val_loss: 0.5355 - val_acc: 0.8617\n",
      "Epoch 41/75\n",
      "390/390 [==============================] - 160s - loss: 0.6248 - acc: 0.8303 - val_loss: 0.5293 - val_acc: 0.8599\n",
      "Epoch 42/75\n",
      "390/390 [==============================] - 160s - loss: 0.6227 - acc: 0.8298 - val_loss: 0.5394 - val_acc: 0.8621\n",
      "Epoch 43/75\n",
      "390/390 [==============================] - 160s - loss: 0.6064 - acc: 0.8358 - val_loss: 0.5503 - val_acc: 0.8579\n",
      "Epoch 44/75\n",
      "390/390 [==============================] - 160s - loss: 0.6175 - acc: 0.8319 - val_loss: 0.5818 - val_acc: 0.8500\n",
      "Epoch 45/75\n",
      "390/390 [==============================] - 159s - loss: 0.6120 - acc: 0.8350 - val_loss: 0.5217 - val_acc: 0.8668\n",
      "Epoch 46/75\n",
      "390/390 [==============================] - 159s - loss: 0.6100 - acc: 0.8336 - val_loss: 0.5316 - val_acc: 0.8661\n",
      "Epoch 47/75\n",
      "390/390 [==============================] - 160s - loss: 0.6009 - acc: 0.8390 - val_loss: 0.5671 - val_acc: 0.8525\n",
      "Epoch 48/75\n",
      "390/390 [==============================] - 160s - loss: 0.6131 - acc: 0.8354 - val_loss: 0.5127 - val_acc: 0.8697\n",
      "Epoch 49/75\n",
      "390/390 [==============================] - 160s - loss: 0.5992 - acc: 0.8383 - val_loss: 0.5071 - val_acc: 0.8681\n",
      "Epoch 50/75\n",
      "390/390 [==============================] - 160s - loss: 0.5931 - acc: 0.8419 - val_loss: 0.5307 - val_acc: 0.8658\n",
      "Epoch 51/75\n",
      "390/390 [==============================] - 159s - loss: 0.6031 - acc: 0.8389 - val_loss: 0.5177 - val_acc: 0.8701\n",
      "Epoch 52/75\n",
      "390/390 [==============================] - 159s - loss: 0.5992 - acc: 0.8407 - val_loss: 0.5057 - val_acc: 0.8718\n",
      "Epoch 53/75\n",
      "390/390 [==============================] - 159s - loss: 0.5961 - acc: 0.8393 - val_loss: 0.5355 - val_acc: 0.8636\n",
      "Epoch 54/75\n",
      "390/390 [==============================] - 159s - loss: 0.5928 - acc: 0.8414 - val_loss: 0.5257 - val_acc: 0.8685\n",
      "Epoch 55/75\n",
      "390/390 [==============================] - 160s - loss: 0.5920 - acc: 0.8421 - val_loss: 0.5167 - val_acc: 0.8676\n",
      "Epoch 56/75\n",
      "390/390 [==============================] - 161s - loss: 0.5806 - acc: 0.8456 - val_loss: 0.5163 - val_acc: 0.8757\n",
      "Epoch 57/75\n",
      "390/390 [==============================] - 160s - loss: 0.5873 - acc: 0.8412 - val_loss: 0.5154 - val_acc: 0.8743\n",
      "Epoch 58/75\n",
      "390/390 [==============================] - 160s - loss: 0.5865 - acc: 0.8435 - val_loss: 0.5208 - val_acc: 0.8694\n",
      "Epoch 59/75\n",
      "390/390 [==============================] - 160s - loss: 0.5774 - acc: 0.8477 - val_loss: 0.5059 - val_acc: 0.8718\n",
      "Epoch 60/75\n",
      "390/390 [==============================] - 160s - loss: 0.5784 - acc: 0.8443 - val_loss: 0.5281 - val_acc: 0.8683\n",
      "Epoch 61/75\n",
      "390/390 [==============================] - 159s - loss: 0.5796 - acc: 0.8455 - val_loss: 0.5246 - val_acc: 0.8722\n",
      "Epoch 62/75\n",
      "390/390 [==============================] - 159s - loss: 0.5802 - acc: 0.8465 - val_loss: 0.5237 - val_acc: 0.8713\n",
      "Epoch 63/75\n",
      "390/390 [==============================] - 159s - loss: 0.5717 - acc: 0.8485 - val_loss: 0.4925 - val_acc: 0.8764\n",
      "Epoch 64/75\n",
      "390/390 [==============================] - 159s - loss: 0.5716 - acc: 0.8501 - val_loss: 0.5139 - val_acc: 0.8696\n",
      "Epoch 65/75\n",
      "390/390 [==============================] - 159s - loss: 0.5698 - acc: 0.8511 - val_loss: 0.5137 - val_acc: 0.8733\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 159s - loss: 0.5794 - acc: 0.8472 - val_loss: 0.5085 - val_acc: 0.8760\n",
      "Epoch 67/75\n",
      "390/390 [==============================] - 160s - loss: 0.5703 - acc: 0.8505 - val_loss: 0.5166 - val_acc: 0.8716\n",
      "Epoch 68/75\n",
      "390/390 [==============================] - 160s - loss: 0.5718 - acc: 0.8492 - val_loss: 0.5035 - val_acc: 0.8746\n",
      "Epoch 69/75\n",
      "390/390 [==============================] - 160s - loss: 0.5690 - acc: 0.8501 - val_loss: 0.5000 - val_acc: 0.8758\n",
      "Epoch 70/75\n",
      "390/390 [==============================] - 160s - loss: 0.5701 - acc: 0.8492 - val_loss: 0.4895 - val_acc: 0.8783\n",
      "Epoch 71/75\n",
      "390/390 [==============================] - 160s - loss: 0.5651 - acc: 0.8525 - val_loss: 0.5021 - val_acc: 0.8761\n",
      "Epoch 72/75\n",
      "390/390 [==============================] - 159s - loss: 0.5690 - acc: 0.8497 - val_loss: 0.5026 - val_acc: 0.8782\n",
      "Epoch 73/75\n",
      "390/390 [==============================] - 159s - loss: 0.5629 - acc: 0.8514 - val_loss: 0.5073 - val_acc: 0.8746\n",
      "Epoch 74/75\n",
      "390/390 [==============================] - 159s - loss: 0.5600 - acc: 0.8544 - val_loss: 0.4933 - val_acc: 0.8804\n",
      "Epoch 75/75\n",
      "390/390 [==============================] - 159s - loss: 0.5669 - acc: 0.8498 - val_loss: 0.4865 - val_acc: 0.8812\n"
     ]
    }
   ],
   "source": [
    "# base training - 75 epochs\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep75'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.0025512921504487, 1.4468085432725721, 1.2735727691176155, 1.1172772817096153, 1.0372710350732373, 0.97672150943537039, 0.93383220020761692, 0.89651614551862391, 0.87114763410954965, 0.85255599683548033, 0.82612638829953022, 0.80652536044030532, 0.79914372633541475, 0.78142167112939742, 0.76909248980720113, 0.75534605694995083, 0.75080872457838987, 0.74337255622011977, 0.73148993739035406, 0.71922760827058696, 0.71821627379381625, 0.70840981330173991, 0.7002397224732535, 0.69560575676453895, 0.69419094557788152, 0.68732237620808045, 0.67625069392580306, 0.68219177333598036, 0.6617900851371773, 0.66709118123462963, 0.66192576810263426, 0.65153616209767518, 0.65225723549307713, 0.64457780832199474, 0.64941945170071169, 0.63671718674054845, 0.63807477375846822, 0.63574505334180409, 0.63439963058588555, 0.62817887189795962, 0.62475359212292825, 0.62275097796195666, 0.60642422937910867, 0.61754742923515671, 0.61201296896363899, 0.61000802373901408, 0.60082725701058259, 0.61295316500047248, 0.59891823137804678, 0.59274949161601742, 0.60312710888385013, 0.59930142013545518, 0.59584361603522396, 0.59266224529332445, 0.59214559485218565, 0.58054223464473842, 0.58706749143377113, 0.58642204610208382, 0.57727175660342944, 0.57838515046700711, 0.5796395660613185, 0.58011488995568894, 0.57172173946225802, 0.57161947269259183, 0.56990921210508372, 0.57920221533574923, 0.57039633185809191, 0.57158411306412438, 0.56904649065211677, 0.5701813166211116, 0.56507575921152586, 0.56895348990923478, 0.56280959681283593, 0.55988192950298588, 0.56685322219070278], 'val_loss': [1.6780370447158814, 1.2389696942329407, 0.95424341382980349, 0.93642364606857298, 0.92321211090087896, 0.91290112915039068, 0.76324764995574956, 0.71360006027221679, 0.69769714784622194, 0.70421283626556397, 0.6505715238571167, 0.69231306457519526, 0.64235121326446531, 0.62425426397323613, 0.63371207180023192, 0.62365421943664556, 0.63361712808609005, 0.63502542839050291, 0.58873670768737796, 0.6014718441963196, 0.61141478080749512, 0.57788600778579713, 0.57592038774490362, 0.57509764995574952, 0.59289815483093267, 0.61266049327850347, 0.55317879629135136, 0.58340612945556636, 0.55051357669830325, 0.57154502096176152, 0.56065460276603696, 0.55828430242538452, 0.58095600633621214, 0.54720828762054441, 0.57057454352378845, 0.58929554071426393, 0.56174131584167486, 0.56295016279220578, 0.54490003738403325, 0.5354539529800415, 0.52925692396163937, 0.53937937707900996, 0.55029439306259154, 0.5817741934776306, 0.52169670763015752, 0.53162638001441953, 0.56712780423164366, 0.5126879315853119, 0.50707374343872069, 0.53069805803298953, 0.51765267009735105, 0.50569734873771666, 0.53547146701812742, 0.52573599281311034, 0.51674550266265873, 0.51630704779624936, 0.51537777051925659, 0.52078448352813722, 0.50592292017936702, 0.52808889021873473, 0.52461012630462645, 0.5236543024539948, 0.49254885244369506, 0.51391860857009886, 0.51367460379600527, 0.50854759211540224, 0.51663432083129879, 0.50348146700859064, 0.49997851390838621, 0.48945653944015505, 0.50211766948699954, 0.5026446436405182, 0.50732063035964969, 0.49326536064147947, 0.48654032526016233], 'acc': [0.39915865384615384, 0.54842396533217685, 0.6046278473273049, 0.64298604423509487, 0.67522858519717821, 0.6939565286752617, 0.70949631057414331, 0.72621912094963104, 0.73337744628155421, 0.74486685915944817, 0.75182467119640983, 0.75862207246736946, 0.76307346805915799, 0.77059271735643242, 0.7742621110424156, 0.78121992296464249, 0.78288418350978506, 0.78689444977234368, 0.78877927496297873, 0.79387231310246886, 0.79569698429887858, 0.79976740453654005, 0.80267484760988128, 0.80323628485107179, 0.80355710623009602, 0.80668511387243991, 0.81079563684940792, 0.80995348093025499, 0.81494626243182544, 0.81454523576541249, 0.81580846968238696, 0.81799406480590309, 0.81939765796624664, 0.82078119987167153, 0.82062078922040427, 0.82396936152736311, 0.82613490535771572, 0.82559351937144387, 0.82639557266602504, 0.829162656400385, 0.83028553094013324, 0.82978424765492309, 0.83579964711568966, 0.83190968876509164, 0.83501764517163934, 0.8336140520112959, 0.8390479628038513, 0.83541867181892993, 0.83830606356086279, 0.84199550846351967, 0.83894770608944202, 0.84073227458479005, 0.83940888676920267, 0.841474173885146, 0.84209576512056161, 0.84566490213038026, 0.84129371186422541, 0.84357956366390607, 0.84777029194738529, 0.84426130891266948, 0.84552454284876633, 0.84648700673724731, 0.84853224252178228, 0.8500360923965351, 0.85111886431171146, 0.84724895731164429, 0.85047722170664253, 0.84923403910195405, 0.85003609235829025, 0.84919393643913721, 0.85248235486660551, 0.84967516843118385, 0.85139958295142915, 0.85450753933885448, 0.84977542504998094], 'val_acc': [0.44479999999999997, 0.59799999999999998, 0.69450000000000001, 0.7268, 0.72150000000000003, 0.75039999999999996, 0.77380000000000004, 0.78659999999999997, 0.79610000000000003, 0.79179999999999995, 0.80569999999999997, 0.80079999999999996, 0.81559999999999999, 0.82169999999999999, 0.8266, 0.82030000000000003, 0.8276, 0.81869999999999998, 0.8387, 0.83250000000000002, 0.83150000000000002, 0.84530000000000005, 0.84599999999999997, 0.8448, 0.84199999999999997, 0.83420000000000005, 0.85450000000000004, 0.84209999999999996, 0.85199999999999998, 0.84909999999999997, 0.85029999999999994, 0.85229999999999995, 0.84530000000000005, 0.85740000000000005, 0.8538, 0.8468, 0.85229999999999995, 0.84919999999999995, 0.85899999999999999, 0.86170000000000002, 0.8599, 0.86209999999999998, 0.8579, 0.84999999999999998, 0.86680000000000001, 0.86609999999999998, 0.85250000000000004, 0.86970000000000003, 0.86809999999999998, 0.86580000000000001, 0.87009999999999998, 0.87180000000000002, 0.86360000000000003, 0.86850000000000005, 0.86760000000000004, 0.87570000000000003, 0.87429999999999997, 0.86939999999999995, 0.87180000000000002, 0.86829999999999996, 0.87219999999999998, 0.87129999999999996, 0.87639999999999996, 0.86960000000000004, 0.87329999999999997, 0.876, 0.87160000000000004, 0.87460000000000004, 0.87580000000000002, 0.87829999999999997, 0.87609999999999999, 0.87819999999999998, 0.87460000000000004, 0.88039999999999996, 0.88119999999999998]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 161s - loss: 0.5305 - acc: 0.8628 - val_loss: 0.4562 - val_acc: 0.8876\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 159s - loss: 0.5111 - acc: 0.8705 - val_loss: 0.4574 - val_acc: 0.8906\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 159s - loss: 0.5032 - acc: 0.8705 - val_loss: 0.4713 - val_acc: 0.8843\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 159s - loss: 0.5032 - acc: 0.8698 - val_loss: 0.4496 - val_acc: 0.8913\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 159s - loss: 0.4939 - acc: 0.8724 - val_loss: 0.4469 - val_acc: 0.8932\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 159s - loss: 0.4979 - acc: 0.8712 - val_loss: 0.4557 - val_acc: 0.8895\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 161s - loss: 0.4883 - acc: 0.8744 - val_loss: 0.4475 - val_acc: 0.8918\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 161s - loss: 0.4878 - acc: 0.8716 - val_loss: 0.4431 - val_acc: 0.8930\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 161s - loss: 0.4842 - acc: 0.8743 - val_loss: 0.4429 - val_acc: 0.8929\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 161s - loss: 0.4813 - acc: 0.8745 - val_loss: 0.4514 - val_acc: 0.8908\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 161s - loss: 0.4767 - acc: 0.8757 - val_loss: 0.4396 - val_acc: 0.8940\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 161s - loss: 0.4797 - acc: 0.8752 - val_loss: 0.4472 - val_acc: 0.8901\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 161s - loss: 0.4775 - acc: 0.8747 - val_loss: 0.4397 - val_acc: 0.8923\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 161s - loss: 0.4767 - acc: 0.8753 - val_loss: 0.4320 - val_acc: 0.8949\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 161s - loss: 0.4701 - acc: 0.8761 - val_loss: 0.4479 - val_acc: 0.8905\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 161s - loss: 0.4720 - acc: 0.8768 - val_loss: 0.4553 - val_acc: 0.8888\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 161s - loss: 0.4649 - acc: 0.8776 - val_loss: 0.4298 - val_acc: 0.8966\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 161s - loss: 0.4668 - acc: 0.8780 - val_loss: 0.4379 - val_acc: 0.8928\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 161s - loss: 0.4610 - acc: 0.8807 - val_loss: 0.4431 - val_acc: 0.8921\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 161s - loss: 0.4679 - acc: 0.8773 - val_loss: 0.4501 - val_acc: 0.8872\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 161s - loss: 0.4616 - acc: 0.8793 - val_loss: 0.4452 - val_acc: 0.8875\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 161s - loss: 0.4602 - acc: 0.8801 - val_loss: 0.4323 - val_acc: 0.8954\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 161s - loss: 0.4609 - acc: 0.8805 - val_loss: 0.4286 - val_acc: 0.8959\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 159s - loss: 0.4582 - acc: 0.8795 - val_loss: 0.4365 - val_acc: 0.8944\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 159s - loss: 0.4595 - acc: 0.8787 - val_loss: 0.4309 - val_acc: 0.8936\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep100'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.53048112736298492, 0.51091599294226786, 0.50320446814410691, 0.5032598779566364, 0.4941398198974794, 0.49801863459849305, 0.48830298856163695, 0.48762691617585696, 0.48406488703426964, 0.48134286069204535, 0.47664637270362326, 0.47964654754360864, 0.47755852684899708, 0.47657968854919475, 0.47012740809603076, 0.47202705009877777, 0.46484677107777012, 0.4667797349835574, 0.46116171196404276, 0.46791649528294754, 0.46165211240106335, 0.46028906480792547, 0.46091995904336269, 0.45825845074837201, 0.45956500749921508], 'val_loss': [0.45620483751296997, 0.45741837320327761, 0.47128963093757631, 0.44961042013168334, 0.44692125887870787, 0.45565793075561523, 0.44753099231719973, 0.44307440986633301, 0.44291640605926513, 0.45135731148719788, 0.4395730016708374, 0.44722178659439088, 0.43972713618278503, 0.43198130593299866, 0.44787837266921998, 0.45526764335632325, 0.42976857433319093, 0.43794561543464661, 0.44309654345512389, 0.4501353632926941, 0.44519206099510195, 0.43234820895195009, 0.4286088207244873, 0.43648549537658693, 0.43086716551780702], 'acc': [0.86278044871794868, 0.87052855305768073, 0.87046839910170037, 0.8697666025215286, 0.87233317290355961, 0.87119024699415804, 0.87437840870721695, 0.87173163296130751, 0.87435835739493106, 0.87443856268231979, 0.87564164256682409, 0.87524061599602332, 0.8746390760728936, 0.87528071863971768, 0.87608277189605388, 0.87674446587077615, 0.87762672443362355, 0.87802775108091413, 0.88071462941315071, 0.87730590313108903, 0.87921077961488758, 0.88005293547667329, 0.88047401347449472, 0.87953160089829963, 0.87864934229720737], 'val_acc': [0.88759999999999994, 0.89059999999999995, 0.88429999999999997, 0.89129999999999998, 0.89319999999999999, 0.88949999999999996, 0.89180000000000004, 0.89300000000000002, 0.89290000000000003, 0.89080000000000004, 0.89400000000000002, 0.8901, 0.89229999999999998, 0.89490000000000003, 0.89049999999999996, 0.88880000000000003, 0.89659999999999995, 0.89280000000000004, 0.8921, 0.88719999999999999, 0.88749999999999996, 0.89539999999999997, 0.89590000000000003, 0.89439999999999997, 0.89359999999999995]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 161s - loss: 0.4403 - acc: 0.8845 - val_loss: 0.4210 - val_acc: 0.8970\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 159s - loss: 0.4356 - acc: 0.8864 - val_loss: 0.4134 - val_acc: 0.9022\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 159s - loss: 0.4325 - acc: 0.8883 - val_loss: 0.4108 - val_acc: 0.9002\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 159s - loss: 0.4286 - acc: 0.8887 - val_loss: 0.4069 - val_acc: 0.8999\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 159s - loss: 0.4250 - acc: 0.8880 - val_loss: 0.4054 - val_acc: 0.9019\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 159s - loss: 0.4263 - acc: 0.8878 - val_loss: 0.4031 - val_acc: 0.9015\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 159s - loss: 0.4221 - acc: 0.8899 - val_loss: 0.4145 - val_acc: 0.8987\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 159s - loss: 0.4184 - acc: 0.8900 - val_loss: 0.4081 - val_acc: 0.9004\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 159s - loss: 0.4230 - acc: 0.8892 - val_loss: 0.4038 - val_acc: 0.8996\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 159s - loss: 0.4243 - acc: 0.8884 - val_loss: 0.4035 - val_acc: 0.9023\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 159s - loss: 0.4148 - acc: 0.8909 - val_loss: 0.4066 - val_acc: 0.9005\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 159s - loss: 0.4154 - acc: 0.8911 - val_loss: 0.4107 - val_acc: 0.8957\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 159s - loss: 0.4174 - acc: 0.8908 - val_loss: 0.4051 - val_acc: 0.9003\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 159s - loss: 0.4110 - acc: 0.8931 - val_loss: 0.4025 - val_acc: 0.9035\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 159s - loss: 0.4094 - acc: 0.8923 - val_loss: 0.3940 - val_acc: 0.9025\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 159s - loss: 0.4148 - acc: 0.8915 - val_loss: 0.4080 - val_acc: 0.8994\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 159s - loss: 0.4104 - acc: 0.8908 - val_loss: 0.4120 - val_acc: 0.8998\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 159s - loss: 0.4034 - acc: 0.8945 - val_loss: 0.3979 - val_acc: 0.9009\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 159s - loss: 0.4037 - acc: 0.8951 - val_loss: 0.4034 - val_acc: 0.9024\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 159s - loss: 0.4070 - acc: 0.8938 - val_loss: 0.3983 - val_acc: 0.9018\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 159s - loss: 0.4054 - acc: 0.8935 - val_loss: 0.3966 - val_acc: 0.8996\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 159s - loss: 0.4072 - acc: 0.8916 - val_loss: 0.4033 - val_acc: 0.8989\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 159s - loss: 0.4023 - acc: 0.8932 - val_loss: 0.4020 - val_acc: 0.9027\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 159s - loss: 0.4015 - acc: 0.8947 - val_loss: 0.3968 - val_acc: 0.9035\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 159s - loss: 0.4031 - acc: 0.8944 - val_loss: 0.3999 - val_acc: 0.9006\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.0003,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep125'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.44029840735288767, 0.43562102426807964, 0.43246958729621882, 0.42862772634674196, 0.42495228905191318, 0.42613890779527058, 0.42214868573145031, 0.41851825902658585, 0.4231682639589362, 0.42437181577569288, 0.41473161117710056, 0.41547532925094821, 0.41754555127580156, 0.41102939958866108, 0.40935849812614411, 0.41486979109337591, 0.41038175964148949, 0.40333300849012277, 0.40374210103987729, 0.40698102581260065, 0.40549364876280541, 0.40708354034215777, 0.40218844092882783, 0.40145317916117457, 0.40307501446064903], 'val_loss': [0.4210063179016113, 0.41337136611938474, 0.41083007926940918, 0.40690023145675658, 0.40541804101467133, 0.40311455712318423, 0.41452232890129087, 0.40812996606826785, 0.40384225339889529, 0.40353257050514219, 0.40660450654029845, 0.41071225690841673, 0.40513712339401248, 0.40245116968154909, 0.39395373163223268, 0.40801755285263064, 0.41204224195480349, 0.39788528561592101, 0.4034394338607788, 0.39827035884857176, 0.39661533632278445, 0.40326807947158816, 0.40197296605110167, 0.3967583983898163, 0.39986222100257873], 'acc': [0.88445512820512817, 0.88636910490856591, 0.88831408409342616, 0.88865495672736905, 0.88801331410317763, 0.88781280073172619, 0.88995829323067055, 0.88997834456207892, 0.88909608596098666, 0.88841434075046821, 0.89088065445633469, 0.89110121914007212, 0.89078039781841512, 0.89306624961809578, 0.89230429898633157, 0.89148219441770937, 0.89078039778017026, 0.89450994547950102, 0.89503128009611954, 0.89380814882283954, 0.89348732759679472, 0.89164260503073167, 0.89332691694552757, 0.89465030474199247, 0.89440968878421412], 'val_acc': [0.89700000000000002, 0.9022, 0.9002, 0.89990000000000003, 0.90190000000000003, 0.90149999999999997, 0.89870000000000005, 0.90039999999999998, 0.89959999999999996, 0.90229999999999999, 0.90049999999999997, 0.89570000000000005, 0.90029999999999999, 0.90349999999999997, 0.90249999999999997, 0.89939999999999998, 0.89980000000000004, 0.90090000000000003, 0.90239999999999998, 0.90180000000000005, 0.89959999999999996, 0.89890000000000003, 0.90269999999999995, 0.90349999999999997, 0.90059999999999996]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 161s - loss: 0.3917 - acc: 0.8972 - val_loss: 0.3877 - val_acc: 0.9042\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 159s - loss: 0.3831 - acc: 0.8995 - val_loss: 0.3929 - val_acc: 0.9037\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 159s - loss: 0.3815 - acc: 0.9003 - val_loss: 0.3819 - val_acc: 0.9065\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 159s - loss: 0.3813 - acc: 0.8991 - val_loss: 0.3860 - val_acc: 0.9049\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 159s - loss: 0.3838 - acc: 0.8988 - val_loss: 0.3810 - val_acc: 0.9065\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 159s - loss: 0.3790 - acc: 0.9005 - val_loss: 0.3804 - val_acc: 0.9067\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 159s - loss: 0.3795 - acc: 0.9001 - val_loss: 0.3826 - val_acc: 0.9063\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 159s - loss: 0.3739 - acc: 0.9011 - val_loss: 0.3861 - val_acc: 0.9051\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 159s - loss: 0.3694 - acc: 0.9036 - val_loss: 0.3836 - val_acc: 0.9075\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 162s - loss: 0.3769 - acc: 0.9010 - val_loss: 0.3892 - val_acc: 0.9055\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 162s - loss: 0.3709 - acc: 0.9037 - val_loss: 0.3823 - val_acc: 0.9083\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 162s - loss: 0.3696 - acc: 0.9023 - val_loss: 0.3854 - val_acc: 0.9075\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 161s - loss: 0.3677 - acc: 0.9030 - val_loss: 0.3772 - val_acc: 0.9081\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 161s - loss: 0.3675 - acc: 0.9039 - val_loss: 0.3838 - val_acc: 0.9060\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 161s - loss: 0.3637 - acc: 0.9055 - val_loss: 0.3787 - val_acc: 0.9080\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 162s - loss: 0.3724 - acc: 0.9005 - val_loss: 0.3845 - val_acc: 0.9057\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 165s - loss: 0.3600 - acc: 0.9061 - val_loss: 0.3778 - val_acc: 0.9058\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 162s - loss: 0.3629 - acc: 0.9035 - val_loss: 0.3822 - val_acc: 0.9072\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 161s - loss: 0.3622 - acc: 0.9045 - val_loss: 0.3788 - val_acc: 0.9054\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 160s - loss: 0.3574 - acc: 0.9068 - val_loss: 0.3812 - val_acc: 0.9057\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 161s - loss: 0.3666 - acc: 0.9034 - val_loss: 0.3772 - val_acc: 0.9058\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 160s - loss: 0.3617 - acc: 0.9048 - val_loss: 0.3761 - val_acc: 0.9083\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 160s - loss: 0.3601 - acc: 0.9053 - val_loss: 0.3789 - val_acc: 0.9074\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 160s - loss: 0.3627 - acc: 0.9033 - val_loss: 0.3788 - val_acc: 0.9091\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 162s - loss: 0.3585 - acc: 0.9040 - val_loss: 0.3817 - val_acc: 0.9051\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.00015,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep150'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.3916871460966575, 0.3830860229994878, 0.38143821570748582, 0.38133902527944069, 0.38392718473343579, 0.37888510880425913, 0.37949750278674527, 0.37387508421629562, 0.36926520966473858, 0.37692043327696245, 0.37074656615778923, 0.36962512105865897, 0.36777235572828404, 0.36754534033808067, 0.36377019132793736, 0.37250135467532053, 0.35994032432645184, 0.36272934257965039, 0.36217946858217903, 0.35740000111841796, 0.36656409209456092, 0.36170388424974015, 0.36002646275235173, 0.36280184214050892, 0.35844912513120075], 'val_loss': [0.38774400386810304, 0.39290361790657041, 0.38194265713691711, 0.38598793540000914, 0.38104903764724729, 0.38040173792839049, 0.38255194773674012, 0.38610123605728147, 0.38362138419151304, 0.38921717071533202, 0.38230101776123049, 0.38543901891708376, 0.37719017407894134, 0.38382796659469604, 0.37873851175308226, 0.38448255724906921, 0.37778724961280824, 0.38222026104927065, 0.37878373019695283, 0.3811969529390335, 0.37719208648204805, 0.37605884828567504, 0.37893917355537415, 0.37881105639934542, 0.38171985723972318], 'acc': [0.89721554487179489, 0.89950272694282662, 0.90030478023740779, 0.89912175172255671, 0.89874077634930727, 0.90056544756483947, 0.90010426690420131, 0.90108678212409066, 0.90369345522630584, 0.90098652548617109, 0.90383381456528711, 0.90228986200859507, 0.90299165868437903, 0.90391401985267583, 0.90543792111620447, 0.90042508820673572, 0.90609961497619207, 0.90357314721873294, 0.90451555981405052, 0.9068014115946087, 0.90345283926852749, 0.90479627851113553, 0.90533766442091756, 0.90329242859813774, 0.9040142765862077], 'val_acc': [0.9042, 0.90369999999999995, 0.90649999999999997, 0.90490000000000004, 0.90649999999999997, 0.90669999999999995, 0.90629999999999999, 0.90510000000000002, 0.90749999999999997, 0.90549999999999997, 0.9083, 0.90749999999999997, 0.90810000000000002, 0.90600000000000003, 0.90800000000000003, 0.90569999999999995, 0.90580000000000005, 0.90720000000000001, 0.90539999999999998, 0.90569999999999995, 0.90580000000000005, 0.9083, 0.90739999999999998, 0.90910000000000002, 0.90510000000000002]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 164s - loss: 0.3515 - acc: 0.9076 - val_loss: 0.3747 - val_acc: 0.9077\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 165s - loss: 0.3508 - acc: 0.9078 - val_loss: 0.3726 - val_acc: 0.9094\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 226s - loss: 0.3501 - acc: 0.9073 - val_loss: 0.3728 - val_acc: 0.9095\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 171s - loss: 0.3489 - acc: 0.9097 - val_loss: 0.3724 - val_acc: 0.9083\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 167s - loss: 0.3491 - acc: 0.9077 - val_loss: 0.3714 - val_acc: 0.9077\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 161s - loss: 0.3530 - acc: 0.9073 - val_loss: 0.3731 - val_acc: 0.9078\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 161s - loss: 0.3493 - acc: 0.9069 - val_loss: 0.3681 - val_acc: 0.9082\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 163s - loss: 0.3464 - acc: 0.9088 - val_loss: 0.3691 - val_acc: 0.9087\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 162s - loss: 0.3448 - acc: 0.9097 - val_loss: 0.3707 - val_acc: 0.9097\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 163s - loss: 0.3447 - acc: 0.9092 - val_loss: 0.3671 - val_acc: 0.9098\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 163s - loss: 0.3430 - acc: 0.9115 - val_loss: 0.3723 - val_acc: 0.9113\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 164s - loss: 0.3464 - acc: 0.9098 - val_loss: 0.3670 - val_acc: 0.9108\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 162s - loss: 0.3456 - acc: 0.9084 - val_loss: 0.3621 - val_acc: 0.9130\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 163s - loss: 0.3431 - acc: 0.9097 - val_loss: 0.3637 - val_acc: 0.9123\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 161s - loss: 0.3436 - acc: 0.9089 - val_loss: 0.3659 - val_acc: 0.9105\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 161s - loss: 0.3423 - acc: 0.9100 - val_loss: 0.3654 - val_acc: 0.9101\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 161s - loss: 0.3395 - acc: 0.9113 - val_loss: 0.3688 - val_acc: 0.9093\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 163s - loss: 0.3415 - acc: 0.9097 - val_loss: 0.3643 - val_acc: 0.9104\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 162s - loss: 0.3403 - acc: 0.9118 - val_loss: 0.3670 - val_acc: 0.9101\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 166s - loss: 0.3427 - acc: 0.9104 - val_loss: 0.3677 - val_acc: 0.9100\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 162s - loss: 0.3374 - acc: 0.9112 - val_loss: 0.3617 - val_acc: 0.9111\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 163s - loss: 0.3399 - acc: 0.9099 - val_loss: 0.3672 - val_acc: 0.9081\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 162s - loss: 0.3401 - acc: 0.9098 - val_loss: 0.3638 - val_acc: 0.9093\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 164s - loss: 0.3362 - acc: 0.9099 - val_loss: 0.3639 - val_acc: 0.9104\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 163s - loss: 0.3439 - acc: 0.9102 - val_loss: 0.3685 - val_acc: 0.9098\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000075,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep175'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.3515356028691316, 0.3507932654875075, 0.35016389108446111, 0.34890896115388709, 0.34898843144161945, 0.35292680425295125, 0.34931602485102647, 0.3463163648731708, 0.34477103799629333, 0.34465093791656937, 0.3431431201451246, 0.34639851537162308, 0.34559319817297041, 0.34304252292699144, 0.34359552797538406, 0.34219201610453204, 0.33936464202339006, 0.34156580033652628, 0.34019928048121306, 0.34267815525882855, 0.33736218821363723, 0.33993937296480331, 0.34017674660774466, 0.33618998018869956, 0.34380032519403847], 'val_loss': [0.37473451733589175, 0.37259414525032042, 0.37279392015933993, 0.37238651752471924, 0.37143607008457186, 0.3731338778972626, 0.36805003139972686, 0.36910122101306914, 0.37072232716083525, 0.36708630733489989, 0.37231105351448057, 0.36699595897197723, 0.36211951601505282, 0.36371350474357605, 0.36585613398551942, 0.36540722689628602, 0.36875473973751066, 0.36429284458160399, 0.36699169950485228, 0.36773691816329956, 0.36170721726417543, 0.36719307374954224, 0.36377398304939268, 0.36385432071685792, 0.36852316584587097], 'acc': [0.90755208333333337, 0.90778392685274301, 0.90734279760000303, 0.90970885470619478, 0.9077237728585178, 0.90730269489894133, 0.90694177097183482, 0.90878649344228579, 0.90968880329829671, 0.9091674687581679, 0.91147337181276722, 0.90982916269464531, 0.90838546683324006, 0.90970885466794993, 0.90892685270477724, 0.91004972728277045, 0.91137311517484765, 0.90970885468707241, 0.91179419311530163, 0.91035049729214135, 0.91123275587411123, 0.90980911128674713, 0.90980911132499198, 0.90990936802027889, 0.91025024061597692], 'val_acc': [0.90769999999999995, 0.90939999999999999, 0.90949999999999998, 0.9083, 0.90769999999999995, 0.90780000000000005, 0.90820000000000001, 0.90869999999999995, 0.90969999999999995, 0.90980000000000005, 0.9113, 0.91080000000000005, 0.91300000000000003, 0.9123, 0.91049999999999998, 0.91010000000000002, 0.9093, 0.91039999999999999, 0.91010000000000002, 0.91000000000000003, 0.91110000000000002, 0.90810000000000002, 0.9093, 0.91039999999999999, 0.90980000000000005]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 163s - loss: 0.3293 - acc: 0.9127 - val_loss: 0.3631 - val_acc: 0.9110\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 160s - loss: 0.3341 - acc: 0.9121 - val_loss: 0.3645 - val_acc: 0.9113\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 162s - loss: 0.3319 - acc: 0.9139 - val_loss: 0.3607 - val_acc: 0.9108\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 162s - loss: 0.3289 - acc: 0.9149 - val_loss: 0.3656 - val_acc: 0.9110\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 163s - loss: 0.3294 - acc: 0.9128 - val_loss: 0.3609 - val_acc: 0.9115\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 161s - loss: 0.3314 - acc: 0.9129 - val_loss: 0.3648 - val_acc: 0.9108\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 161s - loss: 0.3299 - acc: 0.9125 - val_loss: 0.3649 - val_acc: 0.9102\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 161s - loss: 0.3308 - acc: 0.9130 - val_loss: 0.3663 - val_acc: 0.9113\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 162s - loss: 0.3276 - acc: 0.9152 - val_loss: 0.3655 - val_acc: 0.9109\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 165s - loss: 0.3357 - acc: 0.9108 - val_loss: 0.3651 - val_acc: 0.9111\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 162s - loss: 0.3286 - acc: 0.9127 - val_loss: 0.3616 - val_acc: 0.9115\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 162s - loss: 0.3287 - acc: 0.9133 - val_loss: 0.3644 - val_acc: 0.9104\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 162s - loss: 0.3281 - acc: 0.9144 - val_loss: 0.3637 - val_acc: 0.9115\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 162s - loss: 0.3276 - acc: 0.9138 - val_loss: 0.3628 - val_acc: 0.9114\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 162s - loss: 0.3296 - acc: 0.9129 - val_loss: 0.3623 - val_acc: 0.9118\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 162s - loss: 0.3260 - acc: 0.9148 - val_loss: 0.3638 - val_acc: 0.9119\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 162s - loss: 0.3240 - acc: 0.9151 - val_loss: 0.3623 - val_acc: 0.9139\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 161s - loss: 0.3191 - acc: 0.9165 - val_loss: 0.3622 - val_acc: 0.9110\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 162s - loss: 0.3289 - acc: 0.9126 - val_loss: 0.3658 - val_acc: 0.9117\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 163s - loss: 0.3258 - acc: 0.9136 - val_loss: 0.3643 - val_acc: 0.9120\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 161s - loss: 0.3260 - acc: 0.9146 - val_loss: 0.3637 - val_acc: 0.9123\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 160s - loss: 0.3215 - acc: 0.9169 - val_loss: 0.3614 - val_acc: 0.9117\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 160s - loss: 0.3256 - acc: 0.9134 - val_loss: 0.3634 - val_acc: 0.9124\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 160s - loss: 0.3236 - acc: 0.9151 - val_loss: 0.3626 - val_acc: 0.9128\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 161s - loss: 0.3287 - acc: 0.9119 - val_loss: 0.3610 - val_acc: 0.9118\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep200'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.32927706054387951, 0.33403539033245117, 0.3320226750773117, 0.32889855354498471, 0.32931774173901179, 0.33133422412434793, 0.32991392495045496, 0.3308569425702057, 0.3276316589906807, 0.33565924247564854, 0.32853743054371903, 0.32876266973654278, 0.32808605792585915, 0.32772180080452062, 0.32965527598219957, 0.32603087190408375, 0.32388832083794794, 0.31888465750167722, 0.32902137609602056, 0.32576181519899683, 0.32605346564991106, 0.32145522791566011, 0.32560012685323242, 0.32353692788858995, 0.32874150134869251], 'val_loss': [0.36311696619987488, 0.36449153203964235, 0.36065400500297545, 0.36562670352458954, 0.36087372794151307, 0.36480883178710938, 0.36488462481498718, 0.36634175279140474, 0.36551055855751036, 0.36511351628303529, 0.36161907143592836, 0.36436525125503538, 0.36372643489837647, 0.36277521638870242, 0.36233221931457521, 0.3637727919816971, 0.36225557637214661, 0.36222020153999329, 0.36577175068855283, 0.36431245071887969, 0.36374405379295349, 0.36140025212764743, 0.36343141713142396, 0.36258703327178954, 0.36098965461254118], 'acc': [0.91270032051282046, 0.91215511711889785, 0.91383942893808146, 0.91496230347782981, 0.91289701638100884, 0.91291706767417236, 0.91249598977196322, 0.91303737571999011, 0.91512271412909696, 0.91079162654488144, 0.91273660569149673, 0.91331809428321808, 0.91440086617927196, 0.91373917228103951, 0.91281681101713041, 0.91482194419621576, 0.91512271410997459, 0.91654635871646106, 0.91251604110337159, 0.91357876161064977, 0.91464148223266262, 0.91688723129303673, 0.91339829964709651, 0.91506256015399423, 0.9118543471477718], 'val_acc': [0.91100000000000003, 0.9113, 0.91080000000000005, 0.91100000000000003, 0.91149999999999998, 0.91080000000000005, 0.91020000000000001, 0.9113, 0.91090000000000004, 0.91110000000000002, 0.91149999999999998, 0.91039999999999999, 0.91149999999999998, 0.91139999999999999, 0.91180000000000005, 0.91190000000000004, 0.91390000000000005, 0.91100000000000003, 0.91169999999999995, 0.91200000000000003, 0.9123, 0.91169999999999995, 0.91239999999999999, 0.91279999999999994, 0.91180000000000005]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 166s - loss: 0.3221 - acc: 0.9144 - val_loss: 0.3636 - val_acc: 0.9115\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 160s - loss: 0.3268 - acc: 0.9135 - val_loss: 0.3630 - val_acc: 0.9116\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 161s - loss: 0.3229 - acc: 0.9149 - val_loss: 0.3624 - val_acc: 0.9119\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 161s - loss: 0.3237 - acc: 0.9144 - val_loss: 0.3624 - val_acc: 0.9123\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 161s - loss: 0.3257 - acc: 0.9145 - val_loss: 0.3621 - val_acc: 0.9117\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 161s - loss: 0.3243 - acc: 0.9151 - val_loss: 0.3631 - val_acc: 0.9111\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 161s - loss: 0.3195 - acc: 0.9154 - val_loss: 0.3620 - val_acc: 0.9116\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 160s - loss: 0.3218 - acc: 0.9160 - val_loss: 0.3626 - val_acc: 0.9121\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 159s - loss: 0.3193 - acc: 0.9159 - val_loss: 0.3637 - val_acc: 0.9116\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 159s - loss: 0.3189 - acc: 0.9169 - val_loss: 0.3634 - val_acc: 0.9117\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 159s - loss: 0.3217 - acc: 0.9156 - val_loss: 0.3621 - val_acc: 0.9118\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 159s - loss: 0.3199 - acc: 0.9153 - val_loss: 0.3615 - val_acc: 0.9121\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 159s - loss: 0.3215 - acc: 0.9162 - val_loss: 0.3617 - val_acc: 0.9106\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 159s - loss: 0.3234 - acc: 0.9149 - val_loss: 0.3624 - val_acc: 0.9117\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 159s - loss: 0.3208 - acc: 0.9155 - val_loss: 0.3619 - val_acc: 0.9124\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 159s - loss: 0.3186 - acc: 0.9151 - val_loss: 0.3624 - val_acc: 0.9118\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 159s - loss: 0.3175 - acc: 0.9170 - val_loss: 0.3635 - val_acc: 0.9113\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 159s - loss: 0.3202 - acc: 0.9164 - val_loss: 0.3614 - val_acc: 0.9118\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 159s - loss: 0.3169 - acc: 0.9167 - val_loss: 0.3625 - val_acc: 0.9119\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 159s - loss: 0.3158 - acc: 0.9176 - val_loss: 0.3624 - val_acc: 0.9114\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 159s - loss: 0.3179 - acc: 0.9174 - val_loss: 0.3615 - val_acc: 0.9125\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 159s - loss: 0.3185 - acc: 0.9164 - val_loss: 0.3627 - val_acc: 0.9110\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 159s - loss: 0.3197 - acc: 0.9160 - val_loss: 0.3617 - val_acc: 0.9119\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 159s - loss: 0.3184 - acc: 0.9163 - val_loss: 0.3625 - val_acc: 0.9118\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 159s - loss: 0.3161 - acc: 0.9162 - val_loss: 0.3629 - val_acc: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs, verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep225'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.32208480330613942, 0.32684640355472727, 0.32269396748839568, 0.32364537557578066, 0.32566470715683699, 0.32434217800572396, 0.31950915777648836, 0.32144709070561822, 0.31935992152368864, 0.31889676721691895, 0.32146597914409669, 0.32001503927703084, 0.32141461894800544, 0.32343909920772607, 0.32070021081284372, 0.31854290369614829, 0.31757781932110735, 0.32013130783652283, 0.31681587351297852, 0.3157247817875829, 0.31782810311115511, 0.31865414598927422, 0.31967067582736536, 0.31829771442523475, 0.31615555649733829], 'val_loss': [0.36362199084758756, 0.36297904169559481, 0.36243425235748289, 0.36236669154167173, 0.36209981315135958, 0.36312918095588687, 0.36199545254707338, 0.362604337477684, 0.36369067528247834, 0.36339863023757935, 0.36207701337337495, 0.36146796934604647, 0.36173539891242978, 0.36243227574825287, 0.36191448402404786, 0.36241684017181397, 0.36347164263725279, 0.36137554321289062, 0.36249552607536317, 0.36237710511684418, 0.36153839492797851, 0.36267979824543001, 0.36166459453105926, 0.36245483675003054, 0.36287222452163698], 'acc': [0.91440304487179491, 0.91345845367956668, 0.91496230349695218, 0.91442091752980281, 0.91454122553737571, 0.91510266281681107, 0.91542348413846797, 0.91606512668616957, 0.91590471611139213, 0.91686718001899559, 0.91564404874571559, 0.91528312476124185, 0.9162255373756818, 0.91492220085325782, 0.91552374075726506, 0.91514276544138295, 0.91696743659954782, 0.91646615335258264, 0.9167669233045862, 0.91762913061251505, 0.91736846322771604, 0.91634584532588725, 0.91600497269194436, 0.9163257940709687, 0.91616538334321163], 'val_acc': [0.91149999999999998, 0.91159999999999997, 0.91190000000000004, 0.9123, 0.91169999999999995, 0.91110000000000002, 0.91159999999999997, 0.91210000000000002, 0.91159999999999997, 0.91169999999999995, 0.91180000000000005, 0.91210000000000002, 0.91059999999999997, 0.91169999999999995, 0.91239999999999999, 0.91180000000000005, 0.9113, 0.91180000000000005, 0.91190000000000004, 0.91139999999999999, 0.91249999999999998, 0.91100000000000003, 0.91190000000000004, 0.91180000000000005, 0.91159999999999997]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 163s - loss: 0.3178 - acc: 0.9174 - val_loss: 0.3619 - val_acc: 0.9122\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 161s - loss: 0.3199 - acc: 0.9172 - val_loss: 0.3624 - val_acc: 0.9120\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 160s - loss: 0.3173 - acc: 0.9167 - val_loss: 0.3623 - val_acc: 0.9119\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 160s - loss: 0.3178 - acc: 0.9155 - val_loss: 0.3612 - val_acc: 0.9123\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 161s - loss: 0.3170 - acc: 0.9174 - val_loss: 0.3609 - val_acc: 0.9116\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 160s - loss: 0.3161 - acc: 0.9169 - val_loss: 0.3614 - val_acc: 0.9118\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 160s - loss: 0.3192 - acc: 0.9166 - val_loss: 0.3609 - val_acc: 0.9112\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 159s - loss: 0.3218 - acc: 0.9158 - val_loss: 0.3614 - val_acc: 0.9119\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 159s - loss: 0.3186 - acc: 0.9168 - val_loss: 0.3611 - val_acc: 0.9122\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 159s - loss: 0.3178 - acc: 0.9172 - val_loss: 0.3612 - val_acc: 0.9120\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 159s - loss: 0.3138 - acc: 0.9173 - val_loss: 0.3613 - val_acc: 0.9116\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 159s - loss: 0.3162 - acc: 0.9164 - val_loss: 0.3614 - val_acc: 0.9112\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 159s - loss: 0.3163 - acc: 0.9161 - val_loss: 0.3604 - val_acc: 0.9118\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 159s - loss: 0.3149 - acc: 0.9170 - val_loss: 0.3612 - val_acc: 0.9116\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 159s - loss: 0.3170 - acc: 0.9167 - val_loss: 0.3608 - val_acc: 0.9117\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 159s - loss: 0.3177 - acc: 0.9155 - val_loss: 0.3620 - val_acc: 0.9124\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 159s - loss: 0.3176 - acc: 0.9167 - val_loss: 0.3611 - val_acc: 0.9118\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 159s - loss: 0.3148 - acc: 0.9165 - val_loss: 0.3622 - val_acc: 0.9112\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 161s - loss: 0.3183 - acc: 0.9162 - val_loss: 0.3609 - val_acc: 0.9122\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 160s - loss: 0.3143 - acc: 0.9178 - val_loss: 0.3603 - val_acc: 0.9129\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 161s - loss: 0.3149 - acc: 0.9167 - val_loss: 0.3606 - val_acc: 0.9116\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 161s - loss: 0.3168 - acc: 0.9169 - val_loss: 0.3611 - val_acc: 0.9123\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 161s - loss: 0.3154 - acc: 0.9177 - val_loss: 0.3602 - val_acc: 0.9125\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 161s - loss: 0.3135 - acc: 0.9170 - val_loss: 0.3612 - val_acc: 0.9122\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 161s - loss: 0.3136 - acc: 0.9169 - val_loss: 0.3602 - val_acc: 0.9124\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep250'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31778509731476123, 0.31979557498930966, 0.3173924603158555, 0.31798278747612291, 0.31692799680080785, 0.31620300460079753, 0.31920811063515897, 0.32186891983287397, 0.31851778963188121, 0.31786509809067204, 0.31380045239000626, 0.31618723710225033, 0.3163183502061726, 0.31494900439846468, 0.31690324638797795, 0.31773717685659075, 0.31757317354826731, 0.3146382658994844, 0.31830728459442353, 0.31440094127691742, 0.31494209721067756, 0.31686275063472791, 0.31545547063931234, 0.31354429957420732, 0.31360799723379806], 'val_loss': [0.36186885457038881, 0.36236878440380099, 0.36226771931648255, 0.36122839546203611, 0.360926317858696, 0.36137310361862185, 0.36089489243030548, 0.36140173366069794, 0.36107708740234373, 0.36122900331020358, 0.36128344936370849, 0.3613970421552658, 0.36044900920391082, 0.36119195277690885, 0.36077482202053068, 0.36203010430335997, 0.36110879654884337, 0.36218263964653014, 0.36094407682418822, 0.36026698393821716, 0.36059736957550048, 0.36112215256690977, 0.36015144712924957, 0.36115889711380006, 0.36016337261199949], 'acc': [0.9174479166666667, 0.91716794999012163, 0.91662656402297227, 0.9154034328070596, 0.91736846322771604, 0.91684712868758722, 0.91660651271068638, 0.91572425407134916, 0.91676692334283116, 0.91716794993275441, 0.91726820662804132, 0.9164059993774798, 0.91612528068039489, 0.91702759065114037, 0.91672682066089184, 0.91544353545075396, 0.91670676932948347, 0.91660651267244142, 0.91624558874533502, 0.91772938719306729, 0.91668671799807511, 0.91684712864934237, 0.91766923327533179, 0.91698748796920115, 0.91690728268181243], 'val_acc': [0.91220000000000001, 0.91200000000000003, 0.91190000000000004, 0.9123, 0.91159999999999997, 0.91180000000000005, 0.91120000000000001, 0.91190000000000004, 0.91220000000000001, 0.91200000000000003, 0.91159999999999997, 0.91120000000000001, 0.91180000000000005, 0.91159999999999997, 0.91169999999999995, 0.91239999999999999, 0.91180000000000005, 0.91120000000000001, 0.91220000000000001, 0.91290000000000004, 0.91159999999999997, 0.9123, 0.91249999999999998, 0.91220000000000001, 0.91239999999999999]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "390/390 [==============================] - 204s - loss: 0.3323 - acc: 0.9127 - val_loss: 0.3527 - val_acc: 0.9127\n",
      "Epoch 2/5\n",
      "390/390 [==============================] - 175s - loss: 0.3273 - acc: 0.9141 - val_loss: 0.3518 - val_acc: 0.9134\n",
      "Epoch 3/5\n",
      "390/390 [==============================] - 175s - loss: 0.3282 - acc: 0.9141 - val_loss: 0.3533 - val_acc: 0.9126\n",
      "Epoch 4/5\n",
      "390/390 [==============================] - 175s - loss: 0.3252 - acc: 0.9149 - val_loss: 0.3521 - val_acc: 0.9126\n",
      "Epoch 5/5\n",
      "390/390 [==============================] - 175s - loss: 0.3234 - acc: 0.9142 - val_loss: 0.3510 - val_acc: 0.9142\n"
     ]
    }
   ],
   "source": [
    "# Continue for 5 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs/5,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep180'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.33230996036376709, 0.32719322844005982, 0.32824470005740636, 0.3253342996605092, 0.32338115969720005], 'acc': [0.91270032051282046, 0.91410009628463562, 0.91414019894745246, 0.91484199548937928, 0.91424045560449452], 'val_acc': [0.91269999999999996, 0.91339999999999999, 0.91259999999999997, 0.91259999999999997, 0.91420000000000001], 'val_loss': [0.35265359048843381, 0.3518087520599365, 0.35332506449222567, 0.3521182010412216, 0.35099164197444915]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "390/390 [==============================] - 175s - loss: 0.3216 - acc: 0.9164 - val_loss: 0.3494 - val_acc: 0.9137\n",
      "Epoch 2/5\n",
      "390/390 [==============================] - 173s - loss: 0.3180 - acc: 0.9162 - val_loss: 0.3507 - val_acc: 0.9129\n",
      "Epoch 3/5\n",
      "390/390 [==============================] - 173s - loss: 0.3198 - acc: 0.9163 - val_loss: 0.3495 - val_acc: 0.9145\n",
      "Epoch 4/5\n",
      "390/390 [==============================] - 174s - loss: 0.3177 - acc: 0.9168 - val_loss: 0.3482 - val_acc: 0.9136\n",
      "Epoch 5/5\n",
      "390/390 [==============================] - 175s - loss: 0.3198 - acc: 0.9155 - val_loss: 0.3490 - val_acc: 0.9131\n"
     ]
    }
   ],
   "source": [
    "# Continue for 5 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000017,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs/5,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep185'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.32158530679268715, 0.31804832125803889, 0.31982653061472377, 0.31783790355754427, 0.31977273882831331], 'acc': [0.91644631410256405, 0.91616538340057896, 0.91636589669554058, 0.91674687201142269, 0.91552374075726506], 'val_acc': [0.91369999999999996, 0.91290000000000004, 0.91449999999999998, 0.91359999999999997, 0.91310000000000002], 'val_loss': [0.34940690484046938, 0.35069076657295228, 0.34950749626159666, 0.34822640521526338, 0.34899765317440035]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "390/390 [==============================] - 178s - loss: 0.3181 - acc: 0.9148 - val_loss: 0.3491 - val_acc: 0.9131\n",
      "Epoch 2/5\n",
      "390/390 [==============================] - 182s - loss: 0.3182 - acc: 0.9161 - val_loss: 0.3488 - val_acc: 0.9132\n",
      "Epoch 3/5\n",
      "390/390 [==============================] - 188s - loss: 0.3170 - acc: 0.9171 - val_loss: 0.3486 - val_acc: 0.9146\n",
      "Epoch 4/5\n",
      "390/390 [==============================] - 180s - loss: 0.3178 - acc: 0.9149 - val_loss: 0.3485 - val_acc: 0.9138\n",
      "Epoch 5/5\n",
      "390/390 [==============================] - 177s - loss: 0.3196 - acc: 0.9149 - val_loss: 0.3482 - val_acc: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# Continue for 5 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000012,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs/5,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('cifar10_normal_rms_ep190'+act_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.31811031596018718, 0.31812568393738788, 0.31705727593845995, 0.31778135214014086, 0.3195749556249558], 'acc': [0.91480368589743588, 0.91614533203092563, 0.91712784728905994, 0.9149222008723803, 0.91490214946448212], 'val_acc': [0.91310000000000002, 0.91320000000000001, 0.91459999999999997, 0.91379999999999995, 0.91369999999999996], 'val_loss': [0.34911735839843749, 0.34877158300876615, 0.34858218002319336, 0.34853716928958894, 0.34819411923885346]}\n"
     ]
    }
   ],
   "source": [
    "print(his.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

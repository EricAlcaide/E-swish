{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras import regularizers, optimizers\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)# .reshape((y_train.shape[0], 10,1))\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)# .reshape((y_test.shape[0], 10,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Swish activation function\n",
    "# x*sigmoid(x)\n",
    "def swish(x):\n",
    "    return x*K.sigmoid(x)\n",
    "\n",
    "# Custom activation function 1\n",
    "# mix between relu and positive part of swish mirrored across x=1\n",
    "def e_swish_1(x):\n",
    "    return K.maximum(0.0, x*(2-K.sigmoid(x)))\n",
    "\n",
    "# Custom activation function 2\n",
    "# positive part of swish mirrored across x=1\n",
    "def e_swish_2(x):\n",
    "    return K.maximum(x*K.sigmoid(x), x*(2-K.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relu', 'e_swish_2', 'swish', 'e_swish_1']\n"
     ]
    }
   ],
   "source": [
    "activations = [\"relu\", e_swish_2, swish, e_swish_1]\n",
    "\n",
    "names = activations[:]\n",
    "for i,a in enumerate(names):\n",
    "    if not isinstance(a, str):\n",
    "        names[i] = a.__name__\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(act, act_name):\n",
    "    nn = {\"act\": act, \"act_name\": act_name}\n",
    "    \n",
    "    weight_decay = 1e-2\n",
    "    s = 2\n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=glorot_normal(), input_shape=x_train.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 4\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    \n",
    "    # First Maxpooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    # Block 5\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=RandomNormal(stddev=0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 6\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 7\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    # Second Maxpooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    # Block 8\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 9\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Third Maxpooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    \n",
    "    \n",
    "    # Block 10\n",
    "    model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Block 11  \n",
    "    model.add(Conv2D(2048, (1,1), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Block 12  \n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(Activation(act))\n",
    "    # Fourth Maxpooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    # Block 13\n",
    "    model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "    model.add(Activation(act))\n",
    "    # Fifth Maxpooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=s))\n",
    "\n",
    "    # Final Classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    \n",
    "    nn[\"model\"] = model\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 4, 4, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 5,497,226\n",
      "Trainable params: 5,493,258\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "{'val_loss': [1.7329517599105835, 1.0603529544830321, 0.97548006944656374, 0.72746701297760008, 0.7597872285842896, 0.61026840372085567, 0.65135995960235593, 0.5532294010162353, 0.50345064902305603, 0.44833394536972043, 0.49179735250473022, 0.43488188610076906, 0.43561975603103636, 0.41392285156250003, 0.4229993600845337, 0.38457150311470034, 0.36002096996307376, 0.35500431201457977, 0.39244994511604309, 0.35464530408382416, 0.41346658325195312, 0.3423326653957367, 0.36676351823806763, 0.40554242107868194, 0.30359055061340334, 0.33298080945014952, 0.34651537609100341, 0.3430180743217468, 0.3114858228683472, 0.30348974299430848, 0.3288530241250992, 0.32831635842323303, 0.30387966504096986, 0.2945826789855957, 0.31694274482727053, 0.30898189983367919, 0.33265611674785617, 0.28628292818069456, 0.29154828703403474, 0.26610786178112028, 0.26749351918697356, 0.27940700955390929, 0.27949792910218241, 0.28156600496768952, 0.28037849442958834, 0.26736695795059207, 0.29200477724075319, 0.25357439348697663, 0.26933255457878114, 0.27981425781250002], 'val_acc': [0.40410000000000001, 0.62039999999999995, 0.65159999999999996, 0.75060000000000004, 0.73780000000000001, 0.79120000000000001, 0.77240000009536747, 0.81240000000000001, 0.83040000000000003, 0.84860000000000002, 0.83440000000000003, 0.8538, 0.85370000000000001, 0.86050000000000004, 0.85640000000000005, 0.86919999999999997, 0.88, 0.87670000000000003, 0.86439999999999995, 0.87949999999999995, 0.85919999999999996, 0.88370000000000004, 0.87309999999999999, 0.86180000000000001, 0.90000000000000002, 0.89080000000000004, 0.88600000000000001, 0.88349999999999995, 0.89339999999999997, 0.89949999999999997, 0.88759999999999994, 0.88849999999999996, 0.90180000000000005, 0.90190000000000003, 0.89339999999999997, 0.89339999999999997, 0.89090000000000003, 0.90529999999999999, 0.90059999999999996, 0.90869999999999995, 0.90980000000000005, 0.90539999999999998, 0.90610000000000002, 0.90280000000000005, 0.90700000000000003, 0.90790000000000004, 0.9042, 0.91600000000000004, 0.9073, 0.90880000000000005], 'loss': [1.6696773568344117, 1.1978135011672975, 0.97076420270919794, 0.83798052875518803, 0.75594126264572148, 0.68348283039093016, 0.63346393926620481, 0.59590769216537476, 0.55824406209945676, 0.52912685538291926, 0.50412101441383361, 0.48441363045692443, 0.46149864253997802, 0.44369244746208192, 0.42560738761901856, 0.41514652463912965, 0.40338735296249389, 0.3861116176223755, 0.3771543263912201, 0.36384867888927458, 0.3547870124530792, 0.34086401730060578, 0.33839804542541502, 0.32731084501266478, 0.31803030122756959, 0.31181607466697692, 0.30482855295181277, 0.29898056103706361, 0.29336735146522525, 0.28525618177413942, 0.27782387501716616, 0.2737545419502258, 0.27115947736740115, 0.26257506133079528, 0.26002237626075747, 0.25324112277030947, 0.24665114800930024, 0.24328675702095032, 0.23970119610309601, 0.2346135705423355, 0.22548975520133971, 0.22674388646125793, 0.22166936846733093, 0.22310952488422395, 0.21525440221309661, 0.20881784856796265, 0.20983592505931853, 0.20549511778831481, 0.2025312848854065, 0.19881542884826661], 'acc': [0.36887999999046328, 0.56733999998092655, 0.65522000003814695, 0.70523999999999998, 0.73499999998092647, 0.76226000000000005, 0.7808400000190735, 0.79264000003814694, 0.8066000000190735, 0.81727999998092649, 0.8265800000190735, 0.833220000038147, 0.84079999998092647, 0.84872000000000003, 0.85391999996185308, 0.85533999998092647, 0.86061999998092653, 0.86719999996185304, 0.86847999996185299, 0.87333999996185308, 0.87667999998092649, 0.88218000003814701, 0.88370000001907345, 0.88678000000000001, 0.89056000000000002, 0.89032000003814693, 0.89527999996185303, 0.89610000000000001, 0.89703999996185302, 0.90148000001907347, 0.90361999998092646, 0.90483999999999998, 0.90659999999999996, 0.90915999998092656, 0.90895999999999999, 0.91087999996185298, 0.91461999996185306, 0.91481999999999997, 0.91694000003814702, 0.918140000038147, 0.92129999998092649, 0.92168000000000005, 0.92168000001907346, 0.92261999996185307, 0.92337999998092657, 0.92574000003814694, 0.92654000001907344, 0.92843999998092652, 0.93074000000000001, 0.93042000000000002]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "391/390 [==============================] - 156s 398ms/step - loss: 0.1689 - acc: 0.9404 - val_loss: 0.2425 - val_acc: 0.9212\n",
      "Epoch 2/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1586 - acc: 0.9450 - val_loss: 0.2430 - val_acc: 0.9195\n",
      "Epoch 3/30\n",
      "391/390 [==============================] - 150s 384ms/step - loss: 0.1580 - acc: 0.9458 - val_loss: 0.2321 - val_acc: 0.9228\n",
      "Epoch 4/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1553 - acc: 0.9454 - val_loss: 0.2272 - val_acc: 0.9262\n",
      "Epoch 5/30\n",
      "391/390 [==============================] - 150s 384ms/step - loss: 0.1544 - acc: 0.9463 - val_loss: 0.2449 - val_acc: 0.9206\n",
      "Epoch 6/30\n",
      "391/390 [==============================] - 150s 384ms/step - loss: 0.1493 - acc: 0.9481 - val_loss: 0.2466 - val_acc: 0.9198\n",
      "Epoch 7/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1483 - acc: 0.9482 - val_loss: 0.2413 - val_acc: 0.9208\n",
      "Epoch 8/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1463 - acc: 0.9499 - val_loss: 0.2473 - val_acc: 0.9188\n",
      "Epoch 9/30\n",
      "391/390 [==============================] - 150s 384ms/step - loss: 0.1498 - acc: 0.9484 - val_loss: 0.2370 - val_acc: 0.9244\n",
      "Epoch 10/30\n",
      "391/390 [==============================] - 150s 384ms/step - loss: 0.1432 - acc: 0.9502 - val_loss: 0.2522 - val_acc: 0.9200\n",
      "Epoch 11/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1433 - acc: 0.9504 - val_loss: 0.2478 - val_acc: 0.9221\n",
      "Epoch 12/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1388 - acc: 0.9513 - val_loss: 0.2467 - val_acc: 0.9205\n",
      "Epoch 13/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1414 - acc: 0.9499 - val_loss: 0.2352 - val_acc: 0.9229\n",
      "Epoch 14/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1378 - acc: 0.9523 - val_loss: 0.2455 - val_acc: 0.9208\n",
      "Epoch 15/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1359 - acc: 0.9529 - val_loss: 0.2513 - val_acc: 0.9203\n",
      "Epoch 16/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1340 - acc: 0.9537 - val_loss: 0.2539 - val_acc: 0.9193\n",
      "Epoch 17/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1341 - acc: 0.9534 - val_loss: 0.2418 - val_acc: 0.9221\n",
      "Epoch 18/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1317 - acc: 0.9541 - val_loss: 0.2460 - val_acc: 0.9219\n",
      "Epoch 19/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1326 - acc: 0.9534 - val_loss: 0.2391 - val_acc: 0.9237\n",
      "Epoch 20/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1304 - acc: 0.9552 - val_loss: 0.2309 - val_acc: 0.9277\n",
      "Epoch 21/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1309 - acc: 0.9553 - val_loss: 0.2382 - val_acc: 0.9237\n",
      "Epoch 22/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1308 - acc: 0.9548 - val_loss: 0.2452 - val_acc: 0.9210\n",
      "Epoch 23/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1263 - acc: 0.9553 - val_loss: 0.2407 - val_acc: 0.9240\n",
      "Epoch 24/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1304 - acc: 0.9550 - val_loss: 0.2396 - val_acc: 0.9234\n",
      "Epoch 25/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1281 - acc: 0.9561 - val_loss: 0.2445 - val_acc: 0.9257\n",
      "Epoch 26/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1236 - acc: 0.9574 - val_loss: 0.2402 - val_acc: 0.9228\n",
      "Epoch 27/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1241 - acc: 0.9571 - val_loss: 0.2397 - val_acc: 0.9227\n",
      "Epoch 28/30\n",
      "391/390 [==============================] - 151s 385ms/step - loss: 0.1267 - acc: 0.9563 - val_loss: 0.2306 - val_acc: 0.9249\n",
      "Epoch 29/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1252 - acc: 0.9581 - val_loss: 0.2292 - val_acc: 0.9266\n",
      "Epoch 30/30\n",
      "391/390 [==============================] - 150s 385ms/step - loss: 0.1250 - acc: 0.9583 - val_loss: 0.2452 - val_acc: 0.9213\n",
      "{'val_loss': [0.24245962638854981, 0.2430162910938263, 0.23207923069000244, 0.22719948756694794, 0.24493830523490906, 0.24657567272186279, 0.24125349488258363, 0.24729725546836853, 0.23703989350795746, 0.25218774204254152, 0.24781928060054778, 0.24668223900794983, 0.23520604929924011, 0.24554280018806457, 0.25132192702293393, 0.2539144163608551, 0.24182315587997436, 0.24600123491287232, 0.23912568321228028, 0.23085334286689757, 0.23815927383899688, 0.245244638133049, 0.24066348719596864, 0.23963081274032594, 0.24446011598110198, 0.24015242147445678, 0.23969849342107774, 0.23064203977584838, 0.22915697894096373, 0.2452489758014679], 'val_acc': [0.92120000000000002, 0.91949999999999998, 0.92279999999999995, 0.92620000000000002, 0.92059999999999997, 0.91979999999999995, 0.92079999999999995, 0.91879999999999995, 0.9244, 0.92000000000000004, 0.92210000000000003, 0.92049999999999998, 0.92290000000000005, 0.92079999999999995, 0.92030000000000001, 0.91930000000000001, 0.92210000000000003, 0.92190000000000005, 0.92369999999999997, 0.92769999999999997, 0.92369999999999997, 0.92100000000000004, 0.92400000000000004, 0.9234, 0.92569999999999997, 0.92279999999999995, 0.92269999999999996, 0.92490000000000006, 0.92659999999999998, 0.92130000000000001], 'loss': [0.16882677317619324, 0.15831636659145354, 0.15795956859111787, 0.15550874267578124, 0.1542242204761505, 0.14940835448265075, 0.14842431031465531, 0.14604667214393616, 0.14963936624526977, 0.14306522910118102, 0.14360439639091491, 0.13868621682167054, 0.1411859811449051, 0.13798236478805542, 0.13611552978754043, 0.13402649773597716, 0.13415462124109268, 0.1319606273150444, 0.13268753270387648, 0.13060190661191939, 0.13101590873718261, 0.13060276851654054, 0.12633689054965974, 0.13030982859134674, 0.12821331628084182, 0.12350016693592071, 0.1242244203710556, 0.12663771885156633, 0.12496667431354523, 0.12498276408672333], 'acc': [0.94041999998092651, 0.94503999996185306, 0.945780000038147, 0.94533999996185303, 0.94630000000000003, 0.94811999999999996, 0.94816000003814693, 0.9500200000190735, 0.94851999998092651, 0.95016000003814693, 0.95021999999999995, 0.95141999998092652, 0.94994000000000001, 0.95223999998092657, 0.95282000003814693, 0.95365999996185302, 0.953419999961853, 0.95390000003814701, 0.95337999996185308, 0.95512000003814701, 0.95520000003814698, 0.95484000003814695, 0.95536000003814703, 0.95505999996185298, 0.95600000001907348, 0.95743999999999996, 0.9570200000190735, 0.95633999996185304, 0.95806000003814695, 0.958299999961853]}\n",
      "Epoch 1/25\n",
      "391/390 [==============================] - 156s 400ms/step - loss: 0.1103 - acc: 0.9616 - val_loss: 0.2404 - val_acc: 0.9260\n",
      "Epoch 2/25\n",
      "343/390 [=========================>....] - ETA: 17s - loss: 0.1057 - acc: 0.9630"
     ]
    }
   ],
   "source": [
    "for i, act in enumerate(activations):\n",
    "    if i == 0:\n",
    "        model = load_model(\"simplenet_generic_relu_50.h5\")\n",
    "        model.summary()\n",
    "        print(nn[\"part_1\"].history)\n",
    "        \n",
    "    else:\n",
    "        nn = create_model(act, names[i])\n",
    "        print(\"\\n\", nn) # Ensure everything's ok\n",
    "        nn[\"model\"].summary()\n",
    "        model = nn[\"model\"]\n",
    "        batch_size = 128\n",
    "\n",
    "        # First training for 50 epochs\n",
    "        epochs = 25*2\n",
    "        opt_adm = keras.optimizers.Adadelta()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
    "        nn[\"part_1\"] = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "        print(nn[\"part_1\"].history)\n",
    "        model.save(\"simplenet_generic_\"+nn[\"act_name\"]+\"_\"+str(epochs)+\".h5\")\n",
    "        \n",
    "    # Training for 30 epochs more\n",
    "    epochs = 30\n",
    "    opt_adm = keras.optimizers.Adadelta(lr=0.7, rho=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
    "    nn[\"part_2\"] = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "    print(nn[\"part_2\"].history)\n",
    "    model.save(\"simplenet_generic_\"+nn[\"act_name\"]+\"_\"+str(epochs)+\".h5\")\n",
    "    # First training for 25 epochs\n",
    "    epochs = 25\n",
    "    opt_adm = keras.optimizers.Adadelta(lr=0.5, rho=0.85)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
    "    nn[\"part_3\"] = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "    print(nn[\"part_3\"].history)\n",
    "    model.save(\"simplenet_generic_\"+nn[\"act_name\"]+\"_\"+str(epochs)+\".h5\")\n",
    "    # First training for 50 epochs\n",
    "    epochs = 20\n",
    "    opt_adm = keras.optimizers.Adadelta(lr=0.3, rho=0.75)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
    "    nn[\"part_4\"] = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "    print(nn[\"part_4\"].history)\n",
    "    model.save(\"simplenet_generic_\"+nn[\"act_name\"]+\"_\"+str(epochs)+\".h5\")\n",
    "    \n",
    "    del nn[\"model\"]\n",
    "    print(\"\\n\", nn) # Ensure everything's ok x2\n",
    "    models.append(nn)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"simplenet_generic_\"+nn[\"act_name\"]+\"_\"+str(epochs)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

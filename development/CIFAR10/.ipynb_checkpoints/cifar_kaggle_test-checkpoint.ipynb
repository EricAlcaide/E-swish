{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Adding cutout and padding with 0s to KaggLeNet.v2 \"\"\"\n",
    "\n",
    "from cutout_eraser import get_random_eraser\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom activation function 2\n",
    "# positive part of swish mirrored across x=1\n",
    "def e_swish_2(x):\n",
    "    return K.maximum(x*K.sigmoid(x), x*(2-K.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act, act_name = e_swish_2, \"e_swish_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 1,217,066\n",
      "Trainable params: 1,215,146\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.125))\n",
    "\n",
    "model.add(Conv2D(4*2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(act))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation come at me\n",
    "\"\"\" With 50% probability, erase 16*16 pixel squares. \n",
    "    - p=0.5 for 50% probability\n",
    "    - s_l, s_h = 0.5 for only 16*16 (out of 32*32) pixels cut.\n",
    "    - r_1, r_2 = 1 for squares, not rectangles\n",
    "    - v_l, v_h = 0,255 since data is not normalized. Can change to 0,1 if it is.\n",
    "\"\"\"\n",
    "eraser = get_random_eraser(p=0.5, s_l=0.375, s_h = 0.375, r_1=1, r_2=1, v_l=0, v_h=255)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10,\n",
    "    fill_mode = \"constant\",\n",
    "    width_shift_range=0.125,\n",
    "    height_shift_range=0.125,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=eraser\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_cutout_rms_ep75'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.5369 - acc: 0.8811 - val_loss: 0.5068 - val_acc: 0.8941\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.5119 - acc: 0.8880 - val_loss: 0.4966 - val_acc: 0.8990\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.5001 - acc: 0.8925 - val_loss: 0.4990 - val_acc: 0.9002\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.4899 - acc: 0.8933 - val_loss: 0.4939 - val_acc: 0.9017\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4869 - acc: 0.8940 - val_loss: 0.4979 - val_acc: 0.9011\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.4828 - acc: 0.8930 - val_loss: 0.4908 - val_acc: 0.9029\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.4833 - acc: 0.8932 - val_loss: 0.4919 - val_acc: 0.9005\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.4728 - acc: 0.8954 - val_loss: 0.4927 - val_acc: 0.9000\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 277s 711ms/step - loss: 0.4711 - acc: 0.8960 - val_loss: 0.4810 - val_acc: 0.9036\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 279s 716ms/step - loss: 0.4672 - acc: 0.8964 - val_loss: 0.4795 - val_acc: 0.9020\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.4689 - acc: 0.8960 - val_loss: 0.4713 - val_acc: 0.9028\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 277s 710ms/step - loss: 0.4655 - acc: 0.8946 - val_loss: 0.4882 - val_acc: 0.8987\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.4647 - acc: 0.8966 - val_loss: 0.4761 - val_acc: 0.9045\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4611 - acc: 0.8981 - val_loss: 0.4875 - val_acc: 0.8995\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4515 - acc: 0.8997 - val_loss: 0.4675 - val_acc: 0.9030\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4494 - acc: 0.8991 - val_loss: 0.4760 - val_acc: 0.9031\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4518 - acc: 0.8993 - val_loss: 0.4729 - val_acc: 0.9030\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4518 - acc: 0.8982 - val_loss: 0.4840 - val_acc: 0.9008\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4492 - acc: 0.8991 - val_loss: 0.4820 - val_acc: 0.9012\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4453 - acc: 0.9001 - val_loss: 0.4666 - val_acc: 0.9079\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.4483 - acc: 0.8988 - val_loss: 0.4686 - val_acc: 0.9029\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4363 - acc: 0.9028 - val_loss: 0.4773 - val_acc: 0.8998\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4372 - acc: 0.9020 - val_loss: 0.4647 - val_acc: 0.9053\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4420 - acc: 0.9005 - val_loss: 0.4767 - val_acc: 0.9017\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4422 - acc: 0.9005 - val_loss: 0.4793 - val_acc: 0.8966\n",
      "{'acc': [0.88109560472903281, 0.88797321140211594, 0.89250481233866041, 0.8933469682195686, 0.89394850814269833, 0.89300609562387057, 0.89316650623689298, 0.89545235805569612, 0.89595364128353894, 0.89647497597664716, 0.89601379529688652, 0.89459015076688975, 0.89659528394597521, 0.8981191851521364, 0.89978344563991164, 0.89910170031465853, 0.89934231629155947, 0.89817933910811676, 0.89908164905973986, 0.90014022435897434, 0.89882385998715475, 0.90281119670170329, 0.90196904070606054, 0.9005253448446553, 0.90046519088867505], 'val_loss': [0.50675820817947392, 0.49660079197883605, 0.49899183716773987, 0.49385586843490603, 0.49789135503768922, 0.4908413848876953, 0.49193063421249389, 0.49270526251792907, 0.48096266016960143, 0.47948620719909668, 0.47126741991043092, 0.48823939495086671, 0.47613692750930786, 0.48751417331695557, 0.46753323507308958, 0.47603079733848574, 0.47293474330902102, 0.48401832151412966, 0.48203036127090454, 0.46659983706474306, 0.46863346352577212, 0.47726021986007688, 0.4647468291044235, 0.47668712725639345, 0.47930611996650696], 'val_acc': [0.89410000000000001, 0.89900000000000002, 0.9002, 0.90169999999999995, 0.90110000000000001, 0.90290000000000004, 0.90049999999999997, 0.90000000000000002, 0.90359999999999996, 0.90200000000000002, 0.90280000000000005, 0.89870000000000005, 0.90449999999999997, 0.89949999999999997, 0.90300000000000002, 0.90310000000000001, 0.90300000000000002, 0.90080000000000005, 0.9012, 0.90790000000000004, 0.90290000000000004, 0.89980000000000004, 0.90529999999999999, 0.90169999999999995, 0.89659999999999995], 'loss': [0.5369944472820819, 0.51186859221423253, 0.50019101941474631, 0.48993015161186293, 0.48691052982430066, 0.48285905124286754, 0.4833620423722963, 0.4727928290907909, 0.47113533308003475, 0.46712954990137912, 0.46894046167054543, 0.46552320435179478, 0.4645758954653344, 0.46116746827735328, 0.45148459171537486, 0.44947572583604556, 0.45167917726435336, 0.45177720573646807, 0.44928317960921793, 0.44525896440713836, 0.44816647012530803, 0.43636075887956949, 0.4371287453086628, 0.441988118745824, 0.44221146309609055]}\n"
     ]
    }
   ],
   "source": [
    "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep100'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.4206 - acc: 0.9074 - val_loss: 0.4504 - val_acc: 0.9084\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4003 - acc: 0.9138 - val_loss: 0.4518 - val_acc: 0.9081\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.4019 - acc: 0.9123 - val_loss: 0.4446 - val_acc: 0.9117\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.3940 - acc: 0.9145 - val_loss: 0.4456 - val_acc: 0.9110\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3924 - acc: 0.9149 - val_loss: 0.4491 - val_acc: 0.9095\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3931 - acc: 0.9144 - val_loss: 0.4404 - val_acc: 0.9102\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3873 - acc: 0.9179 - val_loss: 0.4496 - val_acc: 0.9090\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3836 - acc: 0.9191 - val_loss: 0.4295 - val_acc: 0.9111\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3781 - acc: 0.9184 - val_loss: 0.4535 - val_acc: 0.9078\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3809 - acc: 0.9180 - val_loss: 0.4398 - val_acc: 0.9094\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3724 - acc: 0.9194 - val_loss: 0.4351 - val_acc: 0.9105\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3716 - acc: 0.9188 - val_loss: 0.4294 - val_acc: 0.9118\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3771 - acc: 0.9178 - val_loss: 0.4388 - val_acc: 0.9081\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3709 - acc: 0.9191 - val_loss: 0.4528 - val_acc: 0.9094\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3710 - acc: 0.9190 - val_loss: 0.4452 - val_acc: 0.9103\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.3685 - acc: 0.9200 - val_loss: 0.4426 - val_acc: 0.9065\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3699 - acc: 0.9191 - val_loss: 0.4507 - val_acc: 0.9073\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3623 - acc: 0.9215 - val_loss: 0.4575 - val_acc: 0.9077\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3660 - acc: 0.9193 - val_loss: 0.4566 - val_acc: 0.9072\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3639 - acc: 0.9198 - val_loss: 0.4517 - val_acc: 0.9074\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3584 - acc: 0.9228 - val_loss: 0.4420 - val_acc: 0.9083\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3607 - acc: 0.9216 - val_loss: 0.4367 - val_acc: 0.9121\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3605 - acc: 0.9211 - val_loss: 0.4433 - val_acc: 0.9085\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3635 - acc: 0.9209 - val_loss: 0.4379 - val_acc: 0.9113\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3603 - acc: 0.9221 - val_loss: 0.4293 - val_acc: 0.9112\n",
      "{'acc': [0.90738290018633005, 0.91377927494385625, 0.91227542504998094, 0.91444096888033366, 0.91496230347782981, 0.9144008662366393, 0.91790984923311025, 0.91905277510426697, 0.9184712865316681, 0.91803015722156067, 0.91947385308296592, 0.91887231312159123, 0.91782964392659905, 0.91905277510426697, 0.91901267242232765, 0.92003529038152365, 0.91915303172306406, 0.92151908886750078, 0.91931344237433132, 0.91983477706743966, 0.92280237403939391, 0.92153914017978678, 0.92113811353249619, 0.92095765162631038, 0.92214068012203898], 'val_loss': [0.45038050193786622, 0.45178039326667785, 0.44461053013801577, 0.4455671471595764, 0.449062700176239, 0.44042664918899538, 0.44963795356750486, 0.42950965108871458, 0.45346741094589232, 0.43975912270545958, 0.43513947939872744, 0.42943722052574157, 0.43878725137710572, 0.45284216423034668, 0.44520692477226259, 0.44260791273117067, 0.45070134506225584, 0.45748660216331483, 0.45657639608383177, 0.45171215953826904, 0.441963870716095, 0.43673352770805357, 0.44327658042907714, 0.43785969166755678, 0.42932473268508914], 'val_acc': [0.90839999999999999, 0.90810000000000002, 0.91169999999999995, 0.91100000000000003, 0.90949999999999998, 0.91020000000000001, 0.90900000000000003, 0.91110000000000002, 0.90780000000000005, 0.90939999999999999, 0.91049999999999998, 0.91180000000000005, 0.90810000000000002, 0.90939999999999999, 0.9103, 0.90649999999999997, 0.9073, 0.90769999999999995, 0.90720000000000001, 0.90739999999999998, 0.9083, 0.91210000000000002, 0.90849999999999997, 0.9113, 0.91120000000000001], 'loss': [0.42051655891655271, 0.40031699936168869, 0.4018541775263767, 0.39409727802787564, 0.39241682883635293, 0.39312958559586064, 0.38715289984905915, 0.38368364895120582, 0.37794773447463864, 0.38088221969916569, 0.37226977979750597, 0.37158298969536513, 0.37716836292735267, 0.37087820237517394, 0.37106607348099707, 0.36851696277567314, 0.3698337103718552, 0.36238558885375771, 0.36595391771102664, 0.36398799316333125, 0.35832319305154964, 0.36073719527731346, 0.3604870342485485, 0.36346722695167377, 0.36024497730975968]}\n"
     ]
    }
   ],
   "source": [
    "opt_rms = keras.optimizers.rmsprop(lr=0.0003,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep125'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "\n",
      "Test result: 91.120 loss: 0.429\n"
     ]
    }
   ],
   "source": [
    "#testing - no kaggle eval\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 278s 714ms/step - loss: 0.3372 - acc: 0.9277 - val_loss: 0.4217 - val_acc: 0.9153\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3330 - acc: 0.9294 - val_loss: 0.4237 - val_acc: 0.9155\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3267 - acc: 0.9317 - val_loss: 0.4262 - val_acc: 0.9141\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3212 - acc: 0.9332 - val_loss: 0.4244 - val_acc: 0.9155\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3214 - acc: 0.9333 - val_loss: 0.4218 - val_acc: 0.9152\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3168 - acc: 0.9350 - val_loss: 0.4212 - val_acc: 0.9145\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3213 - acc: 0.9339 - val_loss: 0.4179 - val_acc: 0.9167\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3149 - acc: 0.9342 - val_loss: 0.4218 - val_acc: 0.9153\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3136 - acc: 0.9363 - val_loss: 0.4095 - val_acc: 0.9173\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3119 - acc: 0.9349 - val_loss: 0.4152 - val_acc: 0.9190\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3105 - acc: 0.9359 - val_loss: 0.4121 - val_acc: 0.9195\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3152 - acc: 0.9336 - val_loss: 0.4202 - val_acc: 0.9170\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3066 - acc: 0.9376 - val_loss: 0.4193 - val_acc: 0.9183\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3077 - acc: 0.9360 - val_loss: 0.4174 - val_acc: 0.9162\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3055 - acc: 0.9362 - val_loss: 0.4245 - val_acc: 0.9164\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3015 - acc: 0.9383 - val_loss: 0.4173 - val_acc: 0.9139\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3038 - acc: 0.9363 - val_loss: 0.4264 - val_acc: 0.9166\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3064 - acc: 0.9369 - val_loss: 0.4261 - val_acc: 0.9165\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2990 - acc: 0.9378 - val_loss: 0.4199 - val_acc: 0.9173\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3060 - acc: 0.9360 - val_loss: 0.4172 - val_acc: 0.9159\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.3030 - acc: 0.9359 - val_loss: 0.4174 - val_acc: 0.9172\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2988 - acc: 0.9374 - val_loss: 0.4143 - val_acc: 0.9210\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2994 - acc: 0.9370 - val_loss: 0.4173 - val_acc: 0.9188\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2941 - acc: 0.9405 - val_loss: 0.4220 - val_acc: 0.9171\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2961 - acc: 0.9386 - val_loss: 0.4258 - val_acc: 0.9163\n",
      "{'acc': [0.92763474490881959, 0.92941931340416772, 0.93166506256015402, 0.93314886112262085, 0.93328922042335727, 0.93497353228078584, 0.93393086300930384, 0.93423163301867473, 0.93623676614039286, 0.93495348089201002, 0.93587584217504161, 0.93356993906307495, 0.93756015399422521, 0.93601620143753306, 0.93617661208880032, 0.93834215593827552, 0.93629692009637322, 0.93695861409021797, 0.93774061593865599, 0.93603625284543124, 0.93589589344908264, 0.93741979465524394, 0.936998716676545, 0.94052775100442432, 0.93858277193429873], 'val_loss': [0.42166936545372008, 0.42373329119682313, 0.42619594917297365, 0.42438006808757783, 0.42180719261169436, 0.42116077837944033, 0.41789830627441404, 0.42175936350822446, 0.40951610674858091, 0.41520506920814515, 0.4121415732383728, 0.42021748757362365, 0.41926846270561219, 0.41740275616645811, 0.42446207618713377, 0.41732076883316038, 0.42635801258087158, 0.42614305179119111, 0.41986244778633119, 0.41717315382957459, 0.41737620043754575, 0.41429165883064267, 0.41733952760696413, 0.42196220152378083, 0.4258482659339905], 'val_acc': [0.9153, 0.91549999999999998, 0.91410000000000002, 0.91549999999999998, 0.91520000000000001, 0.91449999999999998, 0.91669999999999996, 0.9153, 0.9173, 0.91900000000000004, 0.91949999999999998, 0.91700000000000004, 0.91830000000000001, 0.91620000000000001, 0.91639999999999999, 0.91390000000000005, 0.91659999999999997, 0.91649999999999998, 0.9173, 0.91590000000000005, 0.91720000000000002, 0.92100000000000004, 0.91879999999999995, 0.91710000000000003, 0.9163], 'loss': [0.33727862035038764, 0.33303010469451333, 0.32673505861712526, 0.32136628403662104, 0.32141797855032689, 0.31687941952206056, 0.32132581608739846, 0.31488759906046432, 0.31373697348156532, 0.31178404357825712, 0.31047736725479813, 0.31521823057617404, 0.30662387654419543, 0.30769793578818855, 0.30554917249153318, 0.30145795065353881, 0.30382884719507947, 0.30639415039517459, 0.29898326644386508, 0.30597427415664202, 0.30305908828792105, 0.29884545625996278, 0.29940613503826324, 0.29401900928334851, 0.29605224924589296]}\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.00015,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep150'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 278s 714ms/step - loss: 0.2870 - acc: 0.9412 - val_loss: 0.4162 - val_acc: 0.9182\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2835 - acc: 0.9429 - val_loss: 0.4175 - val_acc: 0.9195\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2789 - acc: 0.9444 - val_loss: 0.4212 - val_acc: 0.9177\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.2799 - acc: 0.9433 - val_loss: 0.4117 - val_acc: 0.9202\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.2759 - acc: 0.9459 - val_loss: 0.4138 - val_acc: 0.9189\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.2746 - acc: 0.9445 - val_loss: 0.4127 - val_acc: 0.9190\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 278s 713ms/step - loss: 0.2779 - acc: 0.9442 - val_loss: 0.4158 - val_acc: 0.9181\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 277s 711ms/step - loss: 0.2701 - acc: 0.9473 - val_loss: 0.4121 - val_acc: 0.9201\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2713 - acc: 0.9466 - val_loss: 0.4185 - val_acc: 0.9190\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2724 - acc: 0.9460 - val_loss: 0.4177 - val_acc: 0.9221\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2762 - acc: 0.9442 - val_loss: 0.4139 - val_acc: 0.9206\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2682 - acc: 0.9465 - val_loss: 0.4167 - val_acc: 0.9201\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2711 - acc: 0.9453 - val_loss: 0.4198 - val_acc: 0.9221\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2719 - acc: 0.9450 - val_loss: 0.4132 - val_acc: 0.9197\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2669 - acc: 0.9482 - val_loss: 0.4115 - val_acc: 0.9217\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2657 - acc: 0.9474 - val_loss: 0.4102 - val_acc: 0.9237\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2637 - acc: 0.9480 - val_loss: 0.4043 - val_acc: 0.9228\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2686 - acc: 0.9462 - val_loss: 0.4092 - val_acc: 0.9211\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2652 - acc: 0.9481 - val_loss: 0.4109 - val_acc: 0.9222\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2600 - acc: 0.9493 - val_loss: 0.4082 - val_acc: 0.9225\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2656 - acc: 0.9475 - val_loss: 0.4136 - val_acc: 0.9211\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2623 - acc: 0.9484 - val_loss: 0.4204 - val_acc: 0.9193\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2601 - acc: 0.9489 - val_loss: 0.4210 - val_acc: 0.9209\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2611 - acc: 0.9489 - val_loss: 0.4097 - val_acc: 0.9229\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2613 - acc: 0.9488 - val_loss: 0.4152 - val_acc: 0.9216\n",
      "{'acc': [0.94122954768020828, 0.94289380811061618, 0.9443776066922055, 0.94327478348386562, 0.94586140515906025, 0.94445781197959433, 0.94423724731497938, 0.94722489577132152, 0.94652309917202737, 0.94602181588681722, 0.94415704200846817, 0.94650304784061901, 0.94538017328174828, 0.94501924931639691, 0.94826756500455867, 0.94744546037856914, 0.94800689769624935, 0.94622232912441151, 0.9480871029645157, 0.94937038821289854, 0.9475056144110392, 0.94844802694898944, 0.94892925886454627, 0.9489092076096276, 0.94884905357715754], 'val_loss': [0.41620316629409793, 0.41747429804801939, 0.42117837700843813, 0.41169154586791989, 0.41380694446563721, 0.4127415421485901, 0.41583897171020506, 0.41213152382373808, 0.41851479830741883, 0.41765020179748535, 0.41392292213439941, 0.41670440366268158, 0.41979966883659364, 0.4131773970603943, 0.41149779958724975, 0.41019836444854735, 0.40434444828033445, 0.4092426626443863, 0.41094058609008788, 0.40817142930030825, 0.41357377405166629, 0.4203918172836304, 0.42095852270126344, 0.40969158325195315, 0.41523648681640624], 'val_acc': [0.91820000000000002, 0.91949999999999998, 0.91769999999999996, 0.92020000000000002, 0.91890000000000005, 0.91900000000000004, 0.91810000000000003, 0.92010000000000003, 0.91900000000000004, 0.92210000000000003, 0.92059999999999997, 0.92010000000000003, 0.92210000000000003, 0.91969999999999996, 0.92169999999999996, 0.92369999999999997, 0.92279999999999995, 0.92110000000000003, 0.92219999980926515, 0.92249999999999999, 0.92110000000000003, 0.91930000000000001, 0.92090000000000005, 0.92290000000000005, 0.92159999999999997], 'loss': [0.28695528870367798, 0.28349563218402218, 0.2788962655852229, 0.27987906339652729, 0.27594354905051838, 0.27464777717404459, 0.27778988370040231, 0.27015703925632839, 0.27134467517484406, 0.272481971820425, 0.27611461926202646, 0.26812466841345228, 0.27106401298456861, 0.27185824452243557, 0.26681445597799153, 0.26575403339039794, 0.26371427599363384, 0.26859212178888708, 0.26515796104607997, 0.26000031520052908, 0.26556603079389829, 0.26214416157292908, 0.26014987515798932, 0.26113017227047713, 0.26129394236152509]}\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000075,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep175'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 279s 715ms/step - loss: 0.2587 - acc: 0.9488 - val_loss: 0.4111 - val_acc: 0.9235\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2525 - acc: 0.9510 - val_loss: 0.4091 - val_acc: 0.9228\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2517 - acc: 0.9526 - val_loss: 0.4114 - val_acc: 0.9234\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2537 - acc: 0.9503 - val_loss: 0.4092 - val_acc: 0.9229\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2494 - acc: 0.9517 - val_loss: 0.4097 - val_acc: 0.9237\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2485 - acc: 0.9523 - val_loss: 0.4096 - val_acc: 0.9237\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2484 - acc: 0.9523 - val_loss: 0.4109 - val_acc: 0.9229\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2479 - acc: 0.9532 - val_loss: 0.4095 - val_acc: 0.9235\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2462 - acc: 0.9531 - val_loss: 0.4099 - val_acc: 0.9226\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2463 - acc: 0.9530 - val_loss: 0.4099 - val_acc: 0.9235\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2452 - acc: 0.9541 - val_loss: 0.4093 - val_acc: 0.9231\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2518 - acc: 0.9516 - val_loss: 0.4085 - val_acc: 0.9231\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2494 - acc: 0.9526 - val_loss: 0.4088 - val_acc: 0.9228\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2428 - acc: 0.9544 - val_loss: 0.4099 - val_acc: 0.9235\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2459 - acc: 0.9532 - val_loss: 0.4117 - val_acc: 0.9226\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2455 - acc: 0.9531 - val_loss: 0.4106 - val_acc: 0.9233\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2456 - acc: 0.9537 - val_loss: 0.4090 - val_acc: 0.9226\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2455 - acc: 0.9530 - val_loss: 0.4102 - val_acc: 0.9227\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2410 - acc: 0.9550 - val_loss: 0.4098 - val_acc: 0.9238\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2442 - acc: 0.9528 - val_loss: 0.4101 - val_acc: 0.9235\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 276s 707ms/step - loss: 0.2465 - acc: 0.9526 - val_loss: 0.4103 - val_acc: 0.9247\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2439 - acc: 0.9542 - val_loss: 0.4091 - val_acc: 0.9248\n",
      "Epoch 23/25\n",
      "390/390 [==============================] - 276s 708ms/step - loss: 0.2441 - acc: 0.9533 - val_loss: 0.4099 - val_acc: 0.9230\n",
      "Epoch 24/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2418 - acc: 0.9554 - val_loss: 0.4092 - val_acc: 0.9232\n",
      "Epoch 25/25\n",
      "390/390 [==============================] - 282s 722ms/step - loss: 0.2414 - acc: 0.9551 - val_loss: 0.4101 - val_acc: 0.9240\n",
      "{'acc': [0.94882900222662669, 0.95099454605697931, 0.9526387551942237, 0.95027269806890946, 0.95171639400680441, 0.95233798522309765, 0.95231793394905651, 0.95326034648700675, 0.95307988448520864, 0.95297962782816659, 0.95408245107475131, 0.95157603464870066, 0.95262419871794868, 0.95443962754618306, 0.95314003853680118, 0.95309993587398434, 0.95368142444658321, 0.95297962782816659, 0.95508501760692677, 0.95283926854655265, 0.95259865255052933, 0.95424286170689621, 0.95330044918806844, 0.95534568491523608, 0.95512820512820518], 'val_loss': [0.41110132126808169, 0.40908146257400513, 0.41141808123588564, 0.40917957463264465, 0.40971894030570982, 0.40960956220626832, 0.41085440487861635, 0.40949423503875731, 0.40988193650245669, 0.40985641078948976, 0.40928388457298281, 0.40847834715843201, 0.4087721936225891, 0.40994238896369933, 0.41167988896369934, 0.41060906605720521, 0.40899055547714236, 0.41019879899024964, 0.40983248414993284, 0.41013530716896057, 0.41025867481231687, 0.40910313687324523, 0.40989697213172915, 0.40916144800186155, 0.41014419736862184], 'val_acc': [0.92349999999999999, 0.92279999999999995, 0.9234, 0.92290000000000005, 0.92369999999999997, 0.92369999999999997, 0.92290000000000005, 0.92349999999999999, 0.92259999999999998, 0.92349999999999999, 0.92310000000000003, 0.92310000000000003, 0.92279999999999995, 0.92349999999999999, 0.92259999999999998, 0.92330000000000001, 0.92259999999999998, 0.92269999999999996, 0.92379999999999995, 0.92349999999999999, 0.92469999999999997, 0.92479999999999996, 0.92300000000000004, 0.92320000000000002, 0.92400000000000004], 'loss': [0.25868932669041134, 0.25260121450616946, 0.25173638081718874, 0.25374424213738944, 0.24943582108856815, 0.24854143094874973, 0.24848475894524114, 0.24790282097618513, 0.24615730705229105, 0.24624318849172278, 0.24527609076758475, 0.25181691412134816, 0.24941155998370587, 0.24278219727537306, 0.24592364478329262, 0.24557967138837308, 0.24552677649697471, 0.24552132424479844, 0.24076718201918751, 0.24413909634260325, 0.2466261138853294, 0.24383033848856747, 0.24415027583720098, 0.2417977853705954, 0.24144373818849907]}\n"
     ]
    }
   ],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000015,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep200'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "390/390 [==============================] - 281s 721ms/step - loss: 0.2442 - acc: 0.9538 - val_loss: 0.4109 - val_acc: 0.9236\n",
      "Epoch 2/25\n",
      "390/390 [==============================] - 278s 714ms/step - loss: 0.2402 - acc: 0.9543 - val_loss: 0.4098 - val_acc: 0.9231\n",
      "Epoch 3/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2404 - acc: 0.9547 - val_loss: 0.4101 - val_acc: 0.9226\n",
      "Epoch 4/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2439 - acc: 0.9538 - val_loss: 0.4103 - val_acc: 0.9229\n",
      "Epoch 5/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2421 - acc: 0.9539 - val_loss: 0.4103 - val_acc: 0.9236\n",
      "Epoch 6/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2383 - acc: 0.9549 - val_loss: 0.4102 - val_acc: 0.9233\n",
      "Epoch 7/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2437 - acc: 0.9538 - val_loss: 0.4103 - val_acc: 0.9238\n",
      "Epoch 8/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2412 - acc: 0.9547 - val_loss: 0.4098 - val_acc: 0.9235\n",
      "Epoch 9/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2424 - acc: 0.9545 - val_loss: 0.4094 - val_acc: 0.9237\n",
      "Epoch 10/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2435 - acc: 0.9543 - val_loss: 0.4089 - val_acc: 0.9236\n",
      "Epoch 11/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2440 - acc: 0.9536 - val_loss: 0.4087 - val_acc: 0.9233\n",
      "Epoch 12/25\n",
      "390/390 [==============================] - 276s 709ms/step - loss: 0.2378 - acc: 0.9563 - val_loss: 0.4094 - val_acc: 0.9231\n",
      "Epoch 13/25\n",
      "390/390 [==============================] - 277s 711ms/step - loss: 0.2387 - acc: 0.9557 - val_loss: 0.4085 - val_acc: 0.9231\n",
      "Epoch 14/25\n",
      "390/390 [==============================] - 281s 719ms/step - loss: 0.2417 - acc: 0.9548 - val_loss: 0.4088 - val_acc: 0.9233\n",
      "Epoch 15/25\n",
      "390/390 [==============================] - 287s 737ms/step - loss: 0.2379 - acc: 0.9567 - val_loss: 0.4093 - val_acc: 0.9237\n",
      "Epoch 16/25\n",
      "390/390 [==============================] - 281s 721ms/step - loss: 0.2418 - acc: 0.9546 - val_loss: 0.4098 - val_acc: 0.9233\n",
      "Epoch 17/25\n",
      "390/390 [==============================] - 281s 721ms/step - loss: 0.2409 - acc: 0.9546 - val_loss: 0.4096 - val_acc: 0.9238\n",
      "Epoch 18/25\n",
      "390/390 [==============================] - 279s 715ms/step - loss: 0.2433 - acc: 0.9531 - val_loss: 0.4099 - val_acc: 0.9228\n",
      "Epoch 19/25\n",
      "390/390 [==============================] - 278s 714ms/step - loss: 0.2381 - acc: 0.9553 - val_loss: 0.4101 - val_acc: 0.9232\n",
      "Epoch 20/25\n",
      "390/390 [==============================] - 279s 715ms/step - loss: 0.2387 - acc: 0.9559 - val_loss: 0.4104 - val_acc: 0.9233\n",
      "Epoch 21/25\n",
      "390/390 [==============================] - 283s 726ms/step - loss: 0.2344 - acc: 0.9562 - val_loss: 0.4114 - val_acc: 0.9238\n",
      "Epoch 22/25\n",
      "390/390 [==============================] - 281s 721ms/step - loss: 0.2409 - acc: 0.9544 - val_loss: 0.4117 - val_acc: 0.9229\n",
      "Epoch 23/25\n",
      " 93/390 [======>.......................] - ETA: 3:24 - loss: 0.2296 - acc: 0.9620"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(uid, i)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    760\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    870\u001b[0m         batch_x = np.zeros(tuple([len(index_array)] + list(self.x.shape)[1:]),\n\u001b[1;32m--> 871\u001b[1;33m                            dtype=K.floatx())\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fc309f97604d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt_rms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         metrics=['accuracy'])\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'KaggLeNet_normal_rms_ep225'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mact_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights('KaggLeNet_normal_rms_ep200'+act_name+'.h5')\n",
    "\n",
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep225'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue for 25 epochs more\n",
    "batch_size = 128\n",
    "epochs=25\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.0000015,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('KaggLeNet_normal_rms_ep250'+act_name+'.h5')\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x) - np.amax(x)\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "(10000, 10)\n",
      "[[ -4.90083042e-06  -4.49831680e-06  -4.81777193e-06 ...,  -4.91496108e-06\n",
      "   -4.86961810e-06  -4.92445519e-06]\n",
      " [ -4.88604739e-08   8.74079187e-07  -2.49583755e-07 ...,  -2.49658926e-07\n",
      "    1.00000092e+00  -2.47317021e-07]\n",
      " [ -4.98662597e-05   8.86949022e-03  -9.17242644e-05 ...,  -9.12299545e-05\n",
      "    9.91811430e-01  -8.20444685e-05]\n",
      " ..., \n",
      " [ -7.29081978e-05  -7.25324876e-05  -1.25106549e-05 ...,  -6.97059817e-05\n",
      "   -7.22895147e-05  -7.24782733e-05]\n",
      " [ -9.70507635e-06   1.00008639e+00  -8.69566493e-06 ...,  -9.81943587e-06\n",
      "   -9.91263143e-06  -9.94954674e-06]\n",
      " [ -2.94160565e-05  -2.87808958e-05  -2.93322451e-05 ...,   1.00026233e+00\n",
      "   -2.90999918e-05  -2.96926985e-05]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cifar_10_logs_1.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "new_content = []\n",
    "for i, l in enumerate(content):\n",
    "    # Merge lines\n",
    "    if l[:4] == \"INFO\":\n",
    "        try:\n",
    "            l = content[i]\n",
    "            l = l[33:-2]\n",
    "            if i+2 < len(content):\n",
    "                if content[i+2][:4] == \"INFO\":\n",
    "    #             print(\"hey\")\n",
    "                    l += content[i+1][:-2]\n",
    "                else:\n",
    "                    l += content[i+1][:-2]\n",
    "                    l += content[i+2][:-2]\n",
    "            else:\n",
    "                    l += content[i+1][:-2]\n",
    "\n",
    "            # Clean unwanted characters\n",
    "            for char in [\"[\", \"]\", \",\"]:\n",
    "    #             print(\"replacing: \"+ char, l)\n",
    "                l.replace(char, \" \")\n",
    "    #             print(l)\n",
    "\n",
    "            parts = l.split(\" \")\n",
    "    #         print(parts)\n",
    "            # Convert to array\n",
    "            lol = []\n",
    "            for p in parts:\n",
    "                try:\n",
    "                    lol.append(float(p))\n",
    "                except:pass\n",
    "    #         print(lol)\n",
    "            hello = np.array(lol)\n",
    "    #         print(hello, hello.shape)\n",
    "            if hello.shape[0] != 10:\n",
    "                print(\"LOL\")\n",
    "                break\n",
    "            new_content.append(softmax(hello))\n",
    "            \n",
    "        except:pass\n",
    "            \n",
    "    else: pass\n",
    "    \n",
    "    if i%1000 == 0: print(\"1000 more\")\n",
    "        \n",
    "print(np.array(new_content).shape)\n",
    "cleaned = np.array(new_content)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembler = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembler += cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "(10000, 10)\n",
      "[[ -6.88311285e-09  -6.82021809e-09  -6.71568857e-09 ...,  -6.90769316e-09\n",
      "   -6.89457826e-09  -6.91148780e-09]\n",
      " [ -4.51994275e-08   2.82880900e-07  -6.16410693e-08 ...,  -6.16259045e-08\n",
      "    1.00000019e+00  -6.14057739e-08]\n",
      " [ -5.23434323e-04   1.54378808e-02  -6.01702816e-04 ...,  -5.83987867e-04\n",
      "    9.89013143e-01  -3.33328514e-04]\n",
      " ..., \n",
      " [ -6.93338813e-06  -6.80913658e-06  -6.74814784e-06 ...,   1.72600785e-03\n",
      "   -6.88697996e-06  -6.84799566e-06]\n",
      " [ -6.54411366e-06   1.00004902e+00   3.78909490e-06 ...,  -6.53696053e-06\n",
      "   -6.65006164e-06  -6.64101143e-06]\n",
      " [ -1.03540179e-05  -1.01708944e-05  -1.03501255e-05 ...,   1.00008875e+00\n",
      "   -1.03910003e-05  -9.84605584e-06]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cifar_10_logs_2.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "new_content_2 = []\n",
    "for i, l in enumerate(content):\n",
    "    # Merge lines\n",
    "    if l[:4] == \"INFO\":\n",
    "        try:\n",
    "            l = content[i]\n",
    "            l = l[33:-2]\n",
    "            if i+2 < len(content):\n",
    "                if content[i+2][:4] == \"INFO\":\n",
    "    #             print(\"hey\")\n",
    "                    l += content[i+1][:-2]\n",
    "                else:\n",
    "                    l += content[i+1][:-2]\n",
    "                    l += content[i+2][:-2]\n",
    "            else:\n",
    "                    l += content[i+1][:-2]\n",
    "\n",
    "            # Clean unwanted characters\n",
    "            for char in [\"[\", \"]\", \",\"]:\n",
    "    #             print(\"replacing: \"+ char, l)\n",
    "                l.replace(char, \" \")\n",
    "    #             print(l)\n",
    "\n",
    "            parts = l.split(\" \")\n",
    "    #         print(parts)\n",
    "            # Convert to array\n",
    "            lol = []\n",
    "            for p in parts:\n",
    "                try:\n",
    "                    lol.append(float(p))\n",
    "                except:pass\n",
    "    #         print(lol)\n",
    "            hello = np.array(lol)\n",
    "    #         print(hello, hello.shape)\n",
    "            if hello.shape[0] != 10:\n",
    "                print(\"LOL\")\n",
    "                break\n",
    "            new_content_2.append(softmax(hello))\n",
    "            \n",
    "        except:pass\n",
    "            \n",
    "    else: pass\n",
    "    \n",
    "    if i%1000 == 0: print(\"1000 more\")\n",
    "        \n",
    "print(np.array(new_content_2).shape)\n",
    "cleaned_2 = np.array(new_content_2)\n",
    "print(cleaned_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensembler += cleaned_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "1000 more\n",
      "(10000, 10)\n",
      "[[ -1.57441159e-06  -1.57772741e-06  -1.45891873e-06 ...,  -1.59082624e-06\n",
      "   -1.58431145e-06  -1.59152312e-06]\n",
      " [  3.35313626e-07   2.62089756e-05  -1.70342628e-06 ...,  -1.70323368e-06\n",
      "    9.99985350e-01  -1.69302179e-06]\n",
      " [  6.57110095e-04   6.19226593e-03  -3.55112923e-04 ...,  -3.51745563e-04\n",
      "    9.95548429e-01  -2.72781988e-04]\n",
      " ..., \n",
      " [ -6.46500489e-06  -6.44906528e-06  -6.08788953e-06 ...,  -5.89226992e-06\n",
      "   -6.45000146e-06  -6.44374483e-06]\n",
      " [ -4.90078489e-05   1.00040277e+00  -1.11118866e-05 ...,  -4.76586889e-05\n",
      "   -4.91237558e-05  -4.93641643e-05]\n",
      " [ -2.99193856e-06  -2.99422431e-06  -2.96956578e-06 ...,   1.00002660e+00\n",
      "   -3.02093184e-06  -2.95644880e-06]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cifar_10_logs_3.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "new_content_3 = []\n",
    "for i, l in enumerate(content):\n",
    "    # Merge lines\n",
    "    if l[:4] == \"INFO\":\n",
    "        try:\n",
    "            l = content[i]\n",
    "            l = l[33:-2]\n",
    "            if i+2 < len(content):\n",
    "                if content[i+2][:4] == \"INFO\":\n",
    "    #             print(\"hey\")\n",
    "                    l += content[i+1][:-2]\n",
    "                else:\n",
    "                    l += content[i+1][:-2]\n",
    "                    l += content[i+2][:-2]\n",
    "            else:\n",
    "                    l += content[i+1][:-2]\n",
    "\n",
    "            # Clean unwanted characters\n",
    "            for char in [\"[\", \"]\", \",\"]:\n",
    "    #             print(\"replacing: \"+ char, l)\n",
    "                l.replace(char, \" \")\n",
    "    #             print(l)\n",
    "\n",
    "            parts = l.split(\" \")\n",
    "    #         print(parts)\n",
    "            # Convert to array\n",
    "            lol = []\n",
    "            for p in parts:\n",
    "                try:\n",
    "                    lol.append(float(p))\n",
    "                except:pass\n",
    "    #         print(lol)\n",
    "            hello = np.array(lol)\n",
    "    #         print(hello, hello.shape)\n",
    "            if hello.shape[0] != 10:\n",
    "                print(\"LOL\")\n",
    "                break\n",
    "            new_content_3.append(softmax(hello))\n",
    "            \n",
    "        except:pass\n",
    "            \n",
    "    else: pass\n",
    "    \n",
    "    if i%1000 == 0: print(\"1000 more\")\n",
    "        \n",
    "print(np.array(new_content_3).shape)\n",
    "cleaned_3 = np.array(new_content_3)\n",
    "print(cleaned_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensembler += cleaned_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ensembled, y_test):\n",
    "    y_hat = np.argmax(ensembled/3, axis=1)\n",
    "    y = np.argmax(y_test, axis=1)\n",
    "\n",
    "    good = np.sum(np.equal(y, y_hat))\n",
    "    return float(good/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(ensembler, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(ensembler-cleaned, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(ensembler-cleaned_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(ensembler-cleaned_3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

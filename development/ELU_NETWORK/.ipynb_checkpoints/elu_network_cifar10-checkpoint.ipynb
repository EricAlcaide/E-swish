{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# Create Validation set\n",
    "x_train, x_val = x_train[:45000], x_train[45000:]\n",
    "y_train, y_val = y_train[:45000], y_train[45000:]\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_val = (x_val-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_val = np_utils.to_categorical(y_val,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e_swish_2 custom activation\n",
    "def e_swish_2(x):\n",
    "    return K.maximum(x*K.sigmoid(x), x*(2-K.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create(act):\n",
    "# ELU NETWORK CIFAR-100 VERSION\n",
    "    weight_decay = 0.0005\n",
    "    \n",
    "    model = Sequential()\n",
    "    # First stack\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Second stack\n",
    "    model.add(Conv2D(128, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(128, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Third stack\n",
    "    model.add(Conv2D(200, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Fourth stack\n",
    "    model.add(Conv2D(220, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Fifth stack\n",
    "    model.add(Conv2D(240, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Sixth stack\n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(264, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.4))\n",
    "                     \n",
    "    # Sixth Seventh stack\n",
    "    model.add(Conv2D(364, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # and last stack\n",
    "    model.add(Conv2D(10, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(x):\n",
    "    if x<30:\n",
    "        return 0.01\n",
    "    elif x<45:\n",
    "        return 0.005\n",
    "    elif x<60:\n",
    "        return 0.001\n",
    "    elif x<70:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 200)       102600    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 200)       160200    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 200)         40200     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 220)         176220    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 220)         48620     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 220)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 240)         475440    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 2, 240)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 256)         246016    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1, 1, 256)         65792     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 264)         67848     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1, 1, 264)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 264)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 1, 1, 364)         96460     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1, 1, 364)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 364)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 1, 1, 10)          3650      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,606,486\n",
      "Trainable params: 2,606,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create(e_swish_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 1/75\n",
      "450/450 [==============================] - 394s 876ms/step - loss: 3.7861 - acc: 0.2060 - val_loss: 3.4180 - val_acc: 0.3512\n",
      "Epoch 2/75\n",
      "450/450 [==============================] - 388s 863ms/step - loss: 3.2876 - acc: 0.3483 - val_loss: 2.9618 - val_acc: 0.4610\n",
      "Epoch 3/75\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 2.9291 - acc: 0.4631 - val_loss: 2.6687 - val_acc: 0.5610\n",
      "Epoch 4/75\n",
      "450/450 [==============================] - 384s 854ms/step - loss: 2.6614 - acc: 0.5424 - val_loss: 2.4109 - val_acc: 0.6036\n",
      "Epoch 5/75\n",
      "450/450 [==============================] - 384s 854ms/step - loss: 2.4527 - acc: 0.5895 - val_loss: 2.1801 - val_acc: 0.6702\n",
      "Epoch 6/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 2.2810 - acc: 0.6240 - val_loss: 2.1292 - val_acc: 0.6762\n",
      "Epoch 7/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 2.1189 - acc: 0.6532 - val_loss: 1.8523 - val_acc: 0.7284\n",
      "Epoch 8/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 2.0011 - acc: 0.6736 - val_loss: 1.7441 - val_acc: 0.7460\n",
      "Epoch 9/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.8807 - acc: 0.6936 - val_loss: 1.6673 - val_acc: 0.7512\n",
      "Epoch 10/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.7772 - acc: 0.7092 - val_loss: 1.5904 - val_acc: 0.7652\n",
      "Epoch 11/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.6949 - acc: 0.7242 - val_loss: 1.4681 - val_acc: 0.7938\n",
      "Epoch 12/75\n",
      "450/450 [==============================] - 388s 862ms/step - loss: 1.6174 - acc: 0.7322 - val_loss: 1.4055 - val_acc: 0.7984\n",
      "Epoch 13/75\n",
      "450/450 [==============================] - 389s 863ms/step - loss: 1.5426 - acc: 0.7451 - val_loss: 1.3261 - val_acc: 0.8070\n",
      "Epoch 14/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.4711 - acc: 0.7578 - val_loss: 1.2811 - val_acc: 0.8094\n",
      "Epoch 15/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.4170 - acc: 0.7611 - val_loss: 1.2395 - val_acc: 0.8108\n",
      "Epoch 16/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.3627 - acc: 0.7708 - val_loss: 1.1795 - val_acc: 0.8208\n",
      "Epoch 17/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.3186 - acc: 0.7741 - val_loss: 1.1779 - val_acc: 0.8092\n",
      "Epoch 18/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.2779 - acc: 0.7779 - val_loss: 1.1172 - val_acc: 0.8234\n",
      "Epoch 19/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.2331 - acc: 0.7851 - val_loss: 1.0877 - val_acc: 0.8296\n",
      "Epoch 20/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.2114 - acc: 0.7872 - val_loss: 1.0520 - val_acc: 0.8342\n",
      "Epoch 21/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.1671 - acc: 0.7944 - val_loss: 1.0477 - val_acc: 0.8322\n",
      "Epoch 22/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.1393 - acc: 0.7966 - val_loss: 0.9705 - val_acc: 0.8452\n",
      "Epoch 23/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.1050 - acc: 0.8031 - val_loss: 0.9894 - val_acc: 0.8374\n",
      "Epoch 24/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.0869 - acc: 0.8036 - val_loss: 0.9274 - val_acc: 0.8524\n",
      "Epoch 25/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.0611 - acc: 0.8081 - val_loss: 0.9183 - val_acc: 0.8534\n",
      "Epoch 26/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.0381 - acc: 0.8118 - val_loss: 0.9623 - val_acc: 0.8296\n",
      "Epoch 27/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.0209 - acc: 0.8121 - val_loss: 0.8851 - val_acc: 0.8520\n",
      "Epoch 28/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 1.0053 - acc: 0.8139 - val_loss: 0.8899 - val_acc: 0.8474\n",
      "Epoch 29/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.9871 - acc: 0.8170 - val_loss: 0.8936 - val_acc: 0.8478\n",
      "Epoch 30/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.9747 - acc: 0.8179 - val_loss: 0.8647 - val_acc: 0.8486\n",
      "Epoch 31/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8876 - acc: 0.8451 - val_loss: 0.8090 - val_acc: 0.8714\n",
      "Epoch 32/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8537 - acc: 0.8542 - val_loss: 0.7995 - val_acc: 0.8656\n",
      "Epoch 33/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8370 - acc: 0.8587 - val_loss: 0.7652 - val_acc: 0.8760\n",
      "Epoch 34/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8335 - acc: 0.8559 - val_loss: 0.7537 - val_acc: 0.8744\n",
      "Epoch 35/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8162 - acc: 0.8590 - val_loss: 0.7584 - val_acc: 0.8740\n",
      "Epoch 36/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8057 - acc: 0.8606 - val_loss: 0.7383 - val_acc: 0.8768\n",
      "Epoch 37/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8014 - acc: 0.8594 - val_loss: 0.7330 - val_acc: 0.8778\n",
      "Epoch 38/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.8015 - acc: 0.8592 - val_loss: 0.7353 - val_acc: 0.8772\n",
      "Epoch 39/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7904 - acc: 0.8625 - val_loss: 0.7319 - val_acc: 0.8750\n",
      "Epoch 40/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7811 - acc: 0.8646 - val_loss: 0.7291 - val_acc: 0.8762\n",
      "Epoch 41/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7736 - acc: 0.8665 - val_loss: 0.7069 - val_acc: 0.8800\n",
      "Epoch 42/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7699 - acc: 0.8649 - val_loss: 0.7119 - val_acc: 0.8832\n",
      "Epoch 43/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7687 - acc: 0.8638 - val_loss: 0.6937 - val_acc: 0.8858\n",
      "Epoch 44/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7579 - acc: 0.8656 - val_loss: 0.7001 - val_acc: 0.8828\n",
      "Epoch 45/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.7514 - acc: 0.8682 - val_loss: 0.6977 - val_acc: 0.8828\n",
      "Epoch 46/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6833 - acc: 0.8894 - val_loss: 0.6517 - val_acc: 0.8970\n",
      "Epoch 47/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6610 - acc: 0.8972 - val_loss: 0.6428 - val_acc: 0.9006\n",
      "Epoch 48/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6542 - acc: 0.8994 - val_loss: 0.6361 - val_acc: 0.8996\n",
      "Epoch 49/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6427 - acc: 0.9012 - val_loss: 0.6365 - val_acc: 0.8986\n",
      "Epoch 50/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6414 - acc: 0.9016 - val_loss: 0.6447 - val_acc: 0.9022\n",
      "Epoch 51/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6360 - acc: 0.9037 - val_loss: 0.6470 - val_acc: 0.8998\n",
      "Epoch 52/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6382 - acc: 0.9026 - val_loss: 0.6352 - val_acc: 0.9002\n",
      "Epoch 53/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6302 - acc: 0.9039 - val_loss: 0.6307 - val_acc: 0.8994\n",
      "Epoch 54/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6303 - acc: 0.9036 - val_loss: 0.6397 - val_acc: 0.8968\n",
      "Epoch 55/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6271 - acc: 0.9039 - val_loss: 0.6311 - val_acc: 0.9016\n",
      "Epoch 56/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6234 - acc: 0.9050 - val_loss: 0.6266 - val_acc: 0.9008\n",
      "Epoch 57/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6199 - acc: 0.9067 - val_loss: 0.6216 - val_acc: 0.9002\n",
      "Epoch 58/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6175 - acc: 0.9062 - val_loss: 0.6221 - val_acc: 0.9022\n",
      "Epoch 59/75\n",
      "450/450 [==============================] - 386s 857ms/step - loss: 0.6166 - acc: 0.9059 - val_loss: 0.6147 - val_acc: 0.9066\n",
      "Epoch 60/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6115 - acc: 0.9068 - val_loss: 0.6187 - val_acc: 0.9050\n",
      "Epoch 61/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.6020 - acc: 0.9108 - val_loss: 0.6144 - val_acc: 0.9064\n",
      "Epoch 62/75\n",
      "450/450 [==============================] - 388s 863ms/step - loss: 0.5943 - acc: 0.9127 - val_loss: 0.6095 - val_acc: 0.9066\n",
      "Epoch 63/75\n",
      "450/450 [==============================] - 387s 860ms/step - loss: 0.5922 - acc: 0.9118 - val_loss: 0.6136 - val_acc: 0.9064\n",
      "Epoch 64/75\n",
      "450/450 [==============================] - 388s 862ms/step - loss: 0.5921 - acc: 0.9125 - val_loss: 0.6028 - val_acc: 0.9054\n",
      "Epoch 65/75\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5873 - acc: 0.9139 - val_loss: 0.6048 - val_acc: 0.9062\n",
      "Epoch 66/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5878 - acc: 0.9152 - val_loss: 0.6142 - val_acc: 0.9060\n",
      "Epoch 67/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5872 - acc: 0.9149 - val_loss: 0.5985 - val_acc: 0.9108\n",
      "Epoch 68/75\n",
      "450/450 [==============================] - 388s 862ms/step - loss: 0.5824 - acc: 0.9150 - val_loss: 0.5990 - val_acc: 0.9102\n",
      "Epoch 69/75\n",
      "450/450 [==============================] - 388s 862ms/step - loss: 0.5849 - acc: 0.9141 - val_loss: 0.6009 - val_acc: 0.9092\n",
      "Epoch 70/75\n",
      "450/450 [==============================] - 386s 858ms/step - loss: 0.5826 - acc: 0.9156 - val_loss: 0.5988 - val_acc: 0.9080\n",
      "Epoch 71/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5745 - acc: 0.9171 - val_loss: 0.5933 - val_acc: 0.9108\n",
      "Epoch 72/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5701 - acc: 0.9180 - val_loss: 0.5932 - val_acc: 0.9100\n",
      "Epoch 73/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5667 - acc: 0.9207 - val_loss: 0.5958 - val_acc: 0.9110\n",
      "Epoch 74/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5706 - acc: 0.9189 - val_loss: 0.5968 - val_acc: 0.9086\n",
      "Epoch 75/75\n",
      "450/450 [==============================] - 385s 855ms/step - loss: 0.5676 - acc: 0.9198 - val_loss: 0.5945 - val_acc: 0.9108\n",
      "{'val_loss': [3.4180096435546874, 2.9617562532424926, 2.6686686754226683, 2.4109007787704466, 2.1800960135459899, 2.1291854476928709, 1.85231379032135, 1.7440691232681274, 1.6672645592689515, 1.5903859066963195, 1.4680691099166869, 1.4054782915115356, 1.3261352372169495, 1.2810584926605224, 1.2394934272766114, 1.1795160293579101, 1.1779083395004273, 1.1171590900421142, 1.0877167701721191, 1.0519733703136445, 1.0477320182323455, 0.97045793175697326, 0.98935461878776554, 0.92739244461059567, 0.91831254959106445, 0.96225921630859379, 0.88512948751449583, 0.88990189433097844, 0.89360536813735958, 0.8647018027305603, 0.80897120475769047, 0.7994749188423157, 0.76523714661598208, 0.75367153286933897, 0.75840578079223631, 0.73825491666793819, 0.73295528888702388, 0.73528701543807984, 0.73187303304672247, 0.72914726972579957, 0.7069307017326355, 0.71185798406600953, 0.6937472796440125, 0.700071280002594, 0.69765126824378965, 0.65174385547637936, 0.64279934048652654, 0.63613726317882535, 0.63652917206287385, 0.64470057606697084, 0.64698726713657384, 0.63516106545925144, 0.63068788766860961, 0.63968972682952885, 0.63109722316265104, 0.6265544611215591, 0.62163981199264529, 0.6220624506473541, 0.61465329825878146, 0.61865644454956059, 0.61443854868412018, 0.6094885647296906, 0.6135600709915161, 0.60277822375297552, 0.60480222105979919, 0.61418083250522615, 0.59853638470172887, 0.59898616552352901, 0.60090219318866733, 0.59884171307086942, 0.59332107782363896, 0.59315010309219363, 0.59577043354511261, 0.59681783318519588, 0.59447622776031495], 'acc': [0.20595555550936195, 0.34831111182769142, 0.46306666420565712, 0.54239999738004474, 0.58948888619740802, 0.6240444434351391, 0.65319999972979226, 0.67357777992884316, 0.69355555706553984, 0.70915555848015677, 0.72422222362624278, 0.73217777914471094, 0.74506666739781702, 0.75777777751286823, 0.76113333317968579, 0.7708222222328186, 0.77411111023690971, 0.77788888679610357, 0.78511110928323535, 0.78722222142749365, 0.79444444179534912, 0.79657777600818214, 0.80313333061006331, 0.80359999895095824, 0.80811110933621721, 0.81182222207387289, 0.81213333010673527, 0.81388888703452211, 0.81702221949895226, 0.81791110899713304, 0.84513333254390288, 0.85424444198608396, 0.85866666595141095, 0.8559333329730564, 0.85902222156524655, 0.86055555383364357, 0.85940000004238548, 0.85924444384045073, 0.86248888889948527, 0.86462222205268013, 0.86653333346048989, 0.86491111040115354, 0.86379999929004248, 0.86564444422721865, 0.868177776866489, 0.88935555564032664, 0.8971555560164981, 0.89940000110202367, 0.90117777930365672, 0.90157777971691555, 0.90371111128065318, 0.90264444549878442, 0.90386666682031425, 0.90355555719799463, 0.90386666695276896, 0.90504444744851853, 0.90673333393202893, 0.90624444590674502, 0.90591111156675552, 0.90677777820163308, 0.91082222236527333, 0.91273333509763077, 0.91184444758627148, 0.91253333449363705, 0.91388889047834609, 0.91515555845366581, 0.91491111358006794, 0.91502222405539624, 0.9140888909498851, 0.91560000128216212, 0.91713333699438304, 0.91804444577958844, 0.92068889088100858, 0.91888888994852702, 0.91980000244246585], 'val_acc': [0.35120000153779984, 0.46099999368190764, 0.56099999845027926, 0.60360000729560848, 0.67020000338554386, 0.67620000481605524, 0.72840000391006465, 0.74600000381469722, 0.75120000123977659, 0.76519999742507938, 0.79379999876022334, 0.79839999914169313, 0.80699999570846559, 0.80939999938011165, 0.810799994468689, 0.8207999992370606, 0.8091999971866608, 0.82340000152587889, 0.8295999979972839, 0.83419999718666071, 0.83219999432563785, 0.84519999623298647, 0.83740000247955326, 0.85239999651908871, 0.85340000152587892, 0.8295999979972839, 0.85200000166893008, 0.84739999532699584, 0.84780000209808348, 0.84860000014305115, 0.87139999866485596, 0.86559999465942383, 0.87600000262260436, 0.8743999993801117, 0.87400000214576723, 0.87679999828338628, 0.87779999613761905, 0.87720000267028808, 0.87500000119209287, 0.87620000004768372, 0.88, 0.88320000171661373, 0.88580000162124639, 0.88279999732971193, 0.88280000329017638, 0.89700000762939458, 0.90060000419616704, 0.8996000003814697, 0.89860000252723693, 0.90220000505447384, 0.89980000257492065, 0.90020000219345098, 0.89940000414848331, 0.89679999947547917, 0.90160000085830694, 0.90080000042915342, 0.90019999742507939, 0.90220000386238097, 0.90660000205039981, 0.90500000000000003, 0.90640000104904173, 0.90660000085830683, 0.90640000224113459, 0.90540000081062322, 0.90620000243186949, 0.90600000143051151, 0.91080000400543215, 0.91020000457763672, 0.90920000195503237, 0.90800000309944151, 0.9108000016212463, 0.9100000011920929, 0.91100000143051152, 0.90860000252723694, 0.91080000042915343], 'loss': [3.7861436870363026, 3.2875720855924819, 2.9290728341208565, 2.6614321215947467, 2.4527160257763332, 2.2810296699735852, 2.1188822213808693, 2.0010797805256315, 1.8806868282953899, 1.7771758641137017, 1.6949132900767856, 1.6174392006132339, 1.5425786428981356, 1.4711050409740871, 1.4170282832781473, 1.3626665340529547, 1.3186476368374294, 1.2778707347975837, 1.2331433129310607, 1.2114459792772929, 1.1670895153946346, 1.1393436319298214, 1.1050321520699395, 1.0869200172689226, 1.0610844075679779, 1.0381148617797429, 1.0208977243635389, 1.0053167066309188, 0.98707654688093394, 0.97468894018067254, 0.887568197382821, 0.85370375567012358, 0.83696812563472323, 0.83350509630309211, 0.81620885146988764, 0.80572402265336773, 0.80140185965432065, 0.80153723597526549, 0.79036064479086132, 0.78107603814866811, 0.77359434498680968, 0.76987905926174582, 0.76865999195310808, 0.7579436465104421, 0.7514077927006616, 0.68329600175221761, 0.66096318165461221, 0.65418305178483327, 0.64265293127960632, 0.64140776402420463, 0.63598300569587285, 0.6381594312191009, 0.63020911720063955, 0.63028280278046922, 0.62708567188845743, 0.62338142520851558, 0.61985485262340967, 0.61752759158611292, 0.61658970057964324, 0.61152038428518507, 0.60196074320210347, 0.59429194264941743, 0.59223247521453437, 0.59205171174473237, 0.58726973613103228, 0.58777501867877113, 0.58723654667536418, 0.5824104287889269, 0.58490353782971705, 0.5826417134867774, 0.57445207946830323, 0.57007600115405188, 0.56666431321038135, 0.57056108315785725, 0.56760807169808281]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 28s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "batch_size  = 100\n",
    "epochs = 75\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "\n",
    "####################\n",
    "# Network training #\n",
    "####################\n",
    "                     \n",
    "print(\"Gonna fit the model\")\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                          epochs=epochs,verbose=1,validation_data=(x_val,y_val), callbacks=[lr_1])\n",
    "print(his.history)\n",
    "model.evaluate(x_test, y_test)\n",
    "model.save('elu_network_mod_e_swish_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"elu_network_mod_e_swish_2.h5\", custom_objects={\"e_swish_2\": e_swish_2})\n",
    "model.save_weights(\"elu_network_mod_e_swish_2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.61119878511428838, 0.90890000000000004]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(his.history)\n",
    "# model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"elu_network_mod_e_swish_2.h5\", custom_objects={\"e_swish_2\": e_swish_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(x):\n",
    "    if x<30:\n",
    "        return 0.01\n",
    "    elif x<45:\n",
    "        return 0.005\n",
    "    elif x<60:\n",
    "        return 0.001\n",
    "    elif x<70:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        # Start from epoch 80\n",
    "        if x<90:\n",
    "            return 0.0001\n",
    "        elif x<105:\n",
    "            return 0.0001/10\n",
    "        else:\n",
    "            return 0.0001/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 81/120\n",
      "450/450 [==============================] - 395s 877ms/step - loss: 0.5659 - acc: 0.9196 - val_loss: 0.5927 - val_acc: 0.9100\n",
      "Epoch 82/120\n",
      "450/450 [==============================] - 388s 863ms/step - loss: 0.5672 - acc: 0.9184 - val_loss: 0.5934 - val_acc: 0.9096\n",
      "Epoch 83/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5659 - acc: 0.9194 - val_loss: 0.5912 - val_acc: 0.9106\n",
      "Epoch 84/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5666 - acc: 0.9210 - val_loss: 0.5922 - val_acc: 0.9090\n",
      "Epoch 85/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5675 - acc: 0.9198 - val_loss: 0.5951 - val_acc: 0.9074\n",
      "Epoch 86/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5665 - acc: 0.9202 - val_loss: 0.5929 - val_acc: 0.9096\n",
      "Epoch 87/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5621 - acc: 0.9214 - val_loss: 0.5919 - val_acc: 0.9104\n",
      "Epoch 88/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5648 - acc: 0.9210 - val_loss: 0.5919 - val_acc: 0.9090\n",
      "Epoch 89/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5589 - acc: 0.9223 - val_loss: 0.5921 - val_acc: 0.9088\n",
      "Epoch 90/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5676 - acc: 0.9196 - val_loss: 0.5905 - val_acc: 0.9078\n",
      "Epoch 91/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5621 - acc: 0.9215 - val_loss: 0.5897 - val_acc: 0.9100\n",
      "Epoch 92/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5623 - acc: 0.9208 - val_loss: 0.5904 - val_acc: 0.9098\n",
      "Epoch 93/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5612 - acc: 0.9212 - val_loss: 0.5900 - val_acc: 0.9098\n",
      "Epoch 94/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5619 - acc: 0.9203 - val_loss: 0.5898 - val_acc: 0.9106\n",
      "Epoch 95/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5603 - acc: 0.9219 - val_loss: 0.5898 - val_acc: 0.9108\n",
      "Epoch 96/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5574 - acc: 0.9221 - val_loss: 0.5898 - val_acc: 0.9104\n",
      "Epoch 97/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5638 - acc: 0.9213 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 98/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5603 - acc: 0.9216 - val_loss: 0.5891 - val_acc: 0.9102\n",
      "Epoch 99/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5586 - acc: 0.9218 - val_loss: 0.5897 - val_acc: 0.9108\n",
      "Epoch 100/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5637 - acc: 0.9206 - val_loss: 0.5892 - val_acc: 0.9104\n",
      "Epoch 101/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5622 - acc: 0.9206 - val_loss: 0.5897 - val_acc: 0.9106\n",
      "Epoch 102/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5627 - acc: 0.9207 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 103/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5582 - acc: 0.9223 - val_loss: 0.5893 - val_acc: 0.9106\n",
      "Epoch 104/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5599 - acc: 0.9211 - val_loss: 0.5898 - val_acc: 0.9106\n",
      "Epoch 105/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5648 - acc: 0.9195 - val_loss: 0.5896 - val_acc: 0.9100\n",
      "Epoch 106/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5589 - acc: 0.9218 - val_loss: 0.5896 - val_acc: 0.9104\n",
      "Epoch 107/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5597 - acc: 0.9222 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 108/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5585 - acc: 0.9215 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 109/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5591 - acc: 0.9224 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 110/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5618 - acc: 0.9207 - val_loss: 0.5896 - val_acc: 0.9102\n",
      "Epoch 111/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5633 - acc: 0.9206 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 112/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5586 - acc: 0.9222 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 113/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5562 - acc: 0.9236 - val_loss: 0.5896 - val_acc: 0.9104\n",
      "Epoch 114/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5593 - acc: 0.9209 - val_loss: 0.5896 - val_acc: 0.9102\n",
      "Epoch 115/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5619 - acc: 0.9213 - val_loss: 0.5896 - val_acc: 0.9102\n",
      "Epoch 116/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5603 - acc: 0.9212 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 117/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5627 - acc: 0.9208 - val_loss: 0.5895 - val_acc: 0.9106\n",
      "Epoch 118/120\n",
      "450/450 [==============================] - 387s 859ms/step - loss: 0.5603 - acc: 0.9217 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 119/120\n",
      "450/450 [==============================] - 388s 862ms/step - loss: 0.5596 - acc: 0.9220 - val_loss: 0.5895 - val_acc: 0.9104\n",
      "Epoch 120/120\n",
      "450/450 [==============================] - 394s 875ms/step - loss: 0.5583 - acc: 0.9212 - val_loss: 0.5896 - val_acc: 0.9104\n",
      "{'val_loss': [0.59273950338363646, 0.59337999045848844, 0.59118726015090939, 0.59217577099800112, 0.59514105319976807, 0.59291731894016264, 0.59191731214523313, 0.5919023078680038, 0.59207700431346888, 0.59049780011177067, 0.58972027301788332, 0.59038996577262881, 0.59001314342021938, 0.5898476475477219, 0.58979859948158264, 0.58978336215019223, 0.58945567548274991, 0.58911741733551026, 0.58971272826194765, 0.58922819495201106, 0.58965066373348241, 0.58951316177845003, 0.58926602602005007, 0.58976851880550385, 0.58961675584316253, 0.58960773825645452, 0.5895047008991241, 0.58950755715370173, 0.58954922139644628, 0.5895906120538712, 0.58950986981391906, 0.58953854560852048, 0.58959236502647405, 0.589600527882576, 0.5895757067203522, 0.58954369485378266, 0.5895197677612305, 0.58949521064758303, 0.58951794624328613, 0.58957852303981784], 'acc': [0.91962222324477305, 0.91837777998712333, 0.91942222436269128, 0.92095555782318117, 0.91977777865197918, 0.92024444619814549, 0.92142222430970933, 0.92095555769072635, 0.92233333534664574, 0.91960000276565557, 0.92151111271646291, 0.92080000082651769, 0.92124444683392848, 0.92028889179229734, 0.92186666886011759, 0.92208889007568362, 0.9213111122449239, 0.92155555764834085, 0.92184444771872631, 0.92062222427792018, 0.92064444714122351, 0.92068888968891571, 0.92226666741900976, 0.92108889102935787, 0.91953333550029326, 0.92182222445805873, 0.92220000227292376, 0.92148889104525245, 0.92237778067588805, 0.92066666775279571, 0.92062222401301064, 0.92224444680743745, 0.92362222406599259, 0.92086666795942518, 0.92131111250983344, 0.92120000216695996, 0.92082222567664251, 0.92166666865348812, 0.92197777867317199, 0.92115555749999156], 'val_acc': [0.9100000011920929, 0.90960000038146971, 0.91060000300407407, 0.90900000095367428, 0.90740000128746034, 0.90960000157356258, 0.91040000319480896, 0.90900000214576726, 0.90880000233650204, 0.90779999732971195, 0.91000000000000003, 0.90980000138282779, 0.90980000019073481, 0.91060000061988833, 0.91080000042915343, 0.91039999961853024, 0.91039999961853024, 0.91020000100135801, 0.91080000042915343, 0.91040000081062322, 0.9106000018119812, 0.91040000081062322, 0.91060000061988833, 0.91059999942779546, 0.91000000000000003, 0.91039999961853024, 0.91039999961853024, 0.91039999961853024, 0.91039999961853024, 0.91019999980926514, 0.91039999961853024, 0.91039999961853024, 0.91039999961853024, 0.91019999980926514, 0.91019999980926514, 0.91040000081062322, 0.91060000061988833, 0.91040000081062322, 0.91040000081062322, 0.91040000081062322], 'loss': [0.56588194674915737, 0.56723716504044008, 0.56585627555847173, 0.56658802906672157, 0.56753930727640789, 0.56645008815659414, 0.56206479079193539, 0.56479608217875166, 0.55890443497233921, 0.56757867468727963, 0.5620941535631816, 0.56227876643339791, 0.56120947698752088, 0.56191857788297861, 0.56029788030518424, 0.55735274871190388, 0.56377992570400237, 0.5603269626696904, 0.55862455421023893, 0.56370714041921832, 0.56218234605259365, 0.56273862547344633, 0.55823084380891586, 0.55988719092475048, 0.56480745381779141, 0.5589122161600325, 0.55966665850745312, 0.55850119431813561, 0.55908146699269612, 0.561849438879225, 0.56325966033670638, 0.55860299991236795, 0.55616917716132275, 0.55931433935960129, 0.56191431370046407, 0.56028980208767787, 0.56271077745490605, 0.56034036457538605, 0.55962652080588871, 0.55833269026544363]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/step\n",
      "[0.60784988565444942, 0.91020000000000001]\n"
     ]
    }
   ],
   "source": [
    "# training - start from epoch 80\n",
    "batch_size  = 100\n",
    "epochs = 40 + 80\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "\n",
    "####################\n",
    "# Network training #\n",
    "####################\n",
    "                     \n",
    "print(\"Gonna fit the model\")\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                          epochs=epochs,verbose=1,validation_data=(x_val,y_val), callbacks=[lr_1], initial_epoch=80)\n",
    "print(his.history)\n",
    "print(model.evaluate(x_test, y_test))\n",
    "model.save('elu_network_mod_e_swish_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=2,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "351/351 [==============================] - 398s 1s/step - loss: 0.6018 - acc: 0.9054 - val_loss: 0.6229 - val_acc: 0.9008\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 397s 1s/step - loss: 0.5980 - acc: 0.9096 - val_loss: 0.6217 - val_acc: 0.8958\n",
      "Epoch 3/5\n",
      "117/351 [=========>....................] - ETA: 4:13 - loss: 0.5854 - acc: 0.9101"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs=5\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000075,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_val,y_val))\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs=5\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.000035,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_val,y_val))\n",
    "print(his.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mod(act):\n",
    "# ELU NETWORK CIFAR-100 VERSION\n",
    "    weight_decay = 0.0005\n",
    "    \n",
    "    model = Sequential()\n",
    "    # First stack\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Second stack\n",
    "    model.add(Conv2D(128, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(128, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Third stack\n",
    "    model.add(Conv2D(200, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Fourth stack\n",
    "    model.add(Conv2D(220, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Fifth stack\n",
    "    model.add(Conv2D(240, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Sixth stack\n",
    "    model.add(Conv2D(256, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(264, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.4))\n",
    "                     \n",
    "    # Sixth Seventh stack\n",
    "    model.add(Conv2D(364, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # and last stack\n",
    "    model.add(Conv2D(10, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 200)       102600    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 200)       160200    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 200)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 200)       800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 200)         40200     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 220)         176220    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 220)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 220)         880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 220)         48620     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 220)         193820    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 220)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 220)         880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 220)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 220)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 240)         475440    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 2, 240)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 256)         246016    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 256)         262400    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1, 1, 256)         65792     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 264)         67848     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1, 1, 264)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 264)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 1, 1, 364)         96460     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1, 1, 364)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 364)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 1, 1, 10)          3650      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,610,582\n",
      "Trainable params: 2,608,534\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_mod(e_swish_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"elu_network_mod_e_swish_2_weights.h5\",  by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"elu_network_mod_e_swish_2_w_batchnorm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(x):\n",
    "    if x<30:\n",
    "        return 0.01\n",
    "    elif x<45:\n",
    "        return 0.005\n",
    "    elif x<60:\n",
    "        return 0.001\n",
    "    elif x<70:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        # Start from epoch 80\n",
    "        if x<100:\n",
    "            return 0.0001\n",
    "        else:\n",
    "            return 0.0001/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 76/78\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 1.1249 - acc: 0.8716 - val_loss: 0.8045 - val_acc: 0.8984\n",
      "Epoch 77/78\n",
      "450/450 [==============================] - 576s 1s/step - loss: 0.7721 - acc: 0.8939 - val_loss: 0.7252 - val_acc: 0.9036\n",
      "Epoch 78/78\n",
      "450/450 [==============================] - 448s 994ms/step - loss: 0.7058 - acc: 0.8988 - val_loss: 0.6828 - val_acc: 0.9040\n",
      "{'val_acc': [0.89839999675750737, 0.90360000491142278, 0.90400000095367428], 'acc': [0.87155555605888368, 0.89386666576067608, 0.89882222427262204], 'val_loss': [0.80447701215744016, 0.72523254334926601, 0.68280347228050231], 'loss': [1.124912972384029, 0.7720515893565284, 0.70579737703005474]}\n",
      "10000/10000 [==============================] - 33s 3ms/step\n",
      "[0.71684425935745244, 0.89859999999999995]\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy w/ batchNorm\n",
    "#training\n",
    "batch_size  = 100\n",
    "epochs = 78\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "\n",
    "####################\n",
    "# Network training #\n",
    "####################\n",
    "                     \n",
    "print(\"Gonna fit the model\")\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                          epochs=epochs,verbose=1,validation_data=(x_val,y_val), callbacks=[lr_1], initial_epoch=75)\n",
    "print(his.history)\n",
    "print(model.evaluate(x_test, y_test))\n",
    "# model.save('elu_network_mod_e_swish_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 79/80\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.6632 - acc: 0.9027 - val_loss: 0.6645 - val_acc: 0.9056\n",
      "Epoch 80/80\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.6466 - acc: 0.9079 - val_loss: 0.6467 - val_acc: 0.9068\n",
      "{'val_acc': [0.90560000538825991, 0.90680000305175779], 'acc': [0.90273333496517605, 0.90791111230850219], 'val_loss': [0.66454115688800808, 0.6467448097467422], 'loss': [0.6631936870018641, 0.64661566760804923]}\n",
      "10000/10000 [==============================] - 32s 3ms/step\n",
      "[0.6797201908111572, 0.90359999999999996]\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy w/ batchNorm\n",
    "#training\n",
    "batch_size  = 100\n",
    "epochs = 80\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "\n",
    "####################\n",
    "# Network training #\n",
    "####################\n",
    "                     \n",
    "print(\"Gonna fit the model\")\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                          epochs=epochs,verbose=1,validation_data=(x_val,y_val), callbacks=[lr_1], initial_epoch=78)\n",
    "print(his.history)\n",
    "print(model.evaluate(x_test, y_test))\n",
    "model.save(\"elu_network_mod_e_swish_2_w_batchnorm.h5\")\n",
    "\n",
    "# FROM NOW ON, SEPARATE NOTEBOOKS (SAME ORIGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

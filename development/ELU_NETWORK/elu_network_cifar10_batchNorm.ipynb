{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Resuming training for modified ELU Network\n",
    "    with added BatchNorm from elu_network_cifar10.ipynb\n",
    "    from the same directory. Look at the end of the\n",
    "    above mentioned notebook to see transference from\n",
    "    non-batchNorm to BatchNorm.\n",
    "\"\"\"\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# Create Validation set\n",
    "x_train, x_val = x_train[:45000], x_train[45000:]\n",
    "y_train, y_val = y_train[:45000], y_train[45000:]\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_val = (x_val-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_val = np_utils.to_categorical(y_val,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e_swish_2 custom activation\n",
    "def e_swish_2(x):\n",
    "    return K.maximum(x*K.sigmoid(x), x*(2-K.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Will create a model with the following structure\n",
    "# ELU NETWORK CIFAR-100 VERSION\n",
    "#     weight_decay = 0.0005\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     # First stack\n",
    "#     model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "#     # Second stack\n",
    "#     model.add(Conv2D(128, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(128, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(200, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.1))\n",
    "\n",
    "#     # Third stack\n",
    "#     model.add(Conv2D(200, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "#     # Fourth stack\n",
    "#     model.add(Conv2D(220, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(220, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.3))\n",
    "    \n",
    "#     # Fifth stack\n",
    "#     model.add(Conv2D(240, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(256, (2,2), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Dropout(0.4))\n",
    "    \n",
    "#     # Sixth stack\n",
    "#     model.add(Conv2D(256, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Conv2D(264, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Dropout(0.4))\n",
    "                     \n",
    "#     # Sixth Seventh stack\n",
    "#     model.add(Conv2D(364, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(act))\n",
    "#     model.add(Dropout(0.3))\n",
    "    \n",
    "#     # and last stack\n",
    "#     model.add(Conv2D(10, (1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#     model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#     model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(x):\n",
    "    if x<30:\n",
    "        return 0.01\n",
    "    elif x<45:\n",
    "        return 0.005\n",
    "    elif x<60:\n",
    "        return 0.001\n",
    "    elif x<70:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        # Start from epoch 80\n",
    "        if x<90:\n",
    "            return 0.0001\n",
    "        else:\n",
    "            return 0.0001/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model. See elu_network_cifar10.ipynb for details of prior training\n",
    "model = load_model(\"elu_network_mod_e_swish_2_w_batchnorm.h5\", custom_objects={\"e_swish_2\": e_swish_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n",
      "Gonna fit the model\n",
      "Epoch 81/110\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.6370 - acc: 0.9059 - val_loss: 0.6451 - val_acc: 0.9088\n",
      "Epoch 82/110\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.6254 - acc: 0.9083 - val_loss: 0.6361 - val_acc: 0.9088\n",
      "Epoch 83/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.6223 - acc: 0.9089 - val_loss: 0.6337 - val_acc: 0.9070\n",
      "Epoch 84/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.6097 - acc: 0.9124 - val_loss: 0.6269 - val_acc: 0.9084\n",
      "Epoch 85/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.6131 - acc: 0.9112 - val_loss: 0.6204 - val_acc: 0.9092\n",
      "Epoch 86/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.6036 - acc: 0.9103 - val_loss: 0.6178 - val_acc: 0.9098\n",
      "Epoch 87/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.6005 - acc: 0.9122 - val_loss: 0.6154 - val_acc: 0.9076\n",
      "Epoch 88/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5952 - acc: 0.9126 - val_loss: 0.6148 - val_acc: 0.9076\n",
      "Epoch 89/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5917 - acc: 0.9127 - val_loss: 0.6084 - val_acc: 0.9090\n",
      "Epoch 90/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5983 - acc: 0.9119 - val_loss: 0.6057 - val_acc: 0.9092\n",
      "Epoch 91/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5868 - acc: 0.9152 - val_loss: 0.6070 - val_acc: 0.9100\n",
      "Epoch 92/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5818 - acc: 0.9155 - val_loss: 0.6082 - val_acc: 0.9102\n",
      "Epoch 93/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5862 - acc: 0.9145 - val_loss: 0.6064 - val_acc: 0.9096\n",
      "Epoch 94/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5822 - acc: 0.9144 - val_loss: 0.6063 - val_acc: 0.9108\n",
      "Epoch 95/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5782 - acc: 0.9159 - val_loss: 0.6066 - val_acc: 0.9114\n",
      "Epoch 96/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5767 - acc: 0.9172 - val_loss: 0.6049 - val_acc: 0.9110\n",
      "Epoch 97/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5821 - acc: 0.9154 - val_loss: 0.6037 - val_acc: 0.9082\n",
      "Epoch 98/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5800 - acc: 0.9162 - val_loss: 0.6027 - val_acc: 0.9098\n",
      "Epoch 99/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5751 - acc: 0.9175 - val_loss: 0.6000 - val_acc: 0.9112\n",
      "Epoch 100/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5734 - acc: 0.9173 - val_loss: 0.6002 - val_acc: 0.9094\n",
      "Epoch 101/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5707 - acc: 0.9184 - val_loss: 0.6005 - val_acc: 0.9102\n",
      "Epoch 102/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5755 - acc: 0.9184 - val_loss: 0.5983 - val_acc: 0.9102\n",
      "Epoch 103/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5741 - acc: 0.9179 - val_loss: 0.5989 - val_acc: 0.9102\n",
      "Epoch 104/110\n",
      "450/450 [==============================] - 434s 964ms/step - loss: 0.5694 - acc: 0.9188 - val_loss: 0.5976 - val_acc: 0.9108\n",
      "Epoch 105/110\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.5726 - acc: 0.9187 - val_loss: 0.5949 - val_acc: 0.9100\n",
      "Epoch 106/110\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.5653 - acc: 0.9197 - val_loss: 0.5941 - val_acc: 0.9092\n",
      "Epoch 107/110\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.5696 - acc: 0.9181 - val_loss: 0.5952 - val_acc: 0.9090\n",
      "Epoch 108/110\n",
      "450/450 [==============================] - 434s 965ms/step - loss: 0.5639 - acc: 0.9186 - val_loss: 0.5950 - val_acc: 0.9094\n",
      "Epoch 109/110\n",
      "450/450 [==============================] - 434s 965ms/step - loss: 0.5697 - acc: 0.9176 - val_loss: 0.5946 - val_acc: 0.9090\n",
      "Epoch 110/110\n",
      "450/450 [==============================] - 434s 965ms/step - loss: 0.5635 - acc: 0.9191 - val_loss: 0.5939 - val_acc: 0.9088\n",
      "{'acc': [0.90591111063957219, 0.9083333351877001, 0.9088666672176785, 0.91237777842415702, 0.91115555789735581, 0.91033333473735389, 0.91224444548288985, 0.91255555669466659, 0.91271111435360375, 0.91193333546320599, 0.91524444646305503, 0.91553333441416418, 0.91451111223962567, 0.91437777956326804, 0.91591111315621265, 0.91724444667498273, 0.91535555852784056, 0.91615555551317007, 0.91748888995912337, 0.91733333693610297, 0.91844444592793784, 0.91840000285042656, 0.91788889209429425, 0.91882222361034815, 0.91868889159626432, 0.91968889077504479, 0.91806666917271085, 0.91860000332196556, 0.91762222396002879, 0.91913333442476064], 'val_acc': [0.90880000710487363, 0.90880000472068789, 0.90700000524520874, 0.9084000039100647, 0.9092000043392181, 0.90980000734329225, 0.90760000586509704, 0.90760000586509704, 0.90900000333786013, 0.90920000553131108, 0.91000000476837162, 0.91020000696182246, 0.90960000276565556, 0.91080000281333928, 0.91140000700950619, 0.91100000619888311, 0.9082000041007996, 0.90980000376701353, 0.91120000123977662, 0.90940000295639034, 0.91020000457763672, 0.91020000219345087, 0.91020000576972959, 0.91080000400543215, 0.91000000596046449, 0.9092000043392181, 0.90900000572204587, 0.90940000295639034, 0.909000004529953, 0.90880000352859502], 'loss': [0.63696697347693976, 0.62542263779375284, 0.62231911804940965, 0.60971983916229677, 0.61309856202867297, 0.60358062293794423, 0.60052880161338384, 0.59519700858328073, 0.59169175419542519, 0.59833596567312874, 0.58676888128121696, 0.58182020518514843, 0.58616439435217116, 0.58222945789496106, 0.57815279265244801, 0.57674355235364705, 0.58209466404385035, 0.58002915475103589, 0.57506075547801128, 0.57335078689787122, 0.5707372893889745, 0.5754798253377279, 0.57409108678499854, 0.56938274323940274, 0.57264302902751496, 0.5653441923194461, 0.56960873524347944, 0.56387374275260504, 0.5697393931945165, 0.56346198605166542], 'val_loss': [0.64508205115795136, 0.63611194014549255, 0.6337271988391876, 0.6268512481451034, 0.62036428987979886, 0.61783664584159848, 0.61539042830467228, 0.61478169202804567, 0.60844056367874144, 0.60574946522712703, 0.60704828023910518, 0.60817424416542054, 0.60636328101158143, 0.60628837466239927, 0.60655457913875577, 0.60488914251327519, 0.60370444953441615, 0.60271142423152924, 0.59996226727962498, 0.60017489671707158, 0.60052116870880123, 0.59831843376159666, 0.59889746189117432, 0.59762562096118932, 0.59488645792007444, 0.5941329818964004, 0.59521746695041655, 0.59501738429069517, 0.59464964091777806, 0.59385470330715184]}\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "[0.62118460006713871, 0.90810000000000002]\n"
     ]
    }
   ],
   "source": [
    "# training - start from epoch 80\n",
    "batch_size  = 100\n",
    "epochs = 30 + 80\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False)\n",
    "lr_1 = keras.callbacks.LearningRateScheduler(schedule)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "\n",
    "####################\n",
    "# Network training #\n",
    "####################\n",
    "                     \n",
    "print(\"Gonna fit the model\")\n",
    "his = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                          epochs=epochs,verbose=1,validation_data=(x_val,y_val), callbacks=[lr_1], initial_epoch=80)\n",
    "print(his.history)\n",
    "print(model.evaluate(x_test, y_test))\n",
    "model.save('elu_network_mod_e_swish_2_w_batchnorm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

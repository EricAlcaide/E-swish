{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Repeating the MNIST experiment\n",
    "\"\"\" An attempt to obtain impressive results on MNIST.\n",
    "    Code extracted from: https://github.com/shahariarrabby/Mnist_cnn_Swish\n",
    "    Expected results > 99.5%\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# For adding new activation function\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "nb_classes = 10\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiAowg8ERfiBoP4P9W+M/MhMKHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1abfe263320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[0], cmap='binary_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 1) (6000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_val = X_val.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "# test = test.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def e_swish_2(x):\n",
    "    sigmoid = K.sigmoid(x)\n",
    "    return K.maximum(x*sigmoid, x*(2-sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "def create(act):\n",
    "    model = Sequential()\n",
    "    # First conv block\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', input_shape = (28,28,1)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding=\"Sme\", input_dim=X_train.shape[1:]))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # Second conv block\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same'))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same'))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # Classification\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(sigmoid))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.125, # Randomly zoom image \n",
    "        width_shift_range=0.125,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.125,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# RELU\n",
    "partial = []\n",
    "for i in range(3):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(\"relu\")\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# ESWISH2\n",
    "partial = []\n",
    "for i in range(3):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(e_swish_2)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SWISH\n",
    "partial = []\n",
    "for i in range(3):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(swish)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.4632 - acc: 0.8544 - val_loss: 0.0625 - val_acc: 0.9807\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.1430 - acc: 0.9578 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.1121 - acc: 0.9678 - val_loss: 0.0356 - val_acc: 0.9887\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0918 - acc: 0.9726 - val_loss: 0.0291 - val_acc: 0.9908\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0847 - acc: 0.9752 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0770 - acc: 0.9782 - val_loss: 0.0309 - val_acc: 0.9908\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0674 - acc: 0.9798 - val_loss: 0.0300 - val_acc: 0.9920\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0675 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9913\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 60s 95ms/step - loss: 0.0642 - acc: 0.9810 - val_loss: 0.0249 - val_acc: 0.9923\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0571 - acc: 0.9837 - val_loss: 0.0264 - val_acc: 0.9915\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0582 - acc: 0.9829 - val_loss: 0.0200 - val_acc: 0.9942\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0546 - acc: 0.9842 - val_loss: 0.0256 - val_acc: 0.9933\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0553 - acc: 0.9844 - val_loss: 0.0246 - val_acc: 0.9937\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0510 - acc: 0.9851 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0501 - acc: 0.9855 - val_loss: 0.0217 - val_acc: 0.9950\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0484 - acc: 0.9859 - val_loss: 0.0289 - val_acc: 0.9928\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0508 - acc: 0.9855 - val_loss: 0.0219 - val_acc: 0.9948\n",
      "Epoch 18/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9863\n",
      "Epoch 00018: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0479 - acc: 0.9863 - val_loss: 0.0221 - val_acc: 0.9940\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0371 - acc: 0.9889 - val_loss: 0.0173 - val_acc: 0.9945\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 0.0184 - val_acc: 0.9940\n",
      "Epoch 21/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0349 - acc: 0.9898 - val_loss: 0.0181 - val_acc: 0.9955\n",
      "Epoch 22/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0335 - acc: 0.9903 - val_loss: 0.0190 - val_acc: 0.9953\n",
      "Epoch 23/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.0183 - val_acc: 0.9952\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0324 - acc: 0.9905 - val_loss: 0.0150 - val_acc: 0.9962\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0198 - val_acc: 0.9950\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.0173 - val_acc: 0.9958\n",
      "Epoch 27/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0328 - acc: 0.9905 - val_loss: 0.0194 - val_acc: 0.9947\n",
      "Epoch 28/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9910\n",
      "Epoch 00028: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0306 - acc: 0.9909 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 29/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0154 - val_acc: 0.9960\n",
      "Epoch 30/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.0177 - val_acc: 0.9945\n",
      "Epoch 31/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9929\n",
      "Epoch 00031: reducing learning rate to 0.0001250000059371814.\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0187 - val_acc: 0.9952\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0256 - acc: 0.9925 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 33/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.0165 - val_acc: 0.9953\n",
      "Epoch 34/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9938\n",
      "Epoch 00034: reducing learning rate to 6.25000029685907e-05.\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.0172 - val_acc: 0.9957\n",
      "Epoch 35/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0232 - acc: 0.9934 - val_loss: 0.0175 - val_acc: 0.9957\n",
      "10000/10000 [==============================] - 4s 366us/step\n",
      "[{'loss': [0.46322345850388702, 0.14299749391904606, 0.1120713098216428, 0.091789371674042178, 0.084649768829705416, 0.076959843747611459, 0.067408578183381251, 0.067494563720387243, 0.064216405497800319, 0.057123728021474307, 0.058154496917714217, 0.054602511016208284, 0.055321846387158917, 0.050984587050359513, 0.050094761784864321, 0.048451173938563456, 0.050825745239238898, 0.047852532553810105, 0.037110609875450708, 0.034850012863817233, 0.034890074971439533, 0.033460948801747166, 0.033804146671410587, 0.032394100951652495, 0.032907462439243779, 0.029613405230068453, 0.032843641528313774, 0.030634373268046231, 0.028350859422798101, 0.025777190290113244, 0.023394603029696429, 0.025584115032536162, 0.023611901100296595, 0.020499222446682164, 0.023226825895079038], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001, 6.2500003e-05], 'val_loss': [0.062454711730048684, 0.043199560142830405, 0.035600777247765412, 0.029064758360613875, 0.027680508741536564, 0.030919607137582111, 0.030007604531832235, 0.027980481677674106, 0.024927196639589966, 0.026439933676481207, 0.019975150390643345, 0.025638298507566409, 0.024580761265526236, 0.017239261174715161, 0.021707313660158736, 0.02885484994851625, 0.021934947226664614, 0.022136732024651187, 0.01732211604176094, 0.018380119974106494, 0.018069161161866455, 0.018961028266937015, 0.018331957044501905, 0.015014806412708519, 0.019772302167544695, 0.017312129676140708, 0.01935223338964958, 0.018972959181565482, 0.015423740414950772, 0.017717847459242573, 0.018650162461433563, 0.017452428684183056, 0.016528913494877086, 0.017226979698428294, 0.017491117445400051], 'acc': [0.85437919573515864, 0.95782170537344424, 0.96776346377255884, 0.97258595997392938, 0.97518268797046226, 0.97820602227872311, 0.97976405964312685, 0.98004228042274655, 0.98100678018484044, 0.9837172135021508, 0.98285904283563896, 0.98419704709486588, 0.98441962395028504, 0.98514299871491962, 0.98549541171334609, 0.98588492130761807, 0.98555105609082239, 0.98633007487915703, 0.98887115984919627, 0.98939050575451915, 0.98983565935922468, 0.99026226491696734, 0.99018807259645003, 0.99054048586684185, 0.98976146709177371, 0.99096709143785111, 0.99054048590000832, 0.9909485433378219, 0.99152353346363287, 0.99228400418510487, 0.99293318652530038, 0.9924694848537321, 0.99322995559510396, 0.99376784953412312, 0.99336077722065752], 'val_acc': [0.98066665768623351, 0.98699999403953553, 0.98866666126251224, 0.99083332920074463, 0.99166666269302373, 0.99083332920074463, 0.99199999618530277, 0.99133332920074468, 0.99233332967758181, 0.99149999594688421, 0.99416666388511654, 0.99333333015441894, 0.9936666638851166, 0.99499999761581426, 0.99499999761581426, 0.99283332991600037, 0.99483333086967474, 0.99399999713897702, 0.99449999737739558, 0.99399999713897702, 0.99549999785423282, 0.9953333311080933, 0.99516666436195378, 0.99616666483879091, 0.99499999761581426, 0.99583333134651186, 0.9946666641235351, 0.99499999761581426, 0.99599999809265138, 0.99449999737739558, 0.99516666436195378, 0.99499999761581426, 0.9953333311080933, 0.99566666460037234, 0.99566666460037234]}, [0.0089812893640508727, 0.99680000000000002]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 59s 93ms/step - loss: 0.4752 - acc: 0.8509 - val_loss: 0.0612 - val_acc: 0.9813\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.1509 - acc: 0.9550 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.0396 - val_acc: 0.9888\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0918 - acc: 0.9720 - val_loss: 0.0387 - val_acc: 0.9898\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0855 - acc: 0.9749 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0763 - acc: 0.9773 - val_loss: 0.0243 - val_acc: 0.9920\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0688 - acc: 0.9799 - val_loss: 0.0258 - val_acc: 0.9920\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0647 - acc: 0.9813 - val_loss: 0.0231 - val_acc: 0.9935\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0632 - acc: 0.9815 - val_loss: 0.0236 - val_acc: 0.9927\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0590 - acc: 0.9828 - val_loss: 0.0247 - val_acc: 0.9928\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0584 - acc: 0.9835 - val_loss: 0.0234 - val_acc: 0.9933\n",
      "Epoch 12/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9840\n",
      "Epoch 00012: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0541 - acc: 0.9840 - val_loss: 0.0250 - val_acc: 0.9927\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0420 - acc: 0.9876 - val_loss: 0.0210 - val_acc: 0.9943\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0412 - acc: 0.9876 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0381 - acc: 0.9889 - val_loss: 0.0228 - val_acc: 0.9942\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0385 - acc: 0.9888 - val_loss: 0.0174 - val_acc: 0.9950\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0383 - acc: 0.9889 - val_loss: 0.0171 - val_acc: 0.9953\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0339 - acc: 0.9899 - val_loss: 0.0199 - val_acc: 0.9947\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 58s 92ms/step - loss: 0.0359 - acc: 0.9897 - val_loss: 0.0204 - val_acc: 0.9958\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.0226 - val_acc: 0.9950\n",
      "Epoch 21/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0351 - acc: 0.9894 - val_loss: 0.0198 - val_acc: 0.9945\n",
      "Epoch 22/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0343 - acc: 0.9897 - val_loss: 0.0218 - val_acc: 0.9945\n",
      "Epoch 23/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9900\n",
      "Epoch 00023: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0197 - val_acc: 0.9948\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0190 - val_acc: 0.9955\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0277 - acc: 0.9917 - val_loss: 0.0177 - val_acc: 0.9962\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0287 - acc: 0.9914 - val_loss: 0.0179 - val_acc: 0.9963\n",
      "Epoch 27/35\n",
      "627/627 [==============================] - 58s 93ms/step - loss: 0.0267 - acc: 0.9921 - val_loss: 0.0201 - val_acc: 0.9952\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0268 - acc: 0.9922 - val_loss: 0.0166 - val_acc: 0.9958\n",
      "Epoch 29/35\n",
      "627/627 [==============================] - 59s 93ms/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0194 - val_acc: 0.9960\n",
      "Epoch 30/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0199 - val_acc: 0.9965\n",
      "Epoch 31/35\n",
      "627/627 [==============================] - 59s 95ms/step - loss: 0.0252 - acc: 0.9924 - val_loss: 0.0193 - val_acc: 0.9950\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0257 - acc: 0.9922 - val_loss: 0.0195 - val_acc: 0.9967\n",
      "Epoch 33/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0181 - val_acc: 0.9958\n",
      "Epoch 34/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0251 - acc: 0.9923 - val_loss: 0.0183 - val_acc: 0.9958\n",
      "Epoch 35/35\n",
      "627/627 [==============================] - 59s 94ms/step - loss: 0.0251 - acc: 0.9929 - val_loss: 0.0192 - val_acc: 0.9962\n",
      "10000/10000 [==============================] - 4s 380us/step\n",
      "[{'loss': [0.47526928205310481, 0.15086097700820747, 0.11054499042572635, 0.091758034225364909, 0.085474307092382948, 0.076340583157249384, 0.068821406285971026, 0.064653928793407978, 0.063210814141220595, 0.059025913643484772, 0.058364629710537644, 0.054079680351272558, 0.042042846645440141, 0.041202651186119023, 0.038134872753034232, 0.038482172434452094, 0.038265217015394135, 0.033937756769140869, 0.035906363025983212, 0.034420533468448714, 0.035066244089283514, 0.034283733327379905, 0.033003577229062775, 0.030136977974106468, 0.027656866520603077, 0.028713092987336784, 0.026712707689856507, 0.026758799560939458, 0.026733854868192818, 0.025561535245427019, 0.025216391181035733, 0.025719155289209747, 0.025968953769503197, 0.025063562115868281, 0.025051402022197699], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001], 'val_loss': [0.061247278010783099, 0.03934544026096895, 0.039581246422370896, 0.038712380472274766, 0.031983007217776804, 0.024278400329601331, 0.025758042605564697, 0.023099280001304578, 0.02358843041225191, 0.024716050035910788, 0.023357829374219971, 0.025000438010012054, 0.020995251357666347, 0.020736953042511837, 0.022827967253172876, 0.017427628554892483, 0.017148606204219201, 0.019867429143264115, 0.020357795398137264, 0.022589360581873431, 0.019772363089109908, 0.021764596468352465, 0.019737456813144188, 0.01897139195685001, 0.017692260219782232, 0.017886069581373704, 0.020118506900122762, 0.016599406868800241, 0.019379322438751539, 0.019946937624605806, 0.019316126914463893, 0.019456323902049311, 0.018101259162122005, 0.01830409919436473, 0.019246928939324788], 'acc': [0.85091070837206539, 0.95500240238102807, 0.96789329981827776, 0.97201096918257712, 0.97490446673535569, 0.97729716698254954, 0.97993099224489144, 0.98130354894951222, 0.98148902971321683, 0.9828059421951385, 0.98349222068232611, 0.98403011477833335, 0.98757279526388253, 0.98755424723018637, 0.98892844692942061, 0.98875820330687503, 0.98890825601608823, 0.98985420739292085, 0.98966872672429362, 0.98989130355981281, 0.98944614995510738, 0.98972437092488175, 0.99000259196098916, 0.99085580303667475, 0.99170901411236023, 0.99137514890883116, 0.99213561965020303, 0.99222835998451664, 0.99189449478098757, 0.99213561961703645, 0.99235819645255574, 0.99219126385079115, 0.99224690805137938, 0.99226545613814199, 0.99289609035840842], 'val_acc': [0.9813333246707916, 0.98866666150093074, 0.98883332824707026, 0.98983332848548888, 0.99033332896232606, 0.99199999642372128, 0.99199999618530277, 0.99349999690055846, 0.99266666316986085, 0.99283332991600037, 0.99333333015441894, 0.99266666316986085, 0.99433333063125606, 0.99399999713897702, 0.99416666388511654, 0.99499999761581426, 0.9953333311080933, 0.9946666641235351, 0.99583333134651186, 0.99499999761581426, 0.99449999737739558, 0.99449999737739558, 0.99483333086967474, 0.99549999785423282, 0.99616666483879091, 0.99633333158493043, 0.99516666436195378, 0.99583333134651186, 0.99599999809265138, 0.99649999833106995, 0.99499999761581426, 0.99666666507720947, 0.99583333134651186, 0.99583333134651186, 0.99616666483879091]}, [0.0095151302411324648, 0.99709999999999999]]\n",
      "[[{'loss': [0.46322345850388702, 0.14299749391904606, 0.1120713098216428, 0.091789371674042178, 0.084649768829705416, 0.076959843747611459, 0.067408578183381251, 0.067494563720387243, 0.064216405497800319, 0.057123728021474307, 0.058154496917714217, 0.054602511016208284, 0.055321846387158917, 0.050984587050359513, 0.050094761784864321, 0.048451173938563456, 0.050825745239238898, 0.047852532553810105, 0.037110609875450708, 0.034850012863817233, 0.034890074971439533, 0.033460948801747166, 0.033804146671410587, 0.032394100951652495, 0.032907462439243779, 0.029613405230068453, 0.032843641528313774, 0.030634373268046231, 0.028350859422798101, 0.025777190290113244, 0.023394603029696429, 0.025584115032536162, 0.023611901100296595, 0.020499222446682164, 0.023226825895079038], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001, 6.2500003e-05], 'val_loss': [0.062454711730048684, 0.043199560142830405, 0.035600777247765412, 0.029064758360613875, 0.027680508741536564, 0.030919607137582111, 0.030007604531832235, 0.027980481677674106, 0.024927196639589966, 0.026439933676481207, 0.019975150390643345, 0.025638298507566409, 0.024580761265526236, 0.017239261174715161, 0.021707313660158736, 0.02885484994851625, 0.021934947226664614, 0.022136732024651187, 0.01732211604176094, 0.018380119974106494, 0.018069161161866455, 0.018961028266937015, 0.018331957044501905, 0.015014806412708519, 0.019772302167544695, 0.017312129676140708, 0.01935223338964958, 0.018972959181565482, 0.015423740414950772, 0.017717847459242573, 0.018650162461433563, 0.017452428684183056, 0.016528913494877086, 0.017226979698428294, 0.017491117445400051], 'acc': [0.85437919573515864, 0.95782170537344424, 0.96776346377255884, 0.97258595997392938, 0.97518268797046226, 0.97820602227872311, 0.97976405964312685, 0.98004228042274655, 0.98100678018484044, 0.9837172135021508, 0.98285904283563896, 0.98419704709486588, 0.98441962395028504, 0.98514299871491962, 0.98549541171334609, 0.98588492130761807, 0.98555105609082239, 0.98633007487915703, 0.98887115984919627, 0.98939050575451915, 0.98983565935922468, 0.99026226491696734, 0.99018807259645003, 0.99054048586684185, 0.98976146709177371, 0.99096709143785111, 0.99054048590000832, 0.9909485433378219, 0.99152353346363287, 0.99228400418510487, 0.99293318652530038, 0.9924694848537321, 0.99322995559510396, 0.99376784953412312, 0.99336077722065752], 'val_acc': [0.98066665768623351, 0.98699999403953553, 0.98866666126251224, 0.99083332920074463, 0.99166666269302373, 0.99083332920074463, 0.99199999618530277, 0.99133332920074468, 0.99233332967758181, 0.99149999594688421, 0.99416666388511654, 0.99333333015441894, 0.9936666638851166, 0.99499999761581426, 0.99499999761581426, 0.99283332991600037, 0.99483333086967474, 0.99399999713897702, 0.99449999737739558, 0.99399999713897702, 0.99549999785423282, 0.9953333311080933, 0.99516666436195378, 0.99616666483879091, 0.99499999761581426, 0.99583333134651186, 0.9946666641235351, 0.99499999761581426, 0.99599999809265138, 0.99449999737739558, 0.99516666436195378, 0.99499999761581426, 0.9953333311080933, 0.99566666460037234, 0.99566666460037234]}, [0.0089812893640508727, 0.99680000000000002]], [{'loss': [0.47526928205310481, 0.15086097700820747, 0.11054499042572635, 0.091758034225364909, 0.085474307092382948, 0.076340583157249384, 0.068821406285971026, 0.064653928793407978, 0.063210814141220595, 0.059025913643484772, 0.058364629710537644, 0.054079680351272558, 0.042042846645440141, 0.041202651186119023, 0.038134872753034232, 0.038482172434452094, 0.038265217015394135, 0.033937756769140869, 0.035906363025983212, 0.034420533468448714, 0.035066244089283514, 0.034283733327379905, 0.033003577229062775, 0.030136977974106468, 0.027656866520603077, 0.028713092987336784, 0.026712707689856507, 0.026758799560939458, 0.026733854868192818, 0.025561535245427019, 0.025216391181035733, 0.025719155289209747, 0.025968953769503197, 0.025063562115868281, 0.025051402022197699], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001], 'val_loss': [0.061247278010783099, 0.03934544026096895, 0.039581246422370896, 0.038712380472274766, 0.031983007217776804, 0.024278400329601331, 0.025758042605564697, 0.023099280001304578, 0.02358843041225191, 0.024716050035910788, 0.023357829374219971, 0.025000438010012054, 0.020995251357666347, 0.020736953042511837, 0.022827967253172876, 0.017427628554892483, 0.017148606204219201, 0.019867429143264115, 0.020357795398137264, 0.022589360581873431, 0.019772363089109908, 0.021764596468352465, 0.019737456813144188, 0.01897139195685001, 0.017692260219782232, 0.017886069581373704, 0.020118506900122762, 0.016599406868800241, 0.019379322438751539, 0.019946937624605806, 0.019316126914463893, 0.019456323902049311, 0.018101259162122005, 0.01830409919436473, 0.019246928939324788], 'acc': [0.85091070837206539, 0.95500240238102807, 0.96789329981827776, 0.97201096918257712, 0.97490446673535569, 0.97729716698254954, 0.97993099224489144, 0.98130354894951222, 0.98148902971321683, 0.9828059421951385, 0.98349222068232611, 0.98403011477833335, 0.98757279526388253, 0.98755424723018637, 0.98892844692942061, 0.98875820330687503, 0.98890825601608823, 0.98985420739292085, 0.98966872672429362, 0.98989130355981281, 0.98944614995510738, 0.98972437092488175, 0.99000259196098916, 0.99085580303667475, 0.99170901411236023, 0.99137514890883116, 0.99213561965020303, 0.99222835998451664, 0.99189449478098757, 0.99213561961703645, 0.99235819645255574, 0.99219126385079115, 0.99224690805137938, 0.99226545613814199, 0.99289609035840842], 'val_acc': [0.9813333246707916, 0.98866666150093074, 0.98883332824707026, 0.98983332848548888, 0.99033332896232606, 0.99199999642372128, 0.99199999618530277, 0.99349999690055846, 0.99266666316986085, 0.99283332991600037, 0.99333333015441894, 0.99266666316986085, 0.99433333063125606, 0.99399999713897702, 0.99416666388511654, 0.99499999761581426, 0.9953333311080933, 0.9946666641235351, 0.99583333134651186, 0.99499999761581426, 0.99449999737739558, 0.99449999737739558, 0.99483333086967474, 0.99549999785423282, 0.99616666483879091, 0.99633333158493043, 0.99516666436195378, 0.99583333134651186, 0.99599999809265138, 0.99649999833106995, 0.99499999761581426, 0.99666666507720947, 0.99583333134651186, 0.99583333134651186, 0.99616666483879091]}, [0.0095151302411324648, 0.99709999999999999]]]\n"
     ]
    }
   ],
   "source": [
    "# RELU\n",
    "partial = []\n",
    "for i in range(2):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(\"relu\")\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 84s 134ms/step - loss: 0.3896 - acc: 0.8804 - val_loss: 0.0557 - val_acc: 0.9820\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.1404 - acc: 0.9590 - val_loss: 0.0463 - val_acc: 0.9850\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.1127 - acc: 0.9669 - val_loss: 0.0420 - val_acc: 0.9853\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0968 - acc: 0.9712 - val_loss: 0.0398 - val_acc: 0.9880\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0925 - acc: 0.9723 - val_loss: 0.0313 - val_acc: 0.9913\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0871 - acc: 0.9751 - val_loss: 0.0334 - val_acc: 0.9915\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 82s 130ms/step - loss: 0.0810 - acc: 0.9762 - val_loss: 0.0384 - val_acc: 0.9905\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0808 - acc: 0.9767 - val_loss: 0.0295 - val_acc: 0.9910\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0782 - acc: 0.9775 - val_loss: 0.0362 - val_acc: 0.9898\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0788 - acc: 0.9775 - val_loss: 0.0275 - val_acc: 0.9920\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0734 - acc: 0.9791 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0751 - acc: 0.9792 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0706 - acc: 0.9804 - val_loss: 0.0222 - val_acc: 0.9927\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0712 - acc: 0.9797 - val_loss: 0.0309 - val_acc: 0.9925\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 81s 128ms/step - loss: 0.0717 - acc: 0.9800 - val_loss: 0.0244 - val_acc: 0.9940\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0694 - acc: 0.9814 - val_loss: 0.0317 - val_acc: 0.9920\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0692 - acc: 0.9810 - val_loss: 0.0271 - val_acc: 0.9925\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0705 - acc: 0.9801 - val_loss: 0.0228 - val_acc: 0.9928\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0683 - acc: 0.9808 - val_loss: 0.0275 - val_acc: 0.9943\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0679 - acc: 0.9818 - val_loss: 0.0278 - val_acc: 0.9942\n",
      "Epoch 21/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0662 - acc: 0.9816 - val_loss: 0.0375 - val_acc: 0.9920\n",
      "Epoch 22/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0667 - acc: 0.9823 - val_loss: 0.0273 - val_acc: 0.9933\n",
      "Epoch 23/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9813\n",
      "Epoch 00023: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0666 - acc: 0.9814 - val_loss: 0.0273 - val_acc: 0.9937\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0516 - acc: 0.9859 - val_loss: 0.0244 - val_acc: 0.9952\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0473 - acc: 0.9871 - val_loss: 0.0254 - val_acc: 0.9950\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0433 - acc: 0.9880 - val_loss: 0.0244 - val_acc: 0.9960\n",
      "Epoch 27/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0433 - acc: 0.9879 - val_loss: 0.0233 - val_acc: 0.9947\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0431 - acc: 0.9879 - val_loss: 0.0250 - val_acc: 0.9945\n",
      "Epoch 29/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0463 - acc: 0.9870 - val_loss: 0.0223 - val_acc: 0.9943\n",
      "Epoch 30/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9885\n",
      "Epoch 00030: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0425 - acc: 0.9885 - val_loss: 0.0244 - val_acc: 0.9942\n",
      "Epoch 31/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0373 - acc: 0.9889 - val_loss: 0.0230 - val_acc: 0.9948\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0364 - acc: 0.9903 - val_loss: 0.0235 - val_acc: 0.9947\n",
      "Epoch 33/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9903\n",
      "Epoch 00033: reducing learning rate to 0.0001250000059371814.\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0339 - acc: 0.9903 - val_loss: 0.0216 - val_acc: 0.9960\n",
      "Epoch 34/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0308 - acc: 0.9912 - val_loss: 0.0251 - val_acc: 0.9947\n",
      "Epoch 35/35\n",
      "627/627 [==============================] - 80s 128ms/step - loss: 0.0309 - acc: 0.9916 - val_loss: 0.0222 - val_acc: 0.9955\n",
      "10000/10000 [==============================] - 5s 484us/step\n",
      "[{'loss': [0.38958974921410533, 0.1403638556457692, 0.11268746510979837, 0.096772374145728229, 0.092511093250607149, 0.087037941767880531, 0.081005367607585629, 0.080814000673677902, 0.078188182577127813, 0.078848460745112356, 0.073412809440513788, 0.075134565035596665, 0.070625189392747881, 0.071225800679320633, 0.071654041425822157, 0.069404164805706589, 0.069219716976690715, 0.070500644961247708, 0.06827902847296613, 0.067879726767196252, 0.066206235115751605, 0.066657766036551394, 0.066630299128695572, 0.051559222148422554, 0.047273770703063302, 0.043352982892236262, 0.04329191769242851, 0.043154511148639343, 0.046281757791031497, 0.042504628175157814, 0.037317652637175847, 0.036385622927203098, 0.033945606091610764, 0.030837653799380766, 0.030876233940766204], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001], 'val_loss': [0.055692248054663648, 0.046274284387026757, 0.042037463941737463, 0.039815309665083377, 0.031307099637483286, 0.033429620759648365, 0.038410600809841225, 0.029525156319088031, 0.036203311449726848, 0.027524271847504375, 0.024789724914651742, 0.024576527874380798, 0.022160518716803079, 0.030934340758490029, 0.024366097147463128, 0.031680519206034659, 0.027076422873161695, 0.02276190164089591, 0.027517974698172867, 0.027777571012840781, 0.037457917216095662, 0.027268139406348684, 0.027323502589204584, 0.024446551285390947, 0.025404058152497175, 0.024358656756885162, 0.023293859629659588, 0.025012920933201257, 0.022334397388814674, 0.024404104094655623, 0.023006959574443347, 0.023469419092203452, 0.021565974606784191, 0.025103196695794926, 0.022160820424801084], 'acc': [0.88043921535557801, 0.95900878041665361, 0.96687315682847996, 0.9711577574612501, 0.97230773790523795, 0.97507139954938593, 0.97622137923275509, 0.97670362876776473, 0.97750119657373558, 0.97748264796957529, 0.9790592333676752, 0.97920761777433318, 0.98043178980696399, 0.9796713189285039, 0.97996808796514101, 0.98137774098479758, 0.98104387603333398, 0.98013502092731497, 0.98080275152452789, 0.98182289463151395, 0.98161886580094659, 0.98228659641805949, 0.98135919320316689, 0.98588492123244065, 0.98709054543037422, 0.98803649684037342, 0.98792520856744093, 0.98785101620491267, 0.9869607089955017, 0.98848165056005621, 0.98894535211664714, 0.99029936099762639, 0.9903179090976556, 0.99115257207331187, 0.99163482181174278], 'val_acc': [0.9819999918937683, 0.98499999308586117, 0.98533332657814021, 0.98799999451637266, 0.99133332920074468, 0.99149999594688421, 0.99049999547004697, 0.99099999570846553, 0.9898333287239075, 0.99199999618530277, 0.99216666293144229, 0.99199999618530277, 0.99266666316986085, 0.99249999642372133, 0.99399999713897702, 0.99199999618530277, 0.99249999642372133, 0.99283332991600037, 0.99433333063125606, 0.99416666412353516, 0.99199999642372128, 0.99333333015441894, 0.99366666364669798, 0.99516666436195378, 0.99499999761581426, 0.99599999809265138, 0.9946666641235351, 0.99449999737739558, 0.99433333063125606, 0.99416666388511654, 0.99483333086967474, 0.9946666641235351, 0.99599999809265138, 0.9946666641235351, 0.99549999785423282]}, [0.011231643755045706, 0.99680000000000002]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.3970 - acc: 0.8767 - val_loss: 0.0502 - val_acc: 0.9842\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.1424 - acc: 0.9584 - val_loss: 0.0366 - val_acc: 0.9885\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.1085 - acc: 0.9687 - val_loss: 0.0388 - val_acc: 0.9860\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0987 - acc: 0.9711 - val_loss: 0.0319 - val_acc: 0.9905\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0899 - acc: 0.9745 - val_loss: 0.0372 - val_acc: 0.9892\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0825 - acc: 0.9763 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0828 - acc: 0.9761 - val_loss: 0.0247 - val_acc: 0.9928\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.0349 - val_acc: 0.9912\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0780 - acc: 0.9779 - val_loss: 0.0259 - val_acc: 0.9922\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0790 - acc: 0.9769 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0724 - acc: 0.9784 - val_loss: 0.0256 - val_acc: 0.9935\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0711 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9920\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0756 - acc: 0.9793 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0677 - acc: 0.9802 - val_loss: 0.0280 - val_acc: 0.9938\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0682 - acc: 0.9806 - val_loss: 0.0249 - val_acc: 0.9928\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0685 - acc: 0.9813 - val_loss: 0.0275 - val_acc: 0.9932\n",
      "Epoch 17/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9804\n",
      "Epoch 00017: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0697 - acc: 0.9804 - val_loss: 0.0292 - val_acc: 0.9943\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0535 - acc: 0.9852 - val_loss: 0.0231 - val_acc: 0.9953\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0454 - acc: 0.9870 - val_loss: 0.0238 - val_acc: 0.9953\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0428 - acc: 0.9878 - val_loss: 0.0208 - val_acc: 0.9957\n",
      "Epoch 21/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0452 - acc: 0.9878 - val_loss: 0.0181 - val_acc: 0.9958\n",
      "Epoch 22/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0449 - acc: 0.9873 - val_loss: 0.0184 - val_acc: 0.9955\n",
      "Epoch 23/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0423 - acc: 0.9882 - val_loss: 0.0207 - val_acc: 0.9953\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0413 - acc: 0.9883 - val_loss: 0.0202 - val_acc: 0.9955\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0427 - acc: 0.9873 - val_loss: 0.0172 - val_acc: 0.9960\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0397 - acc: 0.9886 - val_loss: 0.0217 - val_acc: 0.9955\n",
      "Epoch 27/35\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0456 - acc: 0.9876 - val_loss: 0.0195 - val_acc: 0.9960\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0384 - acc: 0.9894 - val_loss: 0.0220 - val_acc: 0.9955\n",
      "Epoch 29/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9882\n",
      "Epoch 00029: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0407 - acc: 0.9883 - val_loss: 0.0246 - val_acc: 0.9945\n",
      "Epoch 30/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0339 - acc: 0.9902 - val_loss: 0.0199 - val_acc: 0.9958\n",
      "Epoch 31/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0319 - acc: 0.9906 - val_loss: 0.0197 - val_acc: 0.9960\n",
      "Epoch 32/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9908\n",
      "Epoch 00032: reducing learning rate to 0.0001250000059371814.\n",
      "627/627 [==============================] - 81s 129ms/step - loss: 0.0314 - acc: 0.9908 - val_loss: 0.0203 - val_acc: 0.9960\n",
      "Epoch 33/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0287 - acc: 0.9914 - val_loss: 0.0200 - val_acc: 0.9963\n",
      "Epoch 34/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.0195 - val_acc: 0.9967\n",
      "Epoch 35/35\n",
      "627/627 [==============================] - 81s 130ms/step - loss: 0.0267 - acc: 0.9924 - val_loss: 0.0188 - val_acc: 0.9967\n",
      "10000/10000 [==============================] - 5s 485us/step\n",
      "[{'loss': [0.39695169260938817, 0.14235148862614821, 0.10852706902730044, 0.098701696768491498, 0.089871525777040967, 0.082495322314658628, 0.082805477291401974, 0.077414558296186764, 0.077945787114611073, 0.078967438479306429, 0.072394727887842625, 0.071069810792801905, 0.075624498400392745, 0.067692134307849122, 0.068155929088432335, 0.06847658329888949, 0.069693845059293852, 0.053508825811881745, 0.045370296727275009, 0.04278517337448106, 0.045185133691650801, 0.044867689362524395, 0.042283497444126517, 0.041301926465606369, 0.042661389442570842, 0.039722431353672871, 0.045585654794886021, 0.038388051435643271, 0.04073300366679275, 0.033908727206368151, 0.031892989309155108, 0.031382151804941513, 0.028657692837885711, 0.028866547650405121, 0.026724047349266127], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001], 'val_loss': [0.050171266499208285, 0.036618868999396606, 0.038819779725289362, 0.031881569717346188, 0.037240521623001163, 0.026392886691120415, 0.024728938796783041, 0.034947493113208716, 0.02593260353707592, 0.028059257468694948, 0.025571030002921966, 0.028026986134361019, 0.022047786511795495, 0.02798906793048021, 0.024917410432431401, 0.027468246529907144, 0.029219524839423989, 0.023058314527953674, 0.023775962539939126, 0.020774363897772066, 0.018132751245886539, 0.018350420275761281, 0.02074478572536979, 0.020176866992226528, 0.017197261500360279, 0.021710816433720841, 0.019511301148824715, 0.021989495767909525, 0.024583227225398938, 0.01988881546960071, 0.019733717079721221, 0.020346505148968692, 0.019998653293020273, 0.019539817671688449, 0.018798611656957443], 'acc': [0.87674815155012686, 0.95841524261534472, 0.96874651112612886, 0.97106501805780987, 0.97449640924447578, 0.97627702316801113, 0.97612863975413744, 0.97783506111172336, 0.97792780118070488, 0.97694475395537872, 0.97837295460852225, 0.98000518479757437, 0.97933745429543873, 0.98024630904325938, 0.98058017439493228, 0.98126645284895331, 0.98035759759257946, 0.98519864289560799, 0.98697925706236445, 0.98781392016626457, 0.9878510164149672, 0.98729457438918544, 0.98820342947530448, 0.98825907367589272, 0.98727602628915623, 0.98861148700819534, 0.9876469874694227, 0.98940905382138189, 0.98825907383288081, 0.99024371683020462, 0.9905775820204672, 0.99080015883608652, 0.99137514890883116, 0.99152353346363287, 0.99243238872000672], 'val_acc': [0.98416665935516356, 0.98849999475479122, 0.98599999332427979, 0.99049999547004697, 0.9891666615009308, 0.99183332943916325, 0.99283332991600037, 0.99116666245460505, 0.99216666293144229, 0.99183332943916325, 0.99349999690055846, 0.99199999642372128, 0.99499999761581426, 0.9938333303928375, 0.99283332991600037, 0.99316666340827942, 0.99433333063125606, 0.9953333311080933, 0.9953333311080933, 0.99566666460037234, 0.99583333134651186, 0.99549999785423282, 0.9953333311080933, 0.99549999785423282, 0.99599999809265138, 0.99549999785423282, 0.99599999809265138, 0.99549999785423282, 0.99449999737739558, 0.99583333134651186, 0.99599999809265138, 0.99599999809265138, 0.99633333158493043, 0.99666666507720947, 0.99666666507720947]}, [0.011073204575383034, 0.99709999999999999]]\n",
      "[[{'loss': [0.38958974921410533, 0.1403638556457692, 0.11268746510979837, 0.096772374145728229, 0.092511093250607149, 0.087037941767880531, 0.081005367607585629, 0.080814000673677902, 0.078188182577127813, 0.078848460745112356, 0.073412809440513788, 0.075134565035596665, 0.070625189392747881, 0.071225800679320633, 0.071654041425822157, 0.069404164805706589, 0.069219716976690715, 0.070500644961247708, 0.06827902847296613, 0.067879726767196252, 0.066206235115751605, 0.066657766036551394, 0.066630299128695572, 0.051559222148422554, 0.047273770703063302, 0.043352982892236262, 0.04329191769242851, 0.043154511148639343, 0.046281757791031497, 0.042504628175157814, 0.037317652637175847, 0.036385622927203098, 0.033945606091610764, 0.030837653799380766, 0.030876233940766204], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001], 'val_loss': [0.055692248054663648, 0.046274284387026757, 0.042037463941737463, 0.039815309665083377, 0.031307099637483286, 0.033429620759648365, 0.038410600809841225, 0.029525156319088031, 0.036203311449726848, 0.027524271847504375, 0.024789724914651742, 0.024576527874380798, 0.022160518716803079, 0.030934340758490029, 0.024366097147463128, 0.031680519206034659, 0.027076422873161695, 0.02276190164089591, 0.027517974698172867, 0.027777571012840781, 0.037457917216095662, 0.027268139406348684, 0.027323502589204584, 0.024446551285390947, 0.025404058152497175, 0.024358656756885162, 0.023293859629659588, 0.025012920933201257, 0.022334397388814674, 0.024404104094655623, 0.023006959574443347, 0.023469419092203452, 0.021565974606784191, 0.025103196695794926, 0.022160820424801084], 'acc': [0.88043921535557801, 0.95900878041665361, 0.96687315682847996, 0.9711577574612501, 0.97230773790523795, 0.97507139954938593, 0.97622137923275509, 0.97670362876776473, 0.97750119657373558, 0.97748264796957529, 0.9790592333676752, 0.97920761777433318, 0.98043178980696399, 0.9796713189285039, 0.97996808796514101, 0.98137774098479758, 0.98104387603333398, 0.98013502092731497, 0.98080275152452789, 0.98182289463151395, 0.98161886580094659, 0.98228659641805949, 0.98135919320316689, 0.98588492123244065, 0.98709054543037422, 0.98803649684037342, 0.98792520856744093, 0.98785101620491267, 0.9869607089955017, 0.98848165056005621, 0.98894535211664714, 0.99029936099762639, 0.9903179090976556, 0.99115257207331187, 0.99163482181174278], 'val_acc': [0.9819999918937683, 0.98499999308586117, 0.98533332657814021, 0.98799999451637266, 0.99133332920074468, 0.99149999594688421, 0.99049999547004697, 0.99099999570846553, 0.9898333287239075, 0.99199999618530277, 0.99216666293144229, 0.99199999618530277, 0.99266666316986085, 0.99249999642372133, 0.99399999713897702, 0.99199999618530277, 0.99249999642372133, 0.99283332991600037, 0.99433333063125606, 0.99416666412353516, 0.99199999642372128, 0.99333333015441894, 0.99366666364669798, 0.99516666436195378, 0.99499999761581426, 0.99599999809265138, 0.9946666641235351, 0.99449999737739558, 0.99433333063125606, 0.99416666388511654, 0.99483333086967474, 0.9946666641235351, 0.99599999809265138, 0.9946666641235351, 0.99549999785423282]}, [0.011231643755045706, 0.99680000000000002]], [{'loss': [0.39695169260938817, 0.14235148862614821, 0.10852706902730044, 0.098701696768491498, 0.089871525777040967, 0.082495322314658628, 0.082805477291401974, 0.077414558296186764, 0.077945787114611073, 0.078967438479306429, 0.072394727887842625, 0.071069810792801905, 0.075624498400392745, 0.067692134307849122, 0.068155929088432335, 0.06847658329888949, 0.069693845059293852, 0.053508825811881745, 0.045370296727275009, 0.04278517337448106, 0.045185133691650801, 0.044867689362524395, 0.042283497444126517, 0.041301926465606369, 0.042661389442570842, 0.039722431353672871, 0.045585654794886021, 0.038388051435643271, 0.04073300366679275, 0.033908727206368151, 0.031892989309155108, 0.031382151804941513, 0.028657692837885711, 0.028866547650405121, 0.026724047349266127], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001], 'val_loss': [0.050171266499208285, 0.036618868999396606, 0.038819779725289362, 0.031881569717346188, 0.037240521623001163, 0.026392886691120415, 0.024728938796783041, 0.034947493113208716, 0.02593260353707592, 0.028059257468694948, 0.025571030002921966, 0.028026986134361019, 0.022047786511795495, 0.02798906793048021, 0.024917410432431401, 0.027468246529907144, 0.029219524839423989, 0.023058314527953674, 0.023775962539939126, 0.020774363897772066, 0.018132751245886539, 0.018350420275761281, 0.02074478572536979, 0.020176866992226528, 0.017197261500360279, 0.021710816433720841, 0.019511301148824715, 0.021989495767909525, 0.024583227225398938, 0.01988881546960071, 0.019733717079721221, 0.020346505148968692, 0.019998653293020273, 0.019539817671688449, 0.018798611656957443], 'acc': [0.87674815155012686, 0.95841524261534472, 0.96874651112612886, 0.97106501805780987, 0.97449640924447578, 0.97627702316801113, 0.97612863975413744, 0.97783506111172336, 0.97792780118070488, 0.97694475395537872, 0.97837295460852225, 0.98000518479757437, 0.97933745429543873, 0.98024630904325938, 0.98058017439493228, 0.98126645284895331, 0.98035759759257946, 0.98519864289560799, 0.98697925706236445, 0.98781392016626457, 0.9878510164149672, 0.98729457438918544, 0.98820342947530448, 0.98825907367589272, 0.98727602628915623, 0.98861148700819534, 0.9876469874694227, 0.98940905382138189, 0.98825907383288081, 0.99024371683020462, 0.9905775820204672, 0.99080015883608652, 0.99137514890883116, 0.99152353346363287, 0.99243238872000672], 'val_acc': [0.98416665935516356, 0.98849999475479122, 0.98599999332427979, 0.99049999547004697, 0.9891666615009308, 0.99183332943916325, 0.99283332991600037, 0.99116666245460505, 0.99216666293144229, 0.99183332943916325, 0.99349999690055846, 0.99199999642372128, 0.99499999761581426, 0.9938333303928375, 0.99283332991600037, 0.99316666340827942, 0.99433333063125606, 0.9953333311080933, 0.9953333311080933, 0.99566666460037234, 0.99583333134651186, 0.99549999785423282, 0.9953333311080933, 0.99549999785423282, 0.99599999809265138, 0.99549999785423282, 0.99599999809265138, 0.99549999785423282, 0.99449999737739558, 0.99583333134651186, 0.99599999809265138, 0.99599999809265138, 0.99633333158493043, 0.99666666507720947, 0.99666666507720947]}, [0.011073204575383034, 0.99709999999999999]]]\n"
     ]
    }
   ],
   "source": [
    "# E-SWISH-2\n",
    "partial = []\n",
    "for i in range(2):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(e_swish_2)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 85s 136ms/step - loss: 0.6617 - acc: 0.7881 - val_loss: 0.1044 - val_acc: 0.9680\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 84s 135ms/step - loss: 0.2168 - acc: 0.9352 - val_loss: 0.0625 - val_acc: 0.9805\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 84s 134ms/step - loss: 0.1735 - acc: 0.9491 - val_loss: 0.0601 - val_acc: 0.9810\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 84s 134ms/step - loss: 0.1484 - acc: 0.9562 - val_loss: 0.0551 - val_acc: 0.9835\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 84s 133ms/step - loss: 0.1327 - acc: 0.9610 - val_loss: 0.0388 - val_acc: 0.9880\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 84s 134ms/step - loss: 0.1274 - acc: 0.9631 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 84s 135ms/step - loss: 0.1169 - acc: 0.9662 - val_loss: 0.0301 - val_acc: 0.9907\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 85s 136ms/step - loss: 0.1139 - acc: 0.9664 - val_loss: 0.0404 - val_acc: 0.9900\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 83s 133ms/step - loss: 0.1094 - acc: 0.9676 - val_loss: 0.0464 - val_acc: 0.9858\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 83s 133ms/step - loss: 0.1040 - acc: 0.9694 - val_loss: 0.0319 - val_acc: 0.9912\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 84s 134ms/step - loss: 0.1047 - acc: 0.9691 - val_loss: 0.0388 - val_acc: 0.9897\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 83s 133ms/step - loss: 0.1002 - acc: 0.9709 - val_loss: 0.0317 - val_acc: 0.9915\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 84s 133ms/step - loss: 0.1005 - acc: 0.9713 - val_loss: 0.0522 - val_acc: 0.9883\n",
      "Epoch 14/35\n",
      "521/627 [=======================>......] - ETA: 13s - loss: 0.0913 - acc: 0.9732"
     ]
    }
   ],
   "source": [
    "def e_swish_5(x):\n",
    "    return K.maximum(-x*K.sigmoid(-x), x*K.sigmoid(x))\n",
    "\n",
    "# SWISH\n",
    "partial = []\n",
    "for i in range(1):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(e_swish_5)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.4557 - acc: 0.8587 - val_loss: 0.0618 - val_acc: 0.9800\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.1413 - acc: 0.9585 - val_loss: 0.0416 - val_acc: 0.9878\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.1059 - acc: 0.9687 - val_loss: 0.0343 - val_acc: 0.9890\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0939 - acc: 0.9733 - val_loss: 0.0351 - val_acc: 0.9883\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0814 - acc: 0.9760 - val_loss: 0.0289 - val_acc: 0.9913\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0756 - acc: 0.9778 - val_loss: 0.0271 - val_acc: 0.9913\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0744 - acc: 0.9783 - val_loss: 0.0289 - val_acc: 0.9907\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 66s 104ms/step - loss: 0.0704 - acc: 0.9788 - val_loss: 0.0251 - val_acc: 0.9935\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0659 - acc: 0.9813 - val_loss: 0.0272 - val_acc: 0.9928\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0666 - acc: 0.9806 - val_loss: 0.0249 - val_acc: 0.9933\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0633 - acc: 0.9820 - val_loss: 0.0199 - val_acc: 0.9938\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0627 - acc: 0.9823 - val_loss: 0.0304 - val_acc: 0.9922\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0610 - acc: 0.9821 - val_loss: 0.0261 - val_acc: 0.9928\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0620 - acc: 0.9825 - val_loss: 0.0238 - val_acc: 0.9945\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0554 - acc: 0.9838 - val_loss: 0.0210 - val_acc: 0.9935\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0572 - acc: 0.9838 - val_loss: 0.0263 - val_acc: 0.9932\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0576 - acc: 0.9840 - val_loss: 0.0216 - val_acc: 0.9955\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0592 - acc: 0.9830 - val_loss: 0.0205 - val_acc: 0.9945\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0557 - acc: 0.9848 - val_loss: 0.0213 - val_acc: 0.9952\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0534 - acc: 0.9847 - val_loss: 0.0206 - val_acc: 0.9942\n",
      "Epoch 21/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9847\n",
      "Epoch 00021: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0549 - acc: 0.9847 - val_loss: 0.0216 - val_acc: 0.9935\n",
      "Epoch 22/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0435 - acc: 0.9877 - val_loss: 0.0219 - val_acc: 0.9952\n",
      "Epoch 23/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0203 - val_acc: 0.9953\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0357 - acc: 0.9899 - val_loss: 0.0176 - val_acc: 0.9958\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 0.0175 - val_acc: 0.9960\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0367 - acc: 0.9892 - val_loss: 0.0225 - val_acc: 0.9955\n",
      "Epoch 27/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0349 - acc: 0.9893 - val_loss: 0.0203 - val_acc: 0.9958\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0341 - acc: 0.9901 - val_loss: 0.0182 - val_acc: 0.9945\n",
      "Epoch 29/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9894\n",
      "Epoch 00029: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 30/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0317 - acc: 0.9909 - val_loss: 0.0163 - val_acc: 0.9960\n",
      "Epoch 31/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0256 - acc: 0.9922 - val_loss: 0.0156 - val_acc: 0.9963\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0280 - acc: 0.9919 - val_loss: 0.0167 - val_acc: 0.9958\n",
      "Epoch 33/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0303 - acc: 0.9913 - val_loss: 0.0157 - val_acc: 0.9962\n",
      "Epoch 34/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0264 - acc: 0.9927 - val_loss: 0.0158 - val_acc: 0.9968\n",
      "Epoch 35/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0274 - acc: 0.9921 - val_loss: 0.0165 - val_acc: 0.9962\n",
      "10000/10000 [==============================] - 4s 412us/step\n",
      "[{'loss': [0.45566110832685575, 0.14126189149459165, 0.10592778535890679, 0.093894850048421907, 0.081396116313786113, 0.075638499929640376, 0.0744125248048466, 0.070351185313501166, 0.06590084008140755, 0.066592752601642741, 0.063322929514538648, 0.062676635503389894, 0.060995748440000143, 0.062004470330922219, 0.055361033848007793, 0.057194738517102925, 0.057608270834943881, 0.059167160408076333, 0.055744203819556144, 0.053406796493197704, 0.054869474181539438, 0.043526912934302844, 0.037863037409860717, 0.035739949532558851, 0.034794345964393014, 0.036738054443970297, 0.0348827265929363, 0.034079944659304577, 0.03524504390530666, 0.031658310252525863, 0.025648991427878711, 0.027988270078313959, 0.030315329716315554, 0.026365566043696279, 0.0273506766410592], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001], 'val_loss': [0.061849017033159426, 0.041641508014872673, 0.03429705438305003, 0.035064900567493167, 0.028863937601873963, 0.027058751174787177, 0.028881159099160867, 0.025084160280418776, 0.02715183565941455, 0.02487587108787678, 0.019899352939125189, 0.030361168626305394, 0.026065804646072745, 0.023809066865570154, 0.021024583230304414, 0.026293179049410659, 0.021647819507501481, 0.020542014953922869, 0.021264862365171819, 0.020640028525387908, 0.02157634555956368, 0.021918798491537623, 0.020349606515798466, 0.017572610590592074, 0.017486270174502959, 0.022475145404775087, 0.02026900536055776, 0.018209383538467593, 0.020199120785564448, 0.016311389964381914, 0.01563495058646288, 0.016717420990014185, 0.015747589639569317, 0.0158336980576784, 0.016501853658344164], 'acc': [0.85866379561712181, 0.95848943503978379, 0.96867231813122578, 0.97327223704380139, 0.97599880211200385, 0.97777941658389222, 0.97826166628915667, 0.97883665617174653, 0.98134064536846966, 0.98061727062373505, 0.9820454715820105, 0.98228659645122596, 0.98206401962897327, 0.98247467758552876, 0.98378658398172614, 0.98384463410970613, 0.98404866261303048, 0.98302851907266864, 0.98479058523447327, 0.98471639287194501, 0.98473494106705162, 0.98770263178498807, 0.98870422728059815, 0.98989130357971278, 0.9894461499219408, 0.98920502508589181, 0.98927921732017632, 0.99013242842902827, 0.98946469802197001, 0.99087570500716071, 0.99219010495053273, 0.99191304286775017, 0.99130095664138018, 0.99265496552235943, 0.99211707160324014], 'val_acc': [0.97999999070167543, 0.98783332777023314, 0.98899999499320979, 0.98833332777023319, 0.99133332920074468, 0.99133332920074468, 0.99066666221618649, 0.99349999690055846, 0.99283332991600037, 0.99333333015441894, 0.9938333303928375, 0.99216666293144229, 0.99283332991600037, 0.99449999737739558, 0.99349999690055846, 0.99316666340827942, 0.99549999785423282, 0.99449999737739558, 0.99516666436195378, 0.99416666388511654, 0.99349999690055846, 0.99516666436195378, 0.9953333311080933, 0.99583333134651186, 0.99599999809265138, 0.99549999785423282, 0.99583333134651186, 0.99449999737739558, 0.99516666436195378, 0.99599999809265138, 0.99633333158493043, 0.99583333134651186, 0.99616666483879091, 0.99683333182334899, 0.99616666483879091]}, [0.010635744385075623, 0.99690000000000001]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.4748 - acc: 0.8492 - val_loss: 0.0556 - val_acc: 0.9813\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.1440 - acc: 0.9571 - val_loss: 0.0424 - val_acc: 0.9880\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.1102 - acc: 0.9680 - val_loss: 0.0353 - val_acc: 0.9873\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0905 - acc: 0.9738 - val_loss: 0.0368 - val_acc: 0.9892\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0811 - acc: 0.9761 - val_loss: 0.0320 - val_acc: 0.9905\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0794 - acc: 0.9771 - val_loss: 0.0308 - val_acc: 0.9900\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0738 - acc: 0.9776 - val_loss: 0.0291 - val_acc: 0.9913\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0671 - acc: 0.9806 - val_loss: 0.0295 - val_acc: 0.9912\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0658 - acc: 0.9800 - val_loss: 0.0231 - val_acc: 0.9928\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0622 - acc: 0.9824 - val_loss: 0.0265 - val_acc: 0.9923\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.0647 - acc: 0.9812 - val_loss: 0.0222 - val_acc: 0.9935\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0590 - acc: 0.9833 - val_loss: 0.0237 - val_acc: 0.9935\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0596 - acc: 0.9832 - val_loss: 0.0272 - val_acc: 0.9925\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.0579 - acc: 0.9827 - val_loss: 0.0220 - val_acc: 0.9952\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.0539 - acc: 0.9841 - val_loss: 0.0192 - val_acc: 0.9958\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0564 - acc: 0.9838 - val_loss: 0.0250 - val_acc: 0.9945\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0548 - acc: 0.9840 - val_loss: 0.0252 - val_acc: 0.9933\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0558 - acc: 0.9844 - val_loss: 0.0266 - val_acc: 0.9948\n",
      "Epoch 19/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9845\n",
      "Epoch 00019: reducing learning rate to 0.0005000000237487257.\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0546 - acc: 0.9845 - val_loss: 0.0212 - val_acc: 0.9937\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 67s 107ms/step - loss: 0.0404 - acc: 0.9883 - val_loss: 0.0210 - val_acc: 0.9947\n",
      "Epoch 21/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.0391 - acc: 0.9889 - val_loss: 0.0208 - val_acc: 0.9950\n",
      "Epoch 22/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9894\n",
      "Epoch 00022: reducing learning rate to 0.0002500000118743628.\n",
      "627/627 [==============================] - 64s 103ms/step - loss: 0.0346 - acc: 0.9894 - val_loss: 0.0255 - val_acc: 0.9948\n",
      "Epoch 23/35\n",
      "627/627 [==============================] - 65s 103ms/step - loss: 0.0330 - acc: 0.9907 - val_loss: 0.0200 - val_acc: 0.9963\n",
      "Epoch 24/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0282 - acc: 0.9912 - val_loss: 0.0224 - val_acc: 0.9963\n",
      "Epoch 25/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0307 - acc: 0.9912 - val_loss: 0.0207 - val_acc: 0.9955\n",
      "Epoch 26/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0295 - acc: 0.9915 - val_loss: 0.0208 - val_acc: 0.9960\n",
      "Epoch 27/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9915\n",
      "Epoch 00027: reducing learning rate to 0.0001250000059371814.\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0287 - acc: 0.9915 - val_loss: 0.0196 - val_acc: 0.9963\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0277 - acc: 0.9917 - val_loss: 0.0200 - val_acc: 0.9963\n",
      "Epoch 29/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0190 - val_acc: 0.9962\n",
      "Epoch 30/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9926\n",
      "Epoch 00030: reducing learning rate to 6.25000029685907e-05.\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0194 - val_acc: 0.9960\n",
      "Epoch 31/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0201 - val_acc: 0.9965\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 64s 102ms/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0189 - val_acc: 0.9957\n",
      "Epoch 33/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0243 - acc: 0.9929 - val_loss: 0.0196 - val_acc: 0.9960\n",
      "Epoch 34/35\n",
      "627/627 [==============================] - 66s 105ms/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0190 - val_acc: 0.9962\n",
      "Epoch 35/35\n",
      "626/627 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9928\n",
      "Epoch 00035: reducing learning rate to 3.125000148429535e-05.\n",
      "627/627 [==============================] - 65s 104ms/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.0186 - val_acc: 0.9962\n",
      "10000/10000 [==============================] - 4s 427us/step\n",
      "[{'loss': [0.47483768247638114, 0.14402030602264865, 0.1102092884119991, 0.090494720485325628, 0.081091969392537433, 0.079412327152036527, 0.073801713457880239, 0.067072686530178699, 0.065808030509314178, 0.062192035657218425, 0.064697164846229047, 0.059033255007607505, 0.059603483201425778, 0.057940790386143588, 0.053879643812915989, 0.056418965590482123, 0.054793255308232341, 0.055828388688270877, 0.054559609224417993, 0.040425298222318863, 0.039129552957032271, 0.034563133904735449, 0.033008968987265658, 0.028204498404044594, 0.030694480042561818, 0.029524484464917657, 0.028719253411601614, 0.027671300858745099, 0.026080479940978594, 0.025214030631216102, 0.02357850699188703, 0.024015708492352357, 0.024319669318181338, 0.021697795624761356, 0.02472955478767307], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05], 'val_loss': [0.055586274582038943, 0.042376619524846317, 0.035317087048975127, 0.036796231327694842, 0.031958541413827334, 0.03078839241260236, 0.029119648910845473, 0.029451994873553607, 0.023056013110057998, 0.026517872082341153, 0.022159638108016223, 0.023654721346002286, 0.027217529137269592, 0.022014546844691722, 0.01922572432999823, 0.025009839840507388, 0.025192806182065396, 0.026556471078553842, 0.021157630932797475, 0.020950092723077737, 0.020819785700366994, 0.025544291201881453, 0.019978960444147559, 0.022373178345935836, 0.020673133270101972, 0.020751629742200066, 0.019629762709459708, 0.019973377548015984, 0.019010587264645436, 0.019380772173673448, 0.020082158559431944, 0.018852226025636961, 0.019558922699042948, 0.018971939381409508, 0.018602116882127952], 'acc': [0.84914864401949408, 0.95711687941639123, 0.96798603998454769, 0.97375448678223231, 0.97605444695602239, 0.97711168617683397, 0.97763103209100133, 0.98059872227164024, 0.98004524160229989, 0.98245092536798684, 0.98124790470691314, 0.9833067403188307, 0.98323254776614777, 0.98265755745018213, 0.98410430700377338, 0.98375189401861352, 0.98395592227871687, 0.98436397969663048, 0.98445672015918795, 0.98825907367589272, 0.98885261181549999, 0.98940905397837009, 0.99067032236804742, 0.99120821630706657, 0.99117112017334108, 0.99150498537687026, 0.99144934117628203, 0.99174611021291914, 0.99209852353637751, 0.99261786938863394, 0.99311866719392761, 0.99258077322174199, 0.99289609048665217, 0.99330414786255494, 0.9928589942578494], 'val_acc': [0.98133332490921021, 0.98799999451637266, 0.98733332753181458, 0.9891666615009308, 0.99049999570846559, 0.9899999952316284, 0.99133332920074468, 0.99116666245460505, 0.99283332991600037, 0.99233332967758181, 0.99349999690055846, 0.99349999690055846, 0.99249999642372133, 0.99516666436195378, 0.99583333134651186, 0.99449999737739558, 0.99333333015441894, 0.99483333086967474, 0.99366666364669798, 0.9946666641235351, 0.99499999761581426, 0.99483333086967474, 0.99633333158493043, 0.99633333158493043, 0.99549999785423282, 0.99599999809265138, 0.99633333158493043, 0.99633333158493043, 0.99616666483879091, 0.99599999809265138, 0.99649999833106995, 0.99566666460037234, 0.99599999809265138, 0.99616666483879091, 0.99616666483879091]}, [0.0086981924470206657, 0.99680000000000002]]\n",
      "[[{'loss': [0.45566110832685575, 0.14126189149459165, 0.10592778535890679, 0.093894850048421907, 0.081396116313786113, 0.075638499929640376, 0.0744125248048466, 0.070351185313501166, 0.06590084008140755, 0.066592752601642741, 0.063322929514538648, 0.062676635503389894, 0.060995748440000143, 0.062004470330922219, 0.055361033848007793, 0.057194738517102925, 0.057608270834943881, 0.059167160408076333, 0.055744203819556144, 0.053406796493197704, 0.054869474181539438, 0.043526912934302844, 0.037863037409860717, 0.035739949532558851, 0.034794345964393014, 0.036738054443970297, 0.0348827265929363, 0.034079944659304577, 0.03524504390530666, 0.031658310252525863, 0.025648991427878711, 0.027988270078313959, 0.030315329716315554, 0.026365566043696279, 0.0273506766410592], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001], 'val_loss': [0.061849017033159426, 0.041641508014872673, 0.03429705438305003, 0.035064900567493167, 0.028863937601873963, 0.027058751174787177, 0.028881159099160867, 0.025084160280418776, 0.02715183565941455, 0.02487587108787678, 0.019899352939125189, 0.030361168626305394, 0.026065804646072745, 0.023809066865570154, 0.021024583230304414, 0.026293179049410659, 0.021647819507501481, 0.020542014953922869, 0.021264862365171819, 0.020640028525387908, 0.02157634555956368, 0.021918798491537623, 0.020349606515798466, 0.017572610590592074, 0.017486270174502959, 0.022475145404775087, 0.02026900536055776, 0.018209383538467593, 0.020199120785564448, 0.016311389964381914, 0.01563495058646288, 0.016717420990014185, 0.015747589639569317, 0.0158336980576784, 0.016501853658344164], 'acc': [0.85866379561712181, 0.95848943503978379, 0.96867231813122578, 0.97327223704380139, 0.97599880211200385, 0.97777941658389222, 0.97826166628915667, 0.97883665617174653, 0.98134064536846966, 0.98061727062373505, 0.9820454715820105, 0.98228659645122596, 0.98206401962897327, 0.98247467758552876, 0.98378658398172614, 0.98384463410970613, 0.98404866261303048, 0.98302851907266864, 0.98479058523447327, 0.98471639287194501, 0.98473494106705162, 0.98770263178498807, 0.98870422728059815, 0.98989130357971278, 0.9894461499219408, 0.98920502508589181, 0.98927921732017632, 0.99013242842902827, 0.98946469802197001, 0.99087570500716071, 0.99219010495053273, 0.99191304286775017, 0.99130095664138018, 0.99265496552235943, 0.99211707160324014], 'val_acc': [0.97999999070167543, 0.98783332777023314, 0.98899999499320979, 0.98833332777023319, 0.99133332920074468, 0.99133332920074468, 0.99066666221618649, 0.99349999690055846, 0.99283332991600037, 0.99333333015441894, 0.9938333303928375, 0.99216666293144229, 0.99283332991600037, 0.99449999737739558, 0.99349999690055846, 0.99316666340827942, 0.99549999785423282, 0.99449999737739558, 0.99516666436195378, 0.99416666388511654, 0.99349999690055846, 0.99516666436195378, 0.9953333311080933, 0.99583333134651186, 0.99599999809265138, 0.99549999785423282, 0.99583333134651186, 0.99449999737739558, 0.99516666436195378, 0.99599999809265138, 0.99633333158493043, 0.99583333134651186, 0.99616666483879091, 0.99683333182334899, 0.99616666483879091]}, [0.010635744385075623, 0.99690000000000001]], [{'loss': [0.47483768247638114, 0.14402030602264865, 0.1102092884119991, 0.090494720485325628, 0.081091969392537433, 0.079412327152036527, 0.073801713457880239, 0.067072686530178699, 0.065808030509314178, 0.062192035657218425, 0.064697164846229047, 0.059033255007607505, 0.059603483201425778, 0.057940790386143588, 0.053879643812915989, 0.056418965590482123, 0.054793255308232341, 0.055828388688270877, 0.054559609224417993, 0.040425298222318863, 0.039129552957032271, 0.034563133904735449, 0.033008968987265658, 0.028204498404044594, 0.030694480042561818, 0.029524484464917657, 0.028719253411601614, 0.027671300858745099, 0.026080479940978594, 0.025214030631216102, 0.02357850699188703, 0.024015708492352357, 0.024319669318181338, 0.021697795624761356, 0.02472955478767307], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00050000002, 0.00050000002, 0.00050000002, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00025000001, 0.00012500001, 0.00012500001, 0.00012500001, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05, 6.2500003e-05], 'val_loss': [0.055586274582038943, 0.042376619524846317, 0.035317087048975127, 0.036796231327694842, 0.031958541413827334, 0.03078839241260236, 0.029119648910845473, 0.029451994873553607, 0.023056013110057998, 0.026517872082341153, 0.022159638108016223, 0.023654721346002286, 0.027217529137269592, 0.022014546844691722, 0.01922572432999823, 0.025009839840507388, 0.025192806182065396, 0.026556471078553842, 0.021157630932797475, 0.020950092723077737, 0.020819785700366994, 0.025544291201881453, 0.019978960444147559, 0.022373178345935836, 0.020673133270101972, 0.020751629742200066, 0.019629762709459708, 0.019973377548015984, 0.019010587264645436, 0.019380772173673448, 0.020082158559431944, 0.018852226025636961, 0.019558922699042948, 0.018971939381409508, 0.018602116882127952], 'acc': [0.84914864401949408, 0.95711687941639123, 0.96798603998454769, 0.97375448678223231, 0.97605444695602239, 0.97711168617683397, 0.97763103209100133, 0.98059872227164024, 0.98004524160229989, 0.98245092536798684, 0.98124790470691314, 0.9833067403188307, 0.98323254776614777, 0.98265755745018213, 0.98410430700377338, 0.98375189401861352, 0.98395592227871687, 0.98436397969663048, 0.98445672015918795, 0.98825907367589272, 0.98885261181549999, 0.98940905397837009, 0.99067032236804742, 0.99120821630706657, 0.99117112017334108, 0.99150498537687026, 0.99144934117628203, 0.99174611021291914, 0.99209852353637751, 0.99261786938863394, 0.99311866719392761, 0.99258077322174199, 0.99289609048665217, 0.99330414786255494, 0.9928589942578494], 'val_acc': [0.98133332490921021, 0.98799999451637266, 0.98733332753181458, 0.9891666615009308, 0.99049999570846559, 0.9899999952316284, 0.99133332920074468, 0.99116666245460505, 0.99283332991600037, 0.99233332967758181, 0.99349999690055846, 0.99349999690055846, 0.99249999642372133, 0.99516666436195378, 0.99583333134651186, 0.99449999737739558, 0.99333333015441894, 0.99483333086967474, 0.99366666364669798, 0.9946666641235351, 0.99499999761581426, 0.99483333086967474, 0.99633333158493043, 0.99633333158493043, 0.99549999785423282, 0.99599999809265138, 0.99633333158493043, 0.99633333158493043, 0.99616666483879091, 0.99599999809265138, 0.99649999833106995, 0.99566666460037234, 0.99599999809265138, 0.99616666483879091, 0.99616666483879091]}, [0.0086981924470206657, 0.99680000000000002]]]\n"
     ]
    }
   ],
   "source": [
    "# SWISH\n",
    "partial = []\n",
    "for i in range(2):\n",
    "    # Define the optimizer - Common to all models\n",
    "    opt = adam(lr=0.001, epsilon=1e-08, decay=0.0)\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) \n",
    "    # Common params \n",
    "    epochs = 35    # Turn epochs to 30 to get 0.9967 accuracy\n",
    "    batch_size = 86\n",
    "    # Create and compile the model\n",
    "    model = create(swish)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # Train the model\n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                                  epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                                  verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                                  , callbacks=[learning_rate_reduction])\n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    ind = [history.history, scores]\n",
    "    print(ind)\n",
    "    partial.append(ind)\n",
    "\n",
    "print(partial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Repeating MNIST first experiment of swish paper. \"\"\"\n",
    "\n",
    "import gc # Garbage collector\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Record settings\n",
    "LOG_FORMAT = \"%(levelname)s %(asctime)s - %(message)s\"\n",
    "logging.basicConfig(filename=\"swish_first_exp_log.txt\",format = LOG_FORMAT, level = logging.DEBUG, filemode = \"a\")\n",
    "logs = logging.getLogger()\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# For adding new activation function\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "nb_classes = 10\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) (6000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_val = X_val.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "# test = test.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x*K.sigmoid(x)\n",
    "\n",
    "def e_swish_2(x):\n",
    "    sigmoid = K.sigmoid(x)\n",
    "    return K.maximum(x*sigmoid, x*(2-sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "def create(act, n):\n",
    "    model = Sequential()\n",
    "    # First conv block\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation(act))\n",
    "    for i in range(n-1):\n",
    "        if i%2 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(act))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(arr, names = [\"relu\", \"e_swish_2\", \"swish\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    for item in arr:\n",
    "        ax.plot(np.array(item))\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.legend(names[:len(arr)], loc='upper right')\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    y_hat = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y_test, axis=1)\n",
    "\n",
    "    good = np.sum(np.equal(y, y_hat))\n",
    "    return float(good/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Starting round with 23 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 1.8138 - acc: 0.3087 - val_loss: 1.1260 - val_acc: 0.5507\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.2893 - acc: 0.5202 - val_loss: 0.9207 - val_acc: 0.6202\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0644 - acc: 0.6229 - val_loss: 0.5850 - val_acc: 0.7962\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.8988 - acc: 0.7164 - val_loss: 0.4861 - val_acc: 0.8677\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7803 - acc: 0.7758 - val_loss: 0.3949 - val_acc: 0.8998\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7047 - acc: 0.8082 - val_loss: 0.3282 - val_acc: 0.9175\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6350 - acc: 0.8374 - val_loss: 0.3050 - val_acc: 0.9350\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5737 - acc: 0.8583 - val_loss: 0.2914 - val_acc: 0.9350\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 71s 1ms/step - loss: 0.5354 - acc: 0.8728 - val_loss: 0.2899 - val_acc: 0.9353\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4996 - acc: 0.8849 - val_loss: 0.2261 - val_acc: 0.9500\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4711 - acc: 0.8925 - val_loss: 0.1973 - val_acc: 0.9552\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4436 - acc: 0.8996 - val_loss: 0.2120 - val_acc: 0.9542\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4255 - acc: 0.9039 - val_loss: 0.1910 - val_acc: 0.9587\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3896 - acc: 0.9135 - val_loss: 0.1816 - val_acc: 0.9607\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3799 - acc: 0.9154 - val_loss: 0.1784 - val_acc: 0.9622\n",
      "10000/10000 [==============================] - 3s 269us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 1.8127 - acc: 0.3074 - val_loss: 1.3107 - val_acc: 0.4187\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.4308 - acc: 0.4223 - val_loss: 1.0700 - val_acc: 0.5315\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.2363 - acc: 0.5301 - val_loss: 0.8384 - val_acc: 0.6692\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0572 - acc: 0.6320 - val_loss: 0.6474 - val_acc: 0.7562\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.9042 - acc: 0.7116 - val_loss: 0.5228 - val_acc: 0.8303\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7645 - acc: 0.7876 - val_loss: 0.3467 - val_acc: 0.9162\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6375 - acc: 0.8412 - val_loss: 0.2950 - val_acc: 0.9327\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5902 - acc: 0.8589 - val_loss: 0.2737 - val_acc: 0.9385\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5359 - acc: 0.8741 - val_loss: 0.2423 - val_acc: 0.9450\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4854 - acc: 0.8887 - val_loss: 0.2335 - val_acc: 0.9480\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4661 - acc: 0.8951 - val_loss: 0.2555 - val_acc: 0.9428\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4263 - acc: 0.9038 - val_loss: 0.2108 - val_acc: 0.9528\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4121 - acc: 0.9078 - val_loss: 0.1952 - val_acc: 0.9577\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3795 - acc: 0.9153 - val_loss: 0.1928 - val_acc: 0.9575\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3760 - acc: 0.9171 - val_loss: 0.1806 - val_acc: 0.9592\n",
      "10000/10000 [==============================] - 3s 273us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 75s 1ms/step - loss: 1.7887 - acc: 0.3216 - val_loss: 1.1843 - val_acc: 0.5382\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.3035 - acc: 0.5196 - val_loss: 0.7345 - val_acc: 0.7475\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0250 - acc: 0.6629 - val_loss: 0.5340 - val_acc: 0.7988\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.8569 - acc: 0.7424 - val_loss: 0.4266 - val_acc: 0.8577\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7270 - acc: 0.7926 - val_loss: 0.3304 - val_acc: 0.9098\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6308 - acc: 0.8376 - val_loss: 0.2981 - val_acc: 0.9323\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5508 - acc: 0.8681 - val_loss: 0.2565 - val_acc: 0.9405\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5030 - acc: 0.8828 - val_loss: 0.2424 - val_acc: 0.9455\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4592 - acc: 0.8956 - val_loss: 0.2017 - val_acc: 0.9535\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4238 - acc: 0.9049 - val_loss: 0.1809 - val_acc: 0.9597\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3871 - acc: 0.9153 - val_loss: 0.1930 - val_acc: 0.9628\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3656 - acc: 0.9210 - val_loss: 0.1650 - val_acc: 0.9645\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3505 - acc: 0.9248 - val_loss: 0.1512 - val_acc: 0.9670\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3241 - acc: 0.9287 - val_loss: 0.1535 - val_acc: 0.9658\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3223 - acc: 0.9316 - val_loss: 0.1555 - val_acc: 0.9667\n",
      "10000/10000 [==============================] - 3s 277us/step\n",
      "0.9717\n",
      "\n",
      " \n",
      " Starting round with 26 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 2.0965 - acc: 0.2386 - val_loss: 1.6202 - val_acc: 0.3768\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.7012 - acc: 0.3495 - val_loss: 1.4475 - val_acc: 0.4187\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.5591 - acc: 0.3974 - val_loss: 1.2574 - val_acc: 0.5033\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.4484 - acc: 0.4457 - val_loss: 1.1232 - val_acc: 0.5427\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.3466 - acc: 0.4886 - val_loss: 0.9860 - val_acc: 0.6398\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.2584 - acc: 0.5271 - val_loss: 0.9340 - val_acc: 0.6635\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.1640 - acc: 0.5663 - val_loss: 0.8329 - val_acc: 0.6995\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.1019 - acc: 0.5921 - val_loss: 0.7778 - val_acc: 0.7352\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.0371 - acc: 0.6234 - val_loss: 0.7590 - val_acc: 0.7663\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 0.9852 - acc: 0.6538 - val_loss: 0.6538 - val_acc: 0.8298\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 0.9471 - acc: 0.6815 - val_loss: 0.6097 - val_acc: 0.8428\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8885 - acc: 0.7088 - val_loss: 0.5574 - val_acc: 0.8697\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8460 - acc: 0.7373 - val_loss: 0.4696 - val_acc: 0.8858\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7891 - acc: 0.7652 - val_loss: 0.4418 - val_acc: 0.8923\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7483 - acc: 0.7843 - val_loss: 0.4252 - val_acc: 0.9003\n",
      "10000/10000 [==============================] - 3s 296us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.9982 - acc: 0.2780 - val_loss: 1.4930 - val_acc: 0.3850\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.6130 - acc: 0.3946 - val_loss: 1.3057 - val_acc: 0.4868\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.4823 - acc: 0.4450 - val_loss: 1.1480 - val_acc: 0.5847\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.3685 - acc: 0.4872 - val_loss: 1.0389 - val_acc: 0.6068\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.2939 - acc: 0.5173 - val_loss: 0.9993 - val_acc: 0.6492\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.2344 - acc: 0.5405 - val_loss: 0.9296 - val_acc: 0.6480\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1697 - acc: 0.5709 - val_loss: 0.8562 - val_acc: 0.7013\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1067 - acc: 0.5964 - val_loss: 0.7633 - val_acc: 0.7223\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.0381 - acc: 0.6321 - val_loss: 0.6844 - val_acc: 0.7543\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.9666 - acc: 0.6657 - val_loss: 0.6309 - val_acc: 0.7805\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.9099 - acc: 0.6927 - val_loss: 0.5844 - val_acc: 0.7948\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8645 - acc: 0.7087 - val_loss: 0.5682 - val_acc: 0.8060\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8228 - acc: 0.7250 - val_loss: 0.5175 - val_acc: 0.8213\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8015 - acc: 0.7332 - val_loss: 0.5245 - val_acc: 0.8323\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 0.7605 - acc: 0.7484 - val_loss: 0.4922 - val_acc: 0.8293\n",
      "10000/10000 [==============================] - 3s 301us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.9193 - acc: 0.2708 - val_loss: 1.3611 - val_acc: 0.4457\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.5362 - acc: 0.3966 - val_loss: 1.1773 - val_acc: 0.5177\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.3826 - acc: 0.4704 - val_loss: 0.9958 - val_acc: 0.6235\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.2693 - acc: 0.5365 - val_loss: 0.9077 - val_acc: 0.6522\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1785 - acc: 0.5718 - val_loss: 0.8301 - val_acc: 0.7077\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1156 - acc: 0.6007 - val_loss: 0.7792 - val_acc: 0.7192\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.0420 - acc: 0.6306 - val_loss: 0.7153 - val_acc: 0.7145\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 0.9859 - acc: 0.6512 - val_loss: 0.6334 - val_acc: 0.7340\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.9308 - acc: 0.6704 - val_loss: 0.6165 - val_acc: 0.7670\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 81s 1ms/step - loss: 0.8900 - acc: 0.6859 - val_loss: 0.6492 - val_acc: 0.7450\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.8732 - acc: 0.6962 - val_loss: 0.5701 - val_acc: 0.7725\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.8173 - acc: 0.7156 - val_loss: 0.5401 - val_acc: 0.7613\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7909 - acc: 0.7352 - val_loss: 0.5304 - val_acc: 0.8087\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7601 - acc: 0.7490 - val_loss: 0.5166 - val_acc: 0.8232\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7245 - acc: 0.7640 - val_loss: 0.4621 - val_acc: 0.8750\n",
      "10000/10000 [==============================] - 3s 318us/step\n",
      "0.9253\n",
      "\n",
      " \n",
      " Starting round with 29 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 103s 2ms/step - loss: 2.1394 - acc: 0.1811 - val_loss: 1.7070 - val_acc: 0.3285\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 91s 2ms/step - loss: 1.7998 - acc: 0.3149 - val_loss: 1.5464 - val_acc: 0.3957\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.6298 - acc: 0.3833 - val_loss: 1.2759 - val_acc: 0.4550\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.4793 - acc: 0.4264 - val_loss: 1.1568 - val_acc: 0.5247\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3912 - acc: 0.4651 - val_loss: 1.0731 - val_acc: 0.5627\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3086 - acc: 0.5055 - val_loss: 1.0157 - val_acc: 0.5457\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.2459 - acc: 0.5271 - val_loss: 0.9286 - val_acc: 0.6388\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1952 - acc: 0.5484 - val_loss: 0.9310 - val_acc: 0.6375\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1534 - acc: 0.5686 - val_loss: 0.8297 - val_acc: 0.6802\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1198 - acc: 0.5861 - val_loss: 0.7934 - val_acc: 0.7277\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.0700 - acc: 0.6063 - val_loss: 0.7759 - val_acc: 0.6990\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.0440 - acc: 0.6205 - val_loss: 0.7147 - val_acc: 0.7422\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.0073 - acc: 0.6439 - val_loss: 0.6642 - val_acc: 0.7405\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.9668 - acc: 0.6679 - val_loss: 0.6584 - val_acc: 0.7730\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.9263 - acc: 0.6883 - val_loss: 0.5509 - val_acc: 0.8540\n",
      "10000/10000 [==============================] - 3s 334us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 2.1911 - acc: 0.1815 - val_loss: 1.9103 - val_acc: 0.2967\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.8623 - acc: 0.3161 - val_loss: 1.4190 - val_acc: 0.4310\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.6369 - acc: 0.3754 - val_loss: 1.3025 - val_acc: 0.4440\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.5305 - acc: 0.4017 - val_loss: 1.1705 - val_acc: 0.5273\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.4550 - acc: 0.4201 - val_loss: 1.1449 - val_acc: 0.5030\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3927 - acc: 0.4374 - val_loss: 1.0832 - val_acc: 0.5417\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3294 - acc: 0.4742 - val_loss: 0.9845 - val_acc: 0.5847\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.2646 - acc: 0.5022 - val_loss: 1.0034 - val_acc: 0.5597\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.2213 - acc: 0.5196 - val_loss: 0.9305 - val_acc: 0.5847\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.1738 - acc: 0.5393 - val_loss: 0.9307 - val_acc: 0.6253: 1.1738 - a\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.1366 - acc: 0.5599 - val_loss: 0.8411 - val_acc: 0.6435\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0811 - acc: 0.5784 - val_loss: 0.7895 - val_acc: 0.6858\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.0426 - acc: 0.5961 - val_loss: 0.7910 - val_acc: 0.6593\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0739 - acc: 0.5937 - val_loss: 0.7843 - val_acc: 0.6813\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0118 - acc: 0.6188 - val_loss: 0.7808 - val_acc: 0.7212\n",
      "10000/10000 [==============================] - 3s 333us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 2.1707 - acc: 0.1879 - val_loss: 1.8979 - val_acc: 0.2793\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.9157 - acc: 0.2715 - val_loss: 1.6330 - val_acc: 0.3645\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.7204 - acc: 0.3492 - val_loss: 1.3882 - val_acc: 0.4198\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.5528 - acc: 0.3921 - val_loss: 1.2597 - val_acc: 0.4192\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.4544 - acc: 0.4181 - val_loss: 1.1931 - val_acc: 0.4315\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.3751 - acc: 0.4313 - val_loss: 1.1190 - val_acc: 0.4732\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.3259 - acc: 0.4407 - val_loss: 1.0745 - val_acc: 0.4770\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2873 - acc: 0.4480 - val_loss: 1.0574 - val_acc: 0.4987\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2566 - acc: 0.4563 - val_loss: 1.0469 - val_acc: 0.4938\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2376 - acc: 0.4596 - val_loss: 1.0235 - val_acc: 0.5013\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.2063 - acc: 0.4659 - val_loss: 1.0285 - val_acc: 0.5103\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1835 - acc: 0.4759 - val_loss: 0.9935 - val_acc: 0.5475\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1776 - acc: 0.4825 - val_loss: 1.0194 - val_acc: 0.5100\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1348 - acc: 0.5128 - val_loss: 0.9473 - val_acc: 0.6028\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.0958 - acc: 0.5578 - val_loss: 0.8550 - val_acc: 0.6808\n",
      "10000/10000 [==============================] - 3s 335us/step\n",
      "0.8639\n",
      "\n",
      " \n",
      " Starting round with 32 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 115s 2ms/step - loss: 2.2819 - acc: 0.1619 - val_loss: 2.0311 - val_acc: 0.2308\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 2.0998 - acc: 0.2201 - val_loss: 1.9076 - val_acc: 0.2703\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 2.0102 - acc: 0.2480 - val_loss: 1.8020 - val_acc: 0.2720\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.9118 - acc: 0.2798 - val_loss: 1.6791 - val_acc: 0.3537\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.8303 - acc: 0.3080 - val_loss: 1.5650 - val_acc: 0.4035\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7538 - acc: 0.3427 - val_loss: 1.4796 - val_acc: 0.4688\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.6694 - acc: 0.3717 - val_loss: 1.3897 - val_acc: 0.5032\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.5914 - acc: 0.4072 - val_loss: 1.2499 - val_acc: 0.5707\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 1.5251 - acc: 0.4347 - val_loss: 1.1472 - val_acc: 0.5955\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.4724 - acc: 0.4477 - val_loss: 1.1315 - val_acc: 0.5867\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4302 - acc: 0.4660 - val_loss: 1.0692 - val_acc: 0.6055\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.3794 - acc: 0.4866 - val_loss: 1.0372 - val_acc: 0.6585\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.3485 - acc: 0.4999 - val_loss: 1.0167 - val_acc: 0.6445\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.3117 - acc: 0.5146 - val_loss: 0.9546 - val_acc: 0.6678\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.2927 - acc: 0.5249 - val_loss: 1.0052 - val_acc: 0.6493\n",
      "10000/10000 [==============================] - 4s 375us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3233 - acc: 0.1530 - val_loss: 2.0805 - val_acc: 0.2280\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 2.1543 - acc: 0.2000 - val_loss: 2.0418 - val_acc: 0.2420\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 2.1086 - acc: 0.2196 - val_loss: 2.0094 - val_acc: 0.2450\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 2.0575 - acc: 0.2346 - val_loss: 1.9317 - val_acc: 0.2675\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.9923 - acc: 0.2468 - val_loss: 1.8413 - val_acc: 0.2805\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.9421 - acc: 0.2562 - val_loss: 1.7853 - val_acc: 0.3082\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.9036 - acc: 0.2664 - val_loss: 1.7303 - val_acc: 0.3182\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.8634 - acc: 0.2826 - val_loss: 1.6881 - val_acc: 0.3362\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.8381 - acc: 0.2965 - val_loss: 1.6552 - val_acc: 0.3648\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.7947 - acc: 0.3189 - val_loss: 1.5889 - val_acc: 0.4140\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7464 - acc: 0.3355 - val_loss: 1.5312 - val_acc: 0.4028\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.7009 - acc: 0.3528 - val_loss: 1.4869 - val_acc: 0.4340\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.6573 - acc: 0.3658 - val_loss: 1.4087 - val_acc: 0.4515\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.6122 - acc: 0.3799 - val_loss: 1.4059 - val_acc: 0.4772\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.5790 - acc: 0.3910 - val_loss: 1.3455 - val_acc: 0.4585\n",
      "10000/10000 [==============================] - 4s 389us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3440 - acc: 0.1451 - val_loss: 2.1683 - val_acc: 0.1923\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 2.1421 - acc: 0.1992 - val_loss: 2.0372 - val_acc: 0.2317\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 2.0463 - acc: 0.2369 - val_loss: 1.8817 - val_acc: 0.2813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.9537 - acc: 0.2649 - val_loss: 1.7453 - val_acc: 0.3308\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.8740 - acc: 0.2913 - val_loss: 1.6371 - val_acc: 0.3460\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7921 - acc: 0.3177 - val_loss: 1.5252 - val_acc: 0.3503\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.7234 - acc: 0.3306 - val_loss: 1.4995 - val_acc: 0.4037\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.6706 - acc: 0.3464 - val_loss: 1.4149 - val_acc: 0.4100\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.6176 - acc: 0.3560 - val_loss: 1.3720 - val_acc: 0.4208\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.5825 - acc: 0.3633 - val_loss: 1.3573 - val_acc: 0.4270\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.5512 - acc: 0.3689 - val_loss: 1.3447 - val_acc: 0.4137\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.5246 - acc: 0.3770 - val_loss: 1.3284 - val_acc: 0.4473\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4861 - acc: 0.3842 - val_loss: 1.3025 - val_acc: 0.4897\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4673 - acc: 0.3964 - val_loss: 1.2838 - val_acc: 0.4440\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4327 - acc: 0.4040 - val_loss: 1.2364 - val_acc: 0.5045\n",
      "10000/10000 [==============================] - 4s 377us/step\n",
      "0.6807\n",
      "\n",
      " \n",
      " Starting round with 35 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 2.3206 - acc: 0.1087 - val_loss: 2.4899 - val_acc: 0.1103\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2866 - acc: 0.1236 - val_loss: 2.4299 - val_acc: 0.1445\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2670 - acc: 0.1369 - val_loss: 2.2762 - val_acc: 0.1548\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2126 - acc: 0.1527 - val_loss: 2.1650 - val_acc: 0.1565\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.1497 - acc: 0.1638 - val_loss: 2.1472 - val_acc: 0.1928\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0887 - acc: 0.1785 - val_loss: 2.1148 - val_acc: 0.2087\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 2.0379 - acc: 0.1933 - val_loss: 1.9941 - val_acc: 0.2178\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9753 - acc: 0.2207 - val_loss: 1.8358 - val_acc: 0.2743\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9218 - acc: 0.2387 - val_loss: 1.8030 - val_acc: 0.2912\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8802 - acc: 0.2486 - val_loss: 1.7470 - val_acc: 0.2938\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.8531 - acc: 0.2619 - val_loss: 1.7311 - val_acc: 0.2942\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8284 - acc: 0.2679 - val_loss: 1.7019 - val_acc: 0.2927\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8134 - acc: 0.2752 - val_loss: 1.6679 - val_acc: 0.3235\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.7885 - acc: 0.2861 - val_loss: 1.6755 - val_acc: 0.3318\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.7678 - acc: 0.2904 - val_loss: 1.6069 - val_acc: 0.3257\n",
      "10000/10000 [==============================] - 4s 407us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 2.3044 - acc: 0.1234 - val_loss: 2.1907 - val_acc: 0.1985\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.1771 - acc: 0.1711 - val_loss: 1.9751 - val_acc: 0.2460\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0610 - acc: 0.1982 - val_loss: 1.9094 - val_acc: 0.2515\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0053 - acc: 0.2098 - val_loss: 1.9039 - val_acc: 0.2578\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9649 - acc: 0.2273 - val_loss: 1.8167 - val_acc: 0.2627\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9153 - acc: 0.2446 - val_loss: 1.7334 - val_acc: 0.3058\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.8718 - acc: 0.2654 - val_loss: 1.6716 - val_acc: 0.3475\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.8341 - acc: 0.2759 - val_loss: 1.6270 - val_acc: 0.3480\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.8006 - acc: 0.2867 - val_loss: 1.6032 - val_acc: 0.3518\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 111s 2ms/step - loss: 1.7556 - acc: 0.3045 - val_loss: 1.5421 - val_acc: 0.3590\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 111s 2ms/step - loss: 1.7121 - acc: 0.3175 - val_loss: 1.5208 - val_acc: 0.3545\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6728 - acc: 0.3298 - val_loss: 1.4790 - val_acc: 0.3820\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6411 - acc: 0.3360 - val_loss: 1.4205 - val_acc: 0.4005\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.6008 - acc: 0.3490 - val_loss: 1.4059 - val_acc: 0.3960\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.5652 - acc: 0.3568 - val_loss: 1.3918 - val_acc: 0.4108\n",
      "10000/10000 [==============================] - 4s 435us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 136s 3ms/step - loss: 2.2477 - acc: 0.1526 - val_loss: 2.1112 - val_acc: 0.1608\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.1402 - acc: 0.1908 - val_loss: 2.0318 - val_acc: 0.2263\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.0994 - acc: 0.2024 - val_loss: 2.0039 - val_acc: 0.2495\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.0617 - acc: 0.2170 - val_loss: 1.9338 - val_acc: 0.2687\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0225 - acc: 0.2309 - val_loss: 1.8295 - val_acc: 0.2763\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.9737 - acc: 0.2467 - val_loss: 1.7477 - val_acc: 0.3147\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.9305 - acc: 0.2583 - val_loss: 1.7199 - val_acc: 0.3173\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.8883 - acc: 0.2686 - val_loss: 1.7210 - val_acc: 0.3217\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.8561 - acc: 0.2765 - val_loss: 1.6704 - val_acc: 0.3455\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.8218 - acc: 0.2840 - val_loss: 1.6118 - val_acc: 0.3823\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.7898 - acc: 0.2917 - val_loss: 1.6146 - val_acc: 0.3540\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.7658 - acc: 0.2969 - val_loss: 1.5531 - val_acc: 0.3830\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.7373 - acc: 0.3104 - val_loss: 1.5237 - val_acc: 0.3972\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.6989 - acc: 0.3224 - val_loss: 1.4617 - val_acc: 0.4075\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6567 - acc: 0.3301 - val_loss: 1.4072 - val_acc: 0.3852\n",
      "10000/10000 [==============================] - 5s 451us/step\n",
      "0.5834\n",
      "\n",
      " \n",
      " Starting round with 38 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 150s 3ms/step - loss: 2.4095 - acc: 0.0971 - val_loss: 2.3024 - val_acc: 0.1012\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3120 - acc: 0.1052 - val_loss: 2.3020 - val_acc: 0.1017\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3048 - acc: 0.1069 - val_loss: 2.3025 - val_acc: 0.1172\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3036 - acc: 0.1075 - val_loss: 2.3014 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3028 - acc: 0.1079 - val_loss: 2.3022 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3025 - acc: 0.1087- ETA: 1s - loss: 2\n",
      "Epoch 00006: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3025 - acc: 0.1087 - val_loss: 2.3051 - val_acc: 0.1152\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3021 - acc: 0.1103 - val_loss: 2.3017 - val_acc: 0.1152\n",
      "Epoch 8/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1110\n",
      "Epoch 00008: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3018 - acc: 0.1110 - val_loss: 2.3016 - val_acc: 0.1152\n",
      "Epoch 00008: early stopping\n",
      "10000/10000 [==============================] - 5s 474us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 154s 3ms/step - loss: 2.4123 - acc: 0.1009 - val_loss: 2.3104 - val_acc: 0.1002\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 124s 2ms/step - loss: 2.3125 - acc: 0.1048 - val_loss: 2.3040 - val_acc: 0.1158\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3049 - acc: 0.1063 - val_loss: 2.3028 - val_acc: 0.1695\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3035 - acc: 0.1068 - val_loss: 2.3019 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3029 - acc: 0.1086 - val_loss: 2.3039 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3027 - acc: 0.1091\n",
      "Epoch 00006: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3027 - acc: 0.1091 - val_loss: 2.3068 - val_acc: 0.1152\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.3020 - acc: 0.1107 - val_loss: 2.3013 - val_acc: 0.1152\n",
      "Epoch 8/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3017 - acc: 0.1116\n",
      "Epoch 00008: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3017 - acc: 0.1116 - val_loss: 2.3020 - val_acc: 0.1145\n",
      "Epoch 00008: early stopping\n",
      "10000/10000 [==============================] - 5s 488us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 155s 3ms/step - loss: 2.4102 - acc: 0.1015 - val_loss: 2.3220 - val_acc: 0.0852\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3117 - acc: 0.1043 - val_loss: 2.3377 - val_acc: 0.1437\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3038 - acc: 0.1096 - val_loss: 2.3004 - val_acc: 0.1152\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3029 - acc: 0.1118 - val_loss: 2.3157 - val_acc: 0.1190\n",
      "Epoch 5/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1097\n",
      "Epoch 00005: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.3018 - acc: 0.1097 - val_loss: 2.3089 - val_acc: 0.1173\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3013 - acc: 0.1110 - val_loss: 2.3172 - val_acc: 0.1170\n",
      "Epoch 7/15\n",
      "51520/54000 [===========================>..] - ETA: 5s - loss: 2.3011 - acc: 0.1122"
     ]
    }
   ],
   "source": [
    "act = \"relu\"\n",
    "\n",
    "logs_relu = []\n",
    "record_relu = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_relu.append([n, ensembled])\n",
    "    logs_relu.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs Relu: \", logs_relu)\n",
    "print(\"Record Relu: \", record_relu)\n",
    "\n",
    "    \n",
    "plot([[x[1] for x in logs_relu]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Starting round with 38 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.4120 - acc: 0.1019 - val_loss: 2.3258 - val_acc: 0.1003\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 2.3133 - acc: 0.1030 - val_loss: 2.3261 - val_acc: 0.1017\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 2.3052 - acc: 0.1075 - val_loss: 2.3299 - val_acc: 0.1698\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 2.3037 - acc: 0.1086 - val_loss: 2.3284 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 2.3031 - acc: 0.1089 - val_loss: 2.3024 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1092\n",
      "Epoch 00006: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.1091 - val_loss: 2.3253 - val_acc: 0.1152\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 111s 2ms/step - loss: 2.3019 - acc: 0.1111 - val_loss: 2.3021 - val_acc: 0.1152\n",
      "Epoch 8/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1110- ETA: 0s - loss: 2.3018 - acc:\n",
      "Epoch 00008: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 2.3018 - acc: 0.1110 - val_loss: 2.3015 - val_acc: 0.1152\n",
      "Epoch 00008: early stopping\n",
      "10000/10000 [==============================] - 4s 415us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.4086 - acc: 0.1023 - val_loss: 2.2859 - val_acc: 0.1628\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 2.3116 - acc: 0.1029 - val_loss: 2.3057 - val_acc: 0.1025\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 2.3042 - acc: 0.1063 - val_loss: 2.3049 - val_acc: 0.1152\n",
      "Epoch 4/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3032 - acc: 0.1069\n",
      "Epoch 00004: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 2.3032 - acc: 0.1069 - val_loss: 2.3040 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 2.3015 - acc: 0.1106 - val_loss: 2.3051 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3011 - acc: 0.1110\n",
      "Epoch 00006: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3011 - acc: 0.1110 - val_loss: 2.3040 - val_acc: 0.1152\n",
      "Epoch 00006: early stopping\n",
      "10000/10000 [==============================] - 4s 407us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.4091 - acc: 0.1003 - val_loss: 2.3121 - val_acc: 0.1152\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3123 - acc: 0.1044 - val_loss: 2.3200 - val_acc: 0.0948\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3054 - acc: 0.1064 - val_loss: 2.3158 - val_acc: 0.1017\n",
      "Epoch 4/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3037 - acc: 0.1080\n",
      "Epoch 00004: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3037 - acc: 0.1081 - val_loss: 2.3027 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3025 - acc: 0.1103 - val_loss: 2.3013 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3022 - acc: 0.1102\n",
      "Epoch 00006: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 2.3022 - acc: 0.1102 - val_loss: 2.3014 - val_acc: 0.1152\n",
      "Epoch 00006: early stopping\n",
      "10000/10000 [==============================] - 4s 413us/step\n",
      "0.1135\n",
      "\n",
      " \n",
      " Starting round with 41 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 2.3259 - acc: 0.1055 - val_loss: 2.3119 - val_acc: 0.1130\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2907 - acc: 0.1246 - val_loss: 2.3211 - val_acc: 0.1240\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2762 - acc: 0.1367 - val_loss: 2.2901 - val_acc: 0.1302\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2599 - acc: 0.1438 - val_loss: 2.2951 - val_acc: 0.1328\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2461 - acc: 0.1506 - val_loss: 2.2627 - val_acc: 0.1438\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2330 - acc: 0.1601 - val_loss: 2.2464 - val_acc: 0.1593\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2165 - acc: 0.1650 - val_loss: 2.2179 - val_acc: 0.1683\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.2041 - acc: 0.1720 - val_loss: 2.2431 - val_acc: 0.1515\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.1926 - acc: 0.1760 - val_loss: 2.2141 - val_acc: 0.1523\n",
      "Epoch 10/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.1845 - acc: 0.1790\n",
      "Epoch 00010: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.1845 - acc: 0.1790 - val_loss: 2.2457 - val_acc: 0.1527\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.1694 - acc: 0.1823 - val_loss: 2.2217 - val_acc: 0.1550\n",
      "Epoch 12/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.1666 - acc: 0.1845\n",
      "Epoch 00012: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.1667 - acc: 0.1845 - val_loss: 2.2127 - val_acc: 0.1552\n",
      "Epoch 00012: early stopping\n",
      "10000/10000 [==============================] - 4s 436us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 2.3263 - acc: 0.1022 - val_loss: 2.3221 - val_acc: 0.1238\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3040 - acc: 0.1080 - val_loss: 2.3017 - val_acc: 0.1152\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3030 - acc: 0.1084 - val_loss: 2.3238 - val_acc: 0.1150\n",
      "Epoch 4/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3029 - acc: 0.1096\n",
      "Epoch 00004: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 123s 2ms/step - loss: 2.3029 - acc: 0.1096 - val_loss: 2.3158 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3020 - acc: 0.1098 - val_loss: 2.3016 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1114\n",
      "Epoch 00006: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3018 - acc: 0.1114 - val_loss: 2.3017 - val_acc: 0.1152\n",
      "Epoch 00006: early stopping\n",
      "10000/10000 [==============================] - 4s 449us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 138s 3ms/step - loss: 2.3264 - acc: 0.1049 - val_loss: 2.3082 - val_acc: 0.1545\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3039 - acc: 0.1068 - val_loss: 2.3100 - val_acc: 0.1015\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3030 - acc: 0.1082 - val_loss: 2.3080 - val_acc: 0.1498\n",
      "Epoch 4/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1092\n",
      "Epoch 00004: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 123s 2ms/step - loss: 2.3026 - acc: 0.1091 - val_loss: 2.3029 - val_acc: 0.1152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3017 - acc: 0.1115 - val_loss: 2.3003 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1110\n",
      "Epoch 00006: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3018 - acc: 0.1110 - val_loss: 2.3084 - val_acc: 0.1153\n",
      "Epoch 00006: early stopping\n",
      "10000/10000 [==============================] - 4s 448us/step\n",
      "0.1572\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "Logs Relu:  [[23, 0.9717], [26, 0.9253], [29, 0.8639], [32, 0.6807], [35, 0.5834], [38, 0.1135, 0.1135, 0.1135], [41, 0.15679999999999999, 0.1135, 0.11360000000000001]]\n",
      "Record Relu:  [[38, 0.1135], [41, 0.1572]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='08ab580f-d6bf-478d-841f-292a711362d2'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = \"relu\"\n",
    "logs_relu = []\n",
    "record_relu = [[23, 0.9717], [26, 0.9253], [29, 0.8639], [32, 0.6807], [35, 0.5834]]\n",
    "logs.info(\"Relu 38-42\")\n",
    "\n",
    "for n in range(38,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    logs.info(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        logs.info(\"Accuracy \"+str(i)+\": \"+str(logger[-1]))\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_relu.append([n, ensembled])\n",
    "    logs_relu.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    logs.info(\"Ensembled accuracy: \"+str(record_relu[-1]))\n",
    "    logs.info(\"Logs: \"+str(logs_relu[-1]))\n",
    "    \n",
    "logs.info(\"\\n \\n \\n\")\n",
    "logs.info(\"Logs e_swish_2: \"+str(logs_relu))\n",
    "logs.info(\"Record e_swish_2: \"+str(record_relu))\n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs Relu: \", logs_relu)\n",
    "print(\"Record Relu: \", record_relu)\n",
    "\n",
    "    \n",
    "plot([[x[1] for x in logs_relu]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Starting round with 23 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 93s 2ms/step - loss: 1.2903 - acc: 0.5598 - val_loss: 0.5266 - val_acc: 0.8643\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7332 - acc: 0.8116 - val_loss: 0.3981 - val_acc: 0.9258\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.5698 - acc: 0.8682 - val_loss: 0.3337 - val_acc: 0.9413\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.5351 - acc: 0.8743 - val_loss: 0.2820 - val_acc: 0.9455\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.4442 - acc: 0.9004 - val_loss: 0.2380 - val_acc: 0.9552\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3893 - acc: 0.9156 - val_loss: 0.1961 - val_acc: 0.9615\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3781 - acc: 0.9180 - val_loss: 0.1998 - val_acc: 0.9595\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3472 - acc: 0.9259 - val_loss: 0.2048 - val_acc: 0.9578\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3230 - acc: 0.9314 - val_loss: 0.1770 - val_acc: 0.9640\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2996 - acc: 0.9354 - val_loss: 0.1700 - val_acc: 0.9648\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2923 - acc: 0.9380 - val_loss: 0.1478 - val_acc: 0.9692\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2877 - acc: 0.9384 - val_loss: 0.1692 - val_acc: 0.9632\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2969 - acc: 0.9372 - val_loss: 0.1549 - val_acc: 0.9668\n",
      "Epoch 14/15\n",
      "53952/54000 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9426\n",
      "Epoch 00014: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 0.2719 - acc: 0.9425 - val_loss: 0.1458 - val_acc: 0.9680\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2317 - acc: 0.9505 - val_loss: 0.1225 - val_acc: 0.9750\n",
      "10000/10000 [==============================] - 3s 318us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 95s 2ms/step - loss: 1.3368 - acc: 0.5298 - val_loss: 0.6997 - val_acc: 0.7782\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8322 - acc: 0.7399 - val_loss: 0.3765 - val_acc: 0.9127\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.6585 - acc: 0.8353 - val_loss: 0.4307 - val_acc: 0.9123\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.5430 - acc: 0.8768 - val_loss: 0.3025 - val_acc: 0.9378\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.4769 - acc: 0.8942 - val_loss: 0.2706 - val_acc: 0.9472\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.4280 - acc: 0.9071 - val_loss: 0.2532 - val_acc: 0.9495\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3962 - acc: 0.9141 - val_loss: 0.2364 - val_acc: 0.9498\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3929 - acc: 0.9151 - val_loss: 0.2046 - val_acc: 0.9573\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3630 - acc: 0.9218 - val_loss: 0.2008 - val_acc: 0.9588\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3389 - acc: 0.9276 - val_loss: 0.1788 - val_acc: 0.9630\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3388 - acc: 0.9274 - val_loss: 0.1864 - val_acc: 0.9628\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3213 - acc: 0.9316 - val_loss: 0.1782 - val_acc: 0.9640\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3102 - acc: 0.9346 - val_loss: 0.1795 - val_acc: 0.9617\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2859 - acc: 0.9395 - val_loss: 0.1659 - val_acc: 0.9632\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2834 - acc: 0.9396 - val_loss: 0.1687 - val_acc: 0.9652\n",
      "10000/10000 [==============================] - 3s 325us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.3235 - acc: 0.5417 - val_loss: 0.5877 - val_acc: 0.8402\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7954 - acc: 0.7903 - val_loss: 0.4051 - val_acc: 0.9170\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.6145 - acc: 0.8560 - val_loss: 0.3445 - val_acc: 0.9297\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.5024 - acc: 0.8860 - val_loss: 0.2990 - val_acc: 0.9415\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.4556 - acc: 0.8982 - val_loss: 0.2554 - val_acc: 0.9507\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.4144 - acc: 0.9110 - val_loss: 0.2393 - val_acc: 0.9548\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3797 - acc: 0.9199 - val_loss: 0.2002 - val_acc: 0.9593\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3436 - acc: 0.9271 - val_loss: 0.2377 - val_acc: 0.9517\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3417 - acc: 0.9274 - val_loss: 0.1979 - val_acc: 0.9588\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3456 - acc: 0.9265 - val_loss: 0.1898 - val_acc: 0.9618\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3275 - acc: 0.9303 - val_loss: 0.1840 - val_acc: 0.9603\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3073 - acc: 0.9358 - val_loss: 0.1880 - val_acc: 0.9608\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3108 - acc: 0.9354 - val_loss: 0.1806 - val_acc: 0.9632\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.3202 - acc: 0.9310 - val_loss: 0.1576 - val_acc: 0.9660\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.2858 - acc: 0.9391 - val_loss: 0.1532 - val_acc: 0.9660\n",
      "10000/10000 [==============================] - 3s 328us/step\n",
      "0.9753\n",
      "\n",
      " \n",
      " Starting round with 26 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.5673 - acc: 0.4335 - val_loss: 0.7896 - val_acc: 0.6845\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.9276 - acc: 0.6857 - val_loss: 0.4729 - val_acc: 0.8413\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.7154 - acc: 0.7725 - val_loss: 0.3519 - val_acc: 0.8563\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.6203 - acc: 0.8007 - val_loss: 0.3422 - val_acc: 0.8622\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.5716 - acc: 0.8253 - val_loss: 0.2549 - val_acc: 0.9338\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.4990 - acc: 0.8676 - val_loss: 0.2405 - val_acc: 0.9478\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.4466 - acc: 0.8913 - val_loss: 0.2097 - val_acc: 0.9503\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.4351 - acc: 0.9020 - val_loss: 0.2219 - val_acc: 0.9510\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.4013 - acc: 0.9108 - val_loss: 0.1917 - val_acc: 0.9575\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.3795 - acc: 0.9172 - val_loss: 0.1928 - val_acc: 0.9590\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.3974 - acc: 0.9140 - val_loss: 0.2479 - val_acc: 0.9457\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.3917 - acc: 0.9172 - val_loss: 0.2042 - val_acc: 0.9552\n",
      "Epoch 13/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 0.3714 - acc: 0.9203\n",
      "Epoch 00013: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 0.3715 - acc: 0.9203 - val_loss: 0.1892 - val_acc: 0.9573\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.3142 - acc: 0.9330 - val_loss: 0.1749 - val_acc: 0.9617\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.2933 - acc: 0.9387 - val_loss: 0.1498 - val_acc: 0.9682\n",
      "10000/10000 [==============================] - 4s 360us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 1.5995 - acc: 0.4336 - val_loss: 0.7574 - val_acc: 0.7243\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.9983 - acc: 0.6611 - val_loss: 0.5428 - val_acc: 0.8122\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.8308 - acc: 0.7368 - val_loss: 0.4433 - val_acc: 0.8485\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.7018 - acc: 0.7885 - val_loss: 0.3912 - val_acc: 0.8737\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.6285 - acc: 0.8279 - val_loss: 0.2913 - val_acc: 0.9257\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.5638 - acc: 0.8603 - val_loss: 0.2796 - val_acc: 0.9390\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.5235 - acc: 0.8778 - val_loss: 0.2847 - val_acc: 0.9418\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4916 - acc: 0.8899 - val_loss: 0.2695 - val_acc: 0.9438\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.5001 - acc: 0.8894 - val_loss: 0.2593 - val_acc: 0.9460\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4815 - acc: 0.8941 - val_loss: 0.2649 - val_acc: 0.9477\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4885 - acc: 0.8932 - val_loss: 0.2576 - val_acc: 0.9460\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4662 - acc: 0.8987 - val_loss: 0.2510 - val_acc: 0.9445\n",
      "Epoch 13/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 0.4709 - acc: 0.8934\n",
      "Epoch 00013: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 0.4711 - acc: 0.8934 - val_loss: 0.3116 - val_acc: 0.9257\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.3899 - acc: 0.9152 - val_loss: 0.2052 - val_acc: 0.9560\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.3601 - acc: 0.9224 - val_loss: 0.1810 - val_acc: 0.9602\n",
      "10000/10000 [==============================] - 4s 371us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 114s 2ms/step - loss: 1.5404 - acc: 0.4676 - val_loss: 0.6398 - val_acc: 0.7622\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.9269 - acc: 0.7018 - val_loss: 0.4404 - val_acc: 0.8725\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.7742 - acc: 0.7798 - val_loss: 0.3526 - val_acc: 0.9220\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.6699 - acc: 0.8283 - val_loss: 0.3119 - val_acc: 0.9323\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.5861 - acc: 0.8622 - val_loss: 0.2952 - val_acc: 0.9393\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.5304 - acc: 0.8795 - val_loss: 0.2374 - val_acc: 0.9473\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4811 - acc: 0.8949 - val_loss: 0.2446 - val_acc: 0.9508\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4536 - acc: 0.9024 - val_loss: 0.2363 - val_acc: 0.9508\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4603 - acc: 0.9000 - val_loss: 0.2370 - val_acc: 0.9523\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4500 - acc: 0.9035 - val_loss: 0.2244 - val_acc: 0.9482\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4363 - acc: 0.9072 - val_loss: 0.2535 - val_acc: 0.9472\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4126 - acc: 0.9138 - val_loss: 0.2210 - val_acc: 0.9545\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4213 - acc: 0.9091 - val_loss: 0.2211 - val_acc: 0.9523\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4092 - acc: 0.9124 - val_loss: 0.2487 - val_acc: 0.9412\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 0.4185 - acc: 0.9054 - val_loss: 0.1929 - val_acc: 0.9575\n",
      "10000/10000 [==============================] - 4s 373us/step\n",
      "0.9682\n",
      "\n",
      " \n",
      " Starting round with 29 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 125s 2ms/step - loss: 1.7071 - acc: 0.3479 - val_loss: 1.1007 - val_acc: 0.5922\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.2199 - acc: 0.5364 - val_loss: 0.8073 - val_acc: 0.6645\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.0574 - acc: 0.6106 - val_loss: 0.7609 - val_acc: 0.6707\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.9805 - acc: 0.6459 - val_loss: 0.6772 - val_acc: 0.7540\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.8971 - acc: 0.7074 - val_loss: 0.5414 - val_acc: 0.8302\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.8134 - acc: 0.7523 - val_loss: 0.4932 - val_acc: 0.8455\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.7929 - acc: 0.7609 - val_loss: 0.4777 - val_acc: 0.8490\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.7059 - acc: 0.7959 - val_loss: 0.4188 - val_acc: 0.8830\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.6506 - acc: 0.8164 - val_loss: 0.4513 - val_acc: 0.8968\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.6722 - acc: 0.8186 - val_loss: 0.4270 - val_acc: 0.9033\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.6654 - acc: 0.8302 - val_loss: 0.4671 - val_acc: 0.8952\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.6525 - acc: 0.8418 - val_loss: 0.3712 - val_acc: 0.9273\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.7426 - acc: 0.8036 - val_loss: 0.4182 - val_acc: 0.9150\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 0.6193 - acc: 0.8561 - val_loss: 0.3991 - val_acc: 0.9168\n",
      "Epoch 15/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 0.5671 - acc: 0.8730\n",
      "Epoch 00015: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 0.5674 - acc: 0.8730 - val_loss: 0.4288 - val_acc: 0.9108\n",
      "10000/10000 [==============================] - 4s 411us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 128s 2ms/step - loss: 1.7032 - acc: 0.3491 - val_loss: 1.0651 - val_acc: 0.5462\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.2657 - acc: 0.5430 - val_loss: 0.8338 - val_acc: 0.6930\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.0799 - acc: 0.6306 - val_loss: 0.6866 - val_acc: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.9554 - acc: 0.7049 - val_loss: 0.6452 - val_acc: 0.7932\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.8421 - acc: 0.7467 - val_loss: 0.5023 - val_acc: 0.8502\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.7537 - acc: 0.7876 - val_loss: 0.4633 - val_acc: 0.8952\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.7391 - acc: 0.8039 - val_loss: 0.4733 - val_acc: 0.8892\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.6776 - acc: 0.8312 - val_loss: 0.3940 - val_acc: 0.9142\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.6372 - acc: 0.8457 - val_loss: 0.3853 - val_acc: 0.9140\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.6439 - acc: 0.8404 - val_loss: 0.3843 - val_acc: 0.9120\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5752 - acc: 0.8636 - val_loss: 0.3249 - val_acc: 0.9297\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5619 - acc: 0.8685 - val_loss: 0.3389 - val_acc: 0.9278\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5407 - acc: 0.8761 - val_loss: 0.3321 - val_acc: 0.9335\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5364 - acc: 0.8792 - val_loss: 0.2902 - val_acc: 0.9420\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5300 - acc: 0.8812 - val_loss: 0.3135 - val_acc: 0.9343\n",
      "10000/10000 [==============================] - 4s 413us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.7511 - acc: 0.3531 - val_loss: 1.0859 - val_acc: 0.5925\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.2537 - acc: 0.5366 - val_loss: 0.7937 - val_acc: 0.7057\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.1296 - acc: 0.6047 - val_loss: 0.7689 - val_acc: 0.7322\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.9447 - acc: 0.6873 - val_loss: 0.6124 - val_acc: 0.8298\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.8373 - acc: 0.7405 - val_loss: 0.6432 - val_acc: 0.7938\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.7866 - acc: 0.7666 - val_loss: 0.5132 - val_acc: 0.8417\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.7097 - acc: 0.8064 - val_loss: 0.4293 - val_acc: 0.9033\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.6807 - acc: 0.8250 - val_loss: 0.4248 - val_acc: 0.8937\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5987 - acc: 0.8555 - val_loss: 0.3695 - val_acc: 0.9268\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5670 - acc: 0.8687 - val_loss: 0.3742 - val_acc: 0.9270\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5529 - acc: 0.8755 - val_loss: 0.3453 - val_acc: 0.9297\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5176 - acc: 0.8869 - val_loss: 0.3104 - val_acc: 0.9403\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5041 - acc: 0.8895 - val_loss: 0.2793 - val_acc: 0.9450\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.4991 - acc: 0.8926 - val_loss: 0.3289 - val_acc: 0.9367\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 0.5276 - acc: 0.8801 - val_loss: 0.3473 - val_acc: 0.9150\n",
      "10000/10000 [==============================] - 4s 414us/step\n",
      "0.9487\n",
      "\n",
      " \n",
      " Starting round with 32 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.9114 - acc: 0.3287 - val_loss: 1.0782 - val_acc: 0.5248\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.3285 - acc: 0.5000 - val_loss: 0.8163 - val_acc: 0.7090\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.0871 - acc: 0.6346 - val_loss: 0.6391 - val_acc: 0.8023\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.9359 - acc: 0.7077 - val_loss: 0.5163 - val_acc: 0.8348\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8530 - acc: 0.7449 - val_loss: 0.5007 - val_acc: 0.8397\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8437 - acc: 0.7479 - val_loss: 0.5794 - val_acc: 0.8065\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7872 - acc: 0.7739 - val_loss: 0.4864 - val_acc: 0.8482\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7491 - acc: 0.8013 - val_loss: 0.4151 - val_acc: 0.9117\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7216 - acc: 0.8195 - val_loss: 0.4321 - val_acc: 0.9100\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7159 - acc: 0.8261 - val_loss: 0.3941 - val_acc: 0.9150\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.6765 - acc: 0.8399 - val_loss: 0.4581 - val_acc: 0.9032\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.6417 - acc: 0.8512 - val_loss: 0.3826 - val_acc: 0.9192\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.6181 - acc: 0.8592 - val_loss: 0.3900 - val_acc: 0.9117\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.6075 - acc: 0.8624 - val_loss: 0.3767 - val_acc: 0.9210\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.5851 - acc: 0.8699 - val_loss: 0.3257 - val_acc: 0.9280\n",
      "10000/10000 [==============================] - 5s 462us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 147s 3ms/step - loss: 1.9871 - acc: 0.2745 - val_loss: 1.3103 - val_acc: 0.4328\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.4983 - acc: 0.3921 - val_loss: 1.0637 - val_acc: 0.5253\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.3033 - acc: 0.4845 - val_loss: 0.9561 - val_acc: 0.6200\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.1638 - acc: 0.5490 - val_loss: 0.7583 - val_acc: 0.6685\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.0699 - acc: 0.5985 - val_loss: 0.7410 - val_acc: 0.6893\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.9972 - acc: 0.6368 - val_loss: 0.7251 - val_acc: 0.7398\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.9696 - acc: 0.6501 - val_loss: 0.6773 - val_acc: 0.7707\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.9590 - acc: 0.6703 - val_loss: 0.5999 - val_acc: 0.8000\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8897 - acc: 0.6971 - val_loss: 0.5252 - val_acc: 0.8132\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8946 - acc: 0.7020 - val_loss: 0.5692 - val_acc: 0.7993\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8502 - acc: 0.7255 - val_loss: 0.5427 - val_acc: 0.8577\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.9123 - acc: 0.7194 - val_loss: 0.5642 - val_acc: 0.8687\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.8218 - acc: 0.7776 - val_loss: 0.5610 - val_acc: 0.8540\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7931 - acc: 0.7869 - val_loss: 0.4648 - val_acc: 0.8937\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 0.7438 - acc: 0.8147 - val_loss: 0.4293 - val_acc: 0.9127\n",
      "10000/10000 [==============================] - 5s 473us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 150s 3ms/step - loss: 2.0049 - acc: 0.2959 - val_loss: 1.1653 - val_acc: 0.5100\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.3759 - acc: 0.4866 - val_loss: 0.9161 - val_acc: 0.6593\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.1377 - acc: 0.6023 - val_loss: 0.6965 - val_acc: 0.6802\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.0046 - acc: 0.6598 - val_loss: 0.6351 - val_acc: 0.8063\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.9659 - acc: 0.6837 - val_loss: 0.5769 - val_acc: 0.8448\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.9054 - acc: 0.7126 - val_loss: 0.5800 - val_acc: 0.8742\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.9106 - acc: 0.7277 - val_loss: 0.6486 - val_acc: 0.8108\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.9420 - acc: 0.7255 - val_loss: 0.5459 - val_acc: 0.8825\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.8688 - acc: 0.7617 - val_loss: 0.4899 - val_acc: 0.8965\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.9490 - acc: 0.7181 - val_loss: 0.5401 - val_acc: 0.8685\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.0452 - acc: 0.7000 - val_loss: 0.9759 - val_acc: 0.6903\n",
      "Epoch 12/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.0366 - acc: 0.6875\n",
      "Epoch 00012: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 113s 2ms/step - loss: 1.0366 - acc: 0.6875 - val_loss: 0.5733 - val_acc: 0.8563\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 0.8278 - acc: 0.7783 - val_loss: 0.4968 - val_acc: 0.8817\n",
      "Epoch 14/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 0.7798 - acc: 0.7934\n",
      "Epoch 00014: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 112s 2ms/step - loss: 0.7798 - acc: 0.7934 - val_loss: 0.4661 - val_acc: 0.8932\n",
      "Epoch 00014: early stopping\n",
      "10000/10000 [==============================] - 5s 492us/step\n",
      "0.9353\n",
      "\n",
      " \n",
      " Starting round with 35 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 166s 3ms/step - loss: 1.8817 - acc: 0.2907 - val_loss: 1.3766 - val_acc: 0.4052\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.5171 - acc: 0.3766 - val_loss: 1.1853 - val_acc: 0.4432\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.3701 - acc: 0.4216 - val_loss: 1.0662 - val_acc: 0.5020\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.2757 - acc: 0.4589 - val_loss: 0.9843 - val_acc: 0.5588\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.1974 - acc: 0.5225 - val_loss: 0.8493 - val_acc: 0.6873\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.1157 - acc: 0.5792 - val_loss: 0.7882 - val_acc: 0.6950\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.0612 - acc: 0.6159 - val_loss: 0.7465 - val_acc: 0.7507\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 1.0261 - acc: 0.6407 - val_loss: 0.7154 - val_acc: 0.7590\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.9783 - acc: 0.6627 - val_loss: 0.6583 - val_acc: 0.7667\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.9259 - acc: 0.6891 - val_loss: 0.6500 - val_acc: 0.7973\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.9176 - acc: 0.7047 - val_loss: 0.5920 - val_acc: 0.8072\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8735 - acc: 0.7190 - val_loss: 0.5742 - val_acc: 0.8115\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8889 - acc: 0.7182 - val_loss: 0.5518 - val_acc: 0.8177\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8427 - acc: 0.7373 - val_loss: 0.5792 - val_acc: 0.8197\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 0.8566 - acc: 0.7359 - val_loss: 0.5899 - val_acc: 0.8133\n",
      "10000/10000 [==============================] - 5s 503us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 167s 3ms/step - loss: 1.9686 - acc: 0.2741 - val_loss: 1.5565 - val_acc: 0.3598\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.6416 - acc: 0.3579 - val_loss: 1.3158 - val_acc: 0.4473\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.4688 - acc: 0.3975 - val_loss: 1.1632 - val_acc: 0.5185\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.3861 - acc: 0.4400 - val_loss: 1.1238 - val_acc: 0.5400\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.3061 - acc: 0.4776 - val_loss: 1.1610 - val_acc: 0.5375\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.3005 - acc: 0.4849 - val_loss: 1.1697 - val_acc: 0.5092\n",
      "Epoch 7/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.3911 - acc: 0.4544\n",
      "Epoch 00007: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 123s 2ms/step - loss: 1.3911 - acc: 0.4544 - val_loss: 1.4663 - val_acc: 0.4287\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.4326 - acc: 0.4124 - val_loss: 1.1558 - val_acc: 0.4772\n",
      "Epoch 9/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.3263 - acc: 0.4504\n",
      "Epoch 00009: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.3263 - acc: 0.4504 - val_loss: 1.1032 - val_acc: 0.5148\n",
      "Epoch 00009: early stopping\n",
      "10000/10000 [==============================] - 5s 523us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 169s 3ms/step - loss: 2.0334 - acc: 0.2620 - val_loss: 1.4756 - val_acc: 0.4202\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.6287 - acc: 0.3809 - val_loss: 1.2871 - val_acc: 0.4365\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 1.4206 - acc: 0.4572 - val_loss: 1.0214 - val_acc: 0.5918\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 1.2511 - acc: 0.5315 - val_loss: 0.8830 - val_acc: 0.6645\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 124s 2ms/step - loss: 1.1446 - acc: 0.5866 - val_loss: 0.7577 - val_acc: 0.7247\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 1.0565 - acc: 0.6263 - val_loss: 0.8152 - val_acc: 0.7155\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 1.0038 - acc: 0.6516 - val_loss: 0.7053 - val_acc: 0.7535\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 0.9585 - acc: 0.6691 - val_loss: 0.6777 - val_acc: 0.7585\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 0.9324 - acc: 0.6875 - val_loss: 0.6359 - val_acc: 0.8027\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 0.9141 - acc: 0.6970 - val_loss: 0.6855 - val_acc: 0.7748\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8894 - acc: 0.7119 - val_loss: 0.5328 - val_acc: 0.8687\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8866 - acc: 0.7262 - val_loss: 0.5668 - val_acc: 0.8628\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8543 - acc: 0.7458 - val_loss: 0.4832 - val_acc: 0.8860\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.8199 - acc: 0.7600 - val_loss: 0.4405 - val_acc: 0.8902\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.7756 - acc: 0.7800 - val_loss: 0.4634 - val_acc: 0.8792\n",
      "10000/10000 [==============================] - 5s 532us/step\n",
      "0.9047\n",
      "\n",
      " \n",
      " Starting round with 38 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 185s 3ms/step - loss: 2.1707 - acc: 0.2288 - val_loss: 1.6790 - val_acc: 0.3395\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.7943 - acc: 0.3041 - val_loss: 1.5162 - val_acc: 0.3598\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.6937 - acc: 0.3266 - val_loss: 1.4352 - val_acc: 0.3845\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.6118 - acc: 0.3547 - val_loss: 1.3481 - val_acc: 0.4338\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.5401 - acc: 0.3851 - val_loss: 1.2724 - val_acc: 0.5430\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.4788 - acc: 0.4233 - val_loss: 1.1929 - val_acc: 0.5643\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.4243 - acc: 0.4564 - val_loss: 1.1247 - val_acc: 0.5597\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3806 - acc: 0.4794 - val_loss: 1.1098 - val_acc: 0.5223\n",
      "Epoch 9/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.3260 - acc: 0.5024\n",
      "Epoch 00009: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 135s 3ms/step - loss: 1.3263 - acc: 0.5024 - val_loss: 1.0262 - val_acc: 0.5640\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.2577 - acc: 0.5270 - val_loss: 0.9948 - val_acc: 0.6127\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.2416 - acc: 0.5288 - val_loss: 0.9728 - val_acc: 0.6295\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.2159 - acc: 0.5347 - val_loss: 0.9414 - val_acc: 0.6397\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.2125 - acc: 0.5366 - val_loss: 0.9200 - val_acc: 0.6498\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.1954 - acc: 0.5449 - val_loss: 0.9357 - val_acc: 0.6308\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.1780 - acc: 0.5506 - val_loss: 0.9616 - val_acc: 0.6328\n",
      "10000/10000 [==============================] - 6s 588us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 189s 4ms/step - loss: 2.1811 - acc: 0.2547 - val_loss: 1.6650 - val_acc: 0.3240\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.7349 - acc: 0.3540 - val_loss: 1.3707 - val_acc: 0.4325\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.5966 - acc: 0.3908 - val_loss: 1.2346 - val_acc: 0.5418\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.5036 - acc: 0.4427 - val_loss: 1.1743 - val_acc: 0.5540\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.4461 - acc: 0.4683 - val_loss: 1.1445 - val_acc: 0.5588\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.4014 - acc: 0.4851 - val_loss: 1.0923 - val_acc: 0.5688\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3144 - acc: 0.5194 - val_loss: 1.0352 - val_acc: 0.5887\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3292 - acc: 0.5093 - val_loss: 1.1284 - val_acc: 0.5797\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3589 - acc: 0.4944 - val_loss: 1.2168 - val_acc: 0.5353\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3536 - acc: 0.5052 - val_loss: 1.0393 - val_acc: 0.5893\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.2319 - acc: 0.5496 - val_loss: 0.9331 - val_acc: 0.6348\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.1583 - acc: 0.5808 - val_loss: 0.8718 - val_acc: 0.6893\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.1220 - acc: 0.5996 - val_loss: 0.8853 - val_acc: 0.7110\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.0888 - acc: 0.6184 - val_loss: 0.8457 - val_acc: 0.7417\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.0620 - acc: 0.6386 - val_loss: 0.7581 - val_acc: 0.7455\n",
      "10000/10000 [==============================] - 6s 584us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 191s 4ms/step - loss: 2.2452 - acc: 0.2322 - val_loss: 1.7780 - val_acc: 0.3285\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.8257 - acc: 0.3326 - val_loss: 1.5314 - val_acc: 0.3725\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.6694 - acc: 0.3712 - val_loss: 1.4225 - val_acc: 0.4387\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.5744 - acc: 0.4029 - val_loss: 1.3102 - val_acc: 0.4620\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.5090 - acc: 0.4257 - val_loss: 1.3193 - val_acc: 0.5253\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.5002 - acc: 0.4366 - val_loss: 1.3018 - val_acc: 0.5515\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.4277 - acc: 0.4562 - val_loss: 1.1518 - val_acc: 0.5810\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.3620 - acc: 0.4876 - val_loss: 0.9979 - val_acc: 0.6633\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2760 - acc: 0.5181 - val_loss: 0.9547 - val_acc: 0.6838\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2222 - acc: 0.5566 - val_loss: 0.9894 - val_acc: 0.6838\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 1.2004 - acc: 0.5690 - val_loss: 0.9171 - val_acc: 0.6498\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 1.1313 - acc: 0.5980 - val_loss: 0.8827 - val_acc: 0.7215\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 1.1302 - acc: 0.6056 - val_loss: 0.9869 - val_acc: 0.7092\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.1402 - acc: 0.6108 - val_loss: 0.9228 - val_acc: 0.7290\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 1.1421 - acc: 0.6149 - val_loss: 0.8296 - val_acc: 0.7472\n",
      "10000/10000 [==============================] - 6s 583us/step\n",
      "0.7936\n",
      "\n",
      " \n",
      " Starting round with 41 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 201s 4ms/step - loss: 2.1442 - acc: 0.2001 - val_loss: 1.7599 - val_acc: 0.3012\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 138s 3ms/step - loss: 1.8171 - acc: 0.2912 - val_loss: 1.4510 - val_acc: 0.3977\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.6326 - acc: 0.3522 - val_loss: 1.3579 - val_acc: 0.4157\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.5282 - acc: 0.3831 - val_loss: 1.3078 - val_acc: 0.4328\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 142s 3ms/step - loss: 1.4716 - acc: 0.4056 - val_loss: 1.2480 - val_acc: 0.4928\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.4289 - acc: 0.4268 - val_loss: 1.2362 - val_acc: 0.5100\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.3932 - acc: 0.4566 - val_loss: 1.1445 - val_acc: 0.5693\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.3423 - acc: 0.4851 - val_loss: 1.0687 - val_acc: 0.5912\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.3053 - acc: 0.4963 - val_loss: 1.0332 - val_acc: 0.5787\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.2597 - acc: 0.5139 - val_loss: 1.0042 - val_acc: 0.5865\n",
      "Epoch 11/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.2742 - acc: 0.5123\n",
      "Epoch 00011: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 148s 3ms/step - loss: 1.2744 - acc: 0.5123 - val_loss: 1.0225 - val_acc: 0.5902\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.2162 - acc: 0.5320 - val_loss: 0.9922 - val_acc: 0.5963\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.1994 - acc: 0.5389 - val_loss: 0.9551 - val_acc: 0.6037\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.2096 - acc: 0.5366 - val_loss: 0.9641 - val_acc: 0.6147\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.1643 - acc: 0.5504 - val_loss: 0.9374 - val_acc: 0.6083\n",
      "10000/10000 [==============================] - 6s 643us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 212s 4ms/step - loss: 2.1089 - acc: 0.2156 - val_loss: 1.7306 - val_acc: 0.3678\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.8429 - acc: 0.2914 - val_loss: 1.5879 - val_acc: 0.4092\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.7057 - acc: 0.3474 - val_loss: 1.4104 - val_acc: 0.4517\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.6031 - acc: 0.3827 - val_loss: 1.3372 - val_acc: 0.4713\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.5349 - acc: 0.3987 - val_loss: 1.2403 - val_acc: 0.4888\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.4837 - acc: 0.4167 - val_loss: 1.2909 - val_acc: 0.4765\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.4425 - acc: 0.4305 - val_loss: 1.2069 - val_acc: 0.5118\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.4070 - acc: 0.4477 - val_loss: 1.1844 - val_acc: 0.5422\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.4288 - acc: 0.4479 - val_loss: 1.2963 - val_acc: 0.4717\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.4189 - acc: 0.4435 - val_loss: 1.1182 - val_acc: 0.5420\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.3558 - acc: 0.4709 - val_loss: 1.1001 - val_acc: 0.5852\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.3535 - acc: 0.4843 - val_loss: 1.0805 - val_acc: 0.6080\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.3426 - acc: 0.4925 - val_loss: 1.1325 - val_acc: 0.5863\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.3167 - acc: 0.5077 - val_loss: 1.0855 - val_acc: 0.5628\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.3309 - acc: 0.5029 - val_loss: 1.0864 - val_acc: 0.6212\n",
      "10000/10000 [==============================] - 6s 637us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "act = e_swish_2\n",
    "logs.info(\"\\n \\n \\n\"+\"\\n \\n \\n\")\n",
    "logs.info(\"ESWISH 23-42\")\n",
    "\n",
    "logs_e_swish_2 = []\n",
    "record_e_swish_2 = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    logs.info(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        logs.info(\"Accuracy \"+str(i)+\": \"+str(logger[-1]))\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_e_swish_2.append([n, ensembled])\n",
    "    logs_e_swish_2.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    logs.info(\"Ensembled accuracy: \"+str(record_e_swish_2[-1]))\n",
    "    logs.info(\"Logs: +\"+str(logs_e_swish_2[-1]))\n",
    "    \n",
    "logs.info(\"\\n \\n \\n\")\n",
    "logs.info(\"Logs e_swish_2: \"+str(logs_e_swish_2))\n",
    "logs.info(\"Record e_swish_2: \"+str(record_e_swish_2))\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs e_swish_2: \", logs_e_swish_2)\n",
    "print(\"Record e_swish_2: \", record_e_swish_2)\n",
    "    \n",
    "plot([[x[1] for x in logs_relu], [x[1] for x in logs_e_swish_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Starting round with 41 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 140s 3ms/step - loss: 2.3038 - acc: 0.1406 - val_loss: 2.0706 - val_acc: 0.1923\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 2.0379 - acc: 0.2082 - val_loss: 1.6829 - val_acc: 0.3590\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.8362 - acc: 0.2873 - val_loss: 1.5304 - val_acc: 0.3847\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.7062 - acc: 0.3286 - val_loss: 1.3722 - val_acc: 0.4520\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.6300 - acc: 0.3511 - val_loss: 1.3249 - val_acc: 0.4560\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.5921 - acc: 0.3683 - val_loss: 1.2773 - val_acc: 0.4715\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.5210 - acc: 0.3947 - val_loss: 1.2199 - val_acc: 0.5048\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.4763 - acc: 0.4110 - val_loss: 1.1553 - val_acc: 0.5087\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.4386 - acc: 0.4236 - val_loss: 1.1733 - val_acc: 0.5128\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.4142 - acc: 0.4379 - val_loss: 1.1209 - val_acc: 0.5393\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.3972 - acc: 0.4476 - val_loss: 1.2173 - val_acc: 0.5260\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.3803 - acc: 0.4607 - val_loss: 1.1212 - val_acc: 0.5545\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.3952 - acc: 0.4548 - val_loss: 1.0860 - val_acc: 0.5848\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.3740 - acc: 0.4694 - val_loss: 1.1527 - val_acc: 0.5573\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.3548 - acc: 0.4726 - val_loss: 1.0085 - val_acc: 0.5955\n",
      "10000/10000 [==============================] - 5s 501us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 2.1643 - acc: 0.2034 - val_loss: 1.8464 - val_acc: 0.3268\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.8489 - acc: 0.3126 - val_loss: 1.5335 - val_acc: 0.4038\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.6655 - acc: 0.3639 - val_loss: 1.3698 - val_acc: 0.4458\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 135s 3ms/step - loss: 1.5496 - acc: 0.3935 - val_loss: 1.2659 - val_acc: 0.4668\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 135s 3ms/step - loss: 1.4852 - acc: 0.4126 - val_loss: 1.2291 - val_acc: 0.4860\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.4302 - acc: 0.4237 - val_loss: 1.1775 - val_acc: 0.5048\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 133s 2ms/step - loss: 1.3814 - acc: 0.4394 - val_loss: 1.1432 - val_acc: 0.4968\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3527 - acc: 0.4472 - val_loss: 1.1228 - val_acc: 0.5063\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3153 - acc: 0.4539 - val_loss: 1.1165 - val_acc: 0.4855\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.3111 - acc: 0.4544 - val_loss: 1.1080 - val_acc: 0.5113\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 1.2839 - acc: 0.4612 - val_loss: 1.0990 - val_acc: 0.5185\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2570 - acc: 0.4708 - val_loss: 1.0749 - val_acc: 0.5145\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2470 - acc: 0.4744 - val_loss: 1.0383 - val_acc: 0.5495\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2396 - acc: 0.4871 - val_loss: 1.0218 - val_acc: 0.5642\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 130s 2ms/step - loss: 1.2041 - acc: 0.5043 - val_loss: 1.0405 - val_acc: 0.5592\n",
      "10000/10000 [==============================] - 5s 497us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 142s 3ms/step - loss: 2.3649 - acc: 0.1016 - val_loss: 2.2993 - val_acc: 0.1103\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 2.3057 - acc: 0.1184 - val_loss: 2.2853 - val_acc: 0.1530\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 2.2611 - acc: 0.1518 - val_loss: 2.1381 - val_acc: 0.2008\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 135s 2ms/step - loss: 2.1879 - acc: 0.1809 - val_loss: 2.0533 - val_acc: 0.2235\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 135s 3ms/step - loss: 2.1205 - acc: 0.2000 - val_loss: 1.9775 - val_acc: 0.2372\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 135s 2ms/step - loss: 2.0563 - acc: 0.2273 - val_loss: 1.8490 - val_acc: 0.2965\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 135s 2ms/step - loss: 1.9572 - acc: 0.2624 - val_loss: 1.6662 - val_acc: 0.3758\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.8586 - acc: 0.2899 - val_loss: 1.6010 - val_acc: 0.3888\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.7828 - acc: 0.3044 - val_loss: 1.5161 - val_acc: 0.3938\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.7462 - acc: 0.3124 - val_loss: 1.5090 - val_acc: 0.4008\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.7028 - acc: 0.3230 - val_loss: 1.4188 - val_acc: 0.4102\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.6612 - acc: 0.3310 - val_loss: 1.3798 - val_acc: 0.4378\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.6263 - acc: 0.3470 - val_loss: 1.3298 - val_acc: 0.4813\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 132s 2ms/step - loss: 1.5953 - acc: 0.3544 - val_loss: 1.2829 - val_acc: 0.4737\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 1.5675 - acc: 0.3654 - val_loss: 1.2745 - val_acc: 0.4887\n",
      "10000/10000 [==============================] - 5s 507us/step\n",
      "0.679\n",
      "\n",
      " \n",
      " Starting round with 44 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 156s 3ms/step - loss: 2.4722 - acc: 0.1218 - val_loss: 2.1897 - val_acc: 0.1830\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 2.2008 - acc: 0.1718 - val_loss: 2.0837 - val_acc: 0.2348\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 2.1017 - acc: 0.2015 - val_loss: 1.8868 - val_acc: 0.2635\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 2.0335 - acc: 0.2138 - val_loss: 1.8411 - val_acc: 0.2822\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.9797 - acc: 0.2257 - val_loss: 1.7637 - val_acc: 0.2833\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.9390 - acc: 0.2358 - val_loss: 1.7439 - val_acc: 0.2773\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.9051 - acc: 0.2455 - val_loss: 1.7005 - val_acc: 0.3055\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.8740 - acc: 0.2576 - val_loss: 1.6443 - val_acc: 0.3317\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 142s 3ms/step - loss: 1.8369 - acc: 0.2670 - val_loss: 1.6188 - val_acc: 0.3180\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 1.8176 - acc: 0.2744 - val_loss: 1.5991 - val_acc: 0.3493\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.7845 - acc: 0.2829 - val_loss: 1.5969 - val_acc: 0.3543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.7652 - acc: 0.2927 - val_loss: 1.6418 - val_acc: 0.3443\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 1.7439 - acc: 0.2987 - val_loss: 1.6365 - val_acc: 0.3762\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.7236 - acc: 0.3065 - val_loss: 1.8872 - val_acc: 0.3463\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 142s 3ms/step - loss: 1.6968 - acc: 0.3172 - val_loss: 2.0396 - val_acc: 0.3560\n",
      "10000/10000 [==============================] - 5s 546us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 159s 3ms/step - loss: 2.4932 - acc: 0.1228 - val_loss: 2.2272 - val_acc: 0.0997\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 2.2148 - acc: 0.1710 - val_loss: 2.1071 - val_acc: 0.1945\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 2.1358 - acc: 0.1880 - val_loss: 2.0248 - val_acc: 0.2258\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 2.0682 - acc: 0.1977 - val_loss: 1.9193 - val_acc: 0.2300\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.9878 - acc: 0.2080 - val_loss: 1.8347 - val_acc: 0.2695\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.9259 - acc: 0.2240 - val_loss: 1.7532 - val_acc: 0.2583\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 147s 3ms/step - loss: 1.8701 - acc: 0.2450 - val_loss: 1.6683 - val_acc: 0.3253\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.8058 - acc: 0.2732 - val_loss: 1.5864 - val_acc: 0.3107\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.7350 - acc: 0.2986 - val_loss: 1.4601 - val_acc: 0.4045\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.6781 - acc: 0.3231 - val_loss: 1.4073 - val_acc: 0.4257\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 1.6187 - acc: 0.3464 - val_loss: 1.3308 - val_acc: 0.4595\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.5733 - acc: 0.3644 - val_loss: 1.2976 - val_acc: 0.4560\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.5448 - acc: 0.3859 - val_loss: 1.2761 - val_acc: 0.4857\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.5032 - acc: 0.4020 - val_loss: 1.2401 - val_acc: 0.4782\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.4867 - acc: 0.4064 - val_loss: 1.2073 - val_acc: 0.5113\n",
      "10000/10000 [==============================] - 6s 572us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 168s 3ms/step - loss: 2.4258 - acc: 0.1513 - val_loss: 2.0415 - val_acc: 0.2923\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 147s 3ms/step - loss: 2.0972 - acc: 0.2365 - val_loss: 1.8824 - val_acc: 0.3028\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.9928 - acc: 0.2632 - val_loss: 1.7859 - val_acc: 0.3117\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 147s 3ms/step - loss: 1.9189 - acc: 0.2836 - val_loss: 1.6812 - val_acc: 0.3143\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 147s 3ms/step - loss: 1.8580 - acc: 0.2909 - val_loss: 1.6030 - val_acc: 0.3592\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.8107 - acc: 0.2989 - val_loss: 1.5806 - val_acc: 0.3843\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.7838 - acc: 0.3065 - val_loss: 1.5491 - val_acc: 0.3670\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.7441 - acc: 0.3194 - val_loss: 1.5258 - val_acc: 0.3755\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.7246 - acc: 0.3226 - val_loss: 1.4924 - val_acc: 0.3973\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.6938 - acc: 0.3303 - val_loss: 1.4606 - val_acc: 0.4048\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.6746 - acc: 0.3353 - val_loss: 1.4463 - val_acc: 0.4312\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.6353 - acc: 0.3461 - val_loss: 1.5158 - val_acc: 0.4285\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 1.6273 - acc: 0.3492 - val_loss: 1.4647 - val_acc: 0.4062\n",
      "Epoch 14/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 1.5953 - acc: 0.3600\n",
      "Epoch 00014: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.5954 - acc: 0.3600 - val_loss: 1.7459 - val_acc: 0.3537\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 146s 3ms/step - loss: 1.5694 - acc: 0.3670 - val_loss: 1.6717 - val_acc: 0.3930\n",
      "10000/10000 [==============================] - 6s 570us/step\n",
      "0.6189\n",
      "\n",
      " \n",
      " Starting round with 47 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2f42137176e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n\u001b[1;32m---> 29\u001b[1;33m                             verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Record accuracy of each model and save it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2353\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2355\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m   2357\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 182\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1291\u001b[0m                 run_metadata):\n\u001b[0;32m   1292\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1293\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m-> 1354\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializeToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[0;32m   1036\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[1;32m-> 1037\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1044\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1055\u001b[0m       \u001b[0mdeterministic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m       \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m       \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeRepeatedField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEncodeRepeatedField\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1055\u001b[0m       \u001b[0mdeterministic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m       \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m       \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    822\u001b[0m     \u001b[0mvalue_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m       \u001b[0mentry_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m       \u001b[0mencode_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eric\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetIntegerEnumValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menum_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m           \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m           \u001b[0m_ReraiseTypeErrorWithFieldName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "act = e_swish_2\n",
    "# logs.info(\"\\n \\n \\n\"+\"\\n \\n \\n\")\n",
    "# logs.info(\"ESWISH 41-42\")\n",
    "\n",
    "logs_e_swish_2 = []\n",
    "record_e_swish_2 = []\n",
    "for n in range(41,45,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    logs.info(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        logs.info(\"Accuracy \"+str(i)+\": \"+str(logger[-1]))\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_e_swish_2.append([n, ensembled])\n",
    "    logs_e_swish_2.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    logs.info(\"Ensembled accuracy: \"+str(record_e_swish_2[-1]))\n",
    "    logs.info(\"Logs: +\"+str(logs_e_swish_2[-1]))\n",
    "    \n",
    "# logs.info(\"\\n \\n \\n\")\n",
    "# logs.info(\"Logs e_swish_2: \"+str(logs_e_swish_2))\n",
    "# logs.info(\"Record e_swish_2: \"+str(record_e_swish_2))\n",
    "    \n",
    "# print(\"\\n \\n \\n\")\n",
    "# print(\"Logs e_swish_2: \", logs_e_swish_2)\n",
    "# print(\"Record e_swish_2: \", record_e_swish_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "Logs e_swish_2:  [[41, 0.6018, 0.55249999999999999, 0.48520000000000002], [44, 0.35160000000000002, 0.51910000000000001, 0.3891]]\n",
      "Record e_swish_2:  [[41, 0.679], [44, 0.6189]]\n"
     ]
    }
   ],
   "source": [
    "logs.info(\"\\n \\n \\n\")\n",
    "logs.info(\"Logs e_swish_2: \"+str(logs_e_swish_2))\n",
    "logs.info(\"Record e_swish_2: \"+str(record_e_swish_2))\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs e_swish_2: \", logs_e_swish_2)\n",
    "print(\"Record e_swish_2: \", record_e_swish_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = swish\n",
    "logs.info(\"\\n \\n \\n\"+\"\\n \\n \\n\")\n",
    "logs.info(\"SWISH 23-42\")\n",
    "\n",
    "logs_swish = []\n",
    "record_swish = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    logs.info(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        logs.info(\"Accuracy \"+str(i)+\": \"+str(logger[-1]))\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_swish.append([n, ensembled])\n",
    "    logs_swish.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    logs.info(\"Ensembled accuracy: \"+str(record_swish[-1]))\n",
    "    logs.info(\"Logs: +\"+str(logs_swish[-1]))\n",
    "    \n",
    "logs.info(\"\\n \\n \\n\")\n",
    "logs.info(\"Logs swish: \"+str(logs_swish))\n",
    "logs.info(\"Record swish: \"+str(record_swish))\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs swish: \", logs_swish)\n",
    "print(\"Record swish: \", record_swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"RELU: \", logs_relu)\n",
    "print(\"E-SWISH: \", logs_e_swish_2)\n",
    "print(\"SWISH: \", logs_swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

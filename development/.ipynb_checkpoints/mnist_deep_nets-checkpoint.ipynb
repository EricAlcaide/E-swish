{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Repeating MNIST first experiment of swish paper. \"\"\"\n",
    "\n",
    "import gc # Garbage collector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# For adding new activation function\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "nb_classes = 10\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) (6000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_val = X_val.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "# test = test.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x*K.sigmoid(x)\n",
    "\n",
    "def e_swish_2(x):\n",
    "    sigmoid = K.sigmoid(x)\n",
    "    return K.maximum(x*sigmoid, x*(2-sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "def create(act, n):\n",
    "    model = Sequential()\n",
    "    # First conv block\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation(act))\n",
    "    for i in range(n-1):\n",
    "        if i%2 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(act))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(arr, names = [\"relu\", \"e_swish_2\", \"swish\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    for item in arr:\n",
    "        ax.plot(np.array(item))\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.legend(names[:len(arr)], loc='upper right')\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    y_hat = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y_test, axis=1)\n",
    "\n",
    "    good = np.sum(np.equal(y, y_hat))\n",
    "    return float(good/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Starting round with 23 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 1.8138 - acc: 0.3087 - val_loss: 1.1260 - val_acc: 0.5507\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.2893 - acc: 0.5202 - val_loss: 0.9207 - val_acc: 0.6202\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0644 - acc: 0.6229 - val_loss: 0.5850 - val_acc: 0.7962\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.8988 - acc: 0.7164 - val_loss: 0.4861 - val_acc: 0.8677\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7803 - acc: 0.7758 - val_loss: 0.3949 - val_acc: 0.8998\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7047 - acc: 0.8082 - val_loss: 0.3282 - val_acc: 0.9175\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6350 - acc: 0.8374 - val_loss: 0.3050 - val_acc: 0.9350\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5737 - acc: 0.8583 - val_loss: 0.2914 - val_acc: 0.9350\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 71s 1ms/step - loss: 0.5354 - acc: 0.8728 - val_loss: 0.2899 - val_acc: 0.9353\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4996 - acc: 0.8849 - val_loss: 0.2261 - val_acc: 0.9500\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4711 - acc: 0.8925 - val_loss: 0.1973 - val_acc: 0.9552\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4436 - acc: 0.8996 - val_loss: 0.2120 - val_acc: 0.9542\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4255 - acc: 0.9039 - val_loss: 0.1910 - val_acc: 0.9587\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3896 - acc: 0.9135 - val_loss: 0.1816 - val_acc: 0.9607\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3799 - acc: 0.9154 - val_loss: 0.1784 - val_acc: 0.9622\n",
      "10000/10000 [==============================] - 3s 269us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 74s 1ms/step - loss: 1.8127 - acc: 0.3074 - val_loss: 1.3107 - val_acc: 0.4187\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.4308 - acc: 0.4223 - val_loss: 1.0700 - val_acc: 0.5315\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.2363 - acc: 0.5301 - val_loss: 0.8384 - val_acc: 0.6692\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0572 - acc: 0.6320 - val_loss: 0.6474 - val_acc: 0.7562\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.9042 - acc: 0.7116 - val_loss: 0.5228 - val_acc: 0.8303\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7645 - acc: 0.7876 - val_loss: 0.3467 - val_acc: 0.9162\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6375 - acc: 0.8412 - val_loss: 0.2950 - val_acc: 0.9327\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5902 - acc: 0.8589 - val_loss: 0.2737 - val_acc: 0.9385\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5359 - acc: 0.8741 - val_loss: 0.2423 - val_acc: 0.9450\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4854 - acc: 0.8887 - val_loss: 0.2335 - val_acc: 0.9480\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4661 - acc: 0.8951 - val_loss: 0.2555 - val_acc: 0.9428\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4263 - acc: 0.9038 - val_loss: 0.2108 - val_acc: 0.9528\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4121 - acc: 0.9078 - val_loss: 0.1952 - val_acc: 0.9577\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3795 - acc: 0.9153 - val_loss: 0.1928 - val_acc: 0.9575\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3760 - acc: 0.9171 - val_loss: 0.1806 - val_acc: 0.9592\n",
      "10000/10000 [==============================] - 3s 273us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 75s 1ms/step - loss: 1.7887 - acc: 0.3216 - val_loss: 1.1843 - val_acc: 0.5382\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.3035 - acc: 0.5196 - val_loss: 0.7345 - val_acc: 0.7475\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 1.0250 - acc: 0.6629 - val_loss: 0.5340 - val_acc: 0.7988\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.8569 - acc: 0.7424 - val_loss: 0.4266 - val_acc: 0.8577\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.7270 - acc: 0.7926 - val_loss: 0.3304 - val_acc: 0.9098\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.6308 - acc: 0.8376 - val_loss: 0.2981 - val_acc: 0.9323\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5508 - acc: 0.8681 - val_loss: 0.2565 - val_acc: 0.9405\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.5030 - acc: 0.8828 - val_loss: 0.2424 - val_acc: 0.9455\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4592 - acc: 0.8956 - val_loss: 0.2017 - val_acc: 0.9535\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4238 - acc: 0.9049 - val_loss: 0.1809 - val_acc: 0.9597\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3871 - acc: 0.9153 - val_loss: 0.1930 - val_acc: 0.9628\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3656 - acc: 0.9210 - val_loss: 0.1650 - val_acc: 0.9645\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3505 - acc: 0.9248 - val_loss: 0.1512 - val_acc: 0.9670\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3241 - acc: 0.9287 - val_loss: 0.1535 - val_acc: 0.9658\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.3223 - acc: 0.9316 - val_loss: 0.1555 - val_acc: 0.9667\n",
      "10000/10000 [==============================] - 3s 277us/step\n",
      "0.9717\n",
      "\n",
      " \n",
      " Starting round with 26 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 2.0965 - acc: 0.2386 - val_loss: 1.6202 - val_acc: 0.3768\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.7012 - acc: 0.3495 - val_loss: 1.4475 - val_acc: 0.4187\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.5591 - acc: 0.3974 - val_loss: 1.2574 - val_acc: 0.5033\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.4484 - acc: 0.4457 - val_loss: 1.1232 - val_acc: 0.5427\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.3466 - acc: 0.4886 - val_loss: 0.9860 - val_acc: 0.6398\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.2584 - acc: 0.5271 - val_loss: 0.9340 - val_acc: 0.6635\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.1640 - acc: 0.5663 - val_loss: 0.8329 - val_acc: 0.6995\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.1019 - acc: 0.5921 - val_loss: 0.7778 - val_acc: 0.7352\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 1.0371 - acc: 0.6234 - val_loss: 0.7590 - val_acc: 0.7663\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 0.9852 - acc: 0.6538 - val_loss: 0.6538 - val_acc: 0.8298\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 79s 1ms/step - loss: 0.9471 - acc: 0.6815 - val_loss: 0.6097 - val_acc: 0.8428\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8885 - acc: 0.7088 - val_loss: 0.5574 - val_acc: 0.8697\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8460 - acc: 0.7373 - val_loss: 0.4696 - val_acc: 0.8858\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7891 - acc: 0.7652 - val_loss: 0.4418 - val_acc: 0.8923\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.7483 - acc: 0.7843 - val_loss: 0.4252 - val_acc: 0.9003\n",
      "10000/10000 [==============================] - 3s 296us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.9982 - acc: 0.2780 - val_loss: 1.4930 - val_acc: 0.3850\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.6130 - acc: 0.3946 - val_loss: 1.3057 - val_acc: 0.4868\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.4823 - acc: 0.4450 - val_loss: 1.1480 - val_acc: 0.5847\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.3685 - acc: 0.4872 - val_loss: 1.0389 - val_acc: 0.6068\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.2939 - acc: 0.5173 - val_loss: 0.9993 - val_acc: 0.6492\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.2344 - acc: 0.5405 - val_loss: 0.9296 - val_acc: 0.6480\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1697 - acc: 0.5709 - val_loss: 0.8562 - val_acc: 0.7013\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1067 - acc: 0.5964 - val_loss: 0.7633 - val_acc: 0.7223\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 1.0381 - acc: 0.6321 - val_loss: 0.6844 - val_acc: 0.7543\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.9666 - acc: 0.6657 - val_loss: 0.6309 - val_acc: 0.7805\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.9099 - acc: 0.6927 - val_loss: 0.5844 - val_acc: 0.7948\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8645 - acc: 0.7087 - val_loss: 0.5682 - val_acc: 0.8060\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8228 - acc: 0.7250 - val_loss: 0.5175 - val_acc: 0.8213\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 77s 1ms/step - loss: 0.8015 - acc: 0.7332 - val_loss: 0.5245 - val_acc: 0.8323\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 0.7605 - acc: 0.7484 - val_loss: 0.4922 - val_acc: 0.8293\n",
      "10000/10000 [==============================] - 3s 301us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.9193 - acc: 0.2708 - val_loss: 1.3611 - val_acc: 0.4457\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.5362 - acc: 0.3966 - val_loss: 1.1773 - val_acc: 0.5177\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.3826 - acc: 0.4704 - val_loss: 0.9958 - val_acc: 0.6235\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.2693 - acc: 0.5365 - val_loss: 0.9077 - val_acc: 0.6522\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1785 - acc: 0.5718 - val_loss: 0.8301 - val_acc: 0.7077\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.1156 - acc: 0.6007 - val_loss: 0.7792 - val_acc: 0.7192\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 1.0420 - acc: 0.6306 - val_loss: 0.7153 - val_acc: 0.7145\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 78s 1ms/step - loss: 0.9859 - acc: 0.6512 - val_loss: 0.6334 - val_acc: 0.7340\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.9308 - acc: 0.6704 - val_loss: 0.6165 - val_acc: 0.7670\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 81s 1ms/step - loss: 0.8900 - acc: 0.6859 - val_loss: 0.6492 - val_acc: 0.7450\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.8732 - acc: 0.6962 - val_loss: 0.5701 - val_acc: 0.7725\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.8173 - acc: 0.7156 - val_loss: 0.5401 - val_acc: 0.7613\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7909 - acc: 0.7352 - val_loss: 0.5304 - val_acc: 0.8087\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7601 - acc: 0.7490 - val_loss: 0.5166 - val_acc: 0.8232\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 80s 1ms/step - loss: 0.7245 - acc: 0.7640 - val_loss: 0.4621 - val_acc: 0.8750\n",
      "10000/10000 [==============================] - 3s 318us/step\n",
      "0.9253\n",
      "\n",
      " \n",
      " Starting round with 29 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 103s 2ms/step - loss: 2.1394 - acc: 0.1811 - val_loss: 1.7070 - val_acc: 0.3285\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 91s 2ms/step - loss: 1.7998 - acc: 0.3149 - val_loss: 1.5464 - val_acc: 0.3957\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.6298 - acc: 0.3833 - val_loss: 1.2759 - val_acc: 0.4550\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.4793 - acc: 0.4264 - val_loss: 1.1568 - val_acc: 0.5247\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3912 - acc: 0.4651 - val_loss: 1.0731 - val_acc: 0.5627\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3086 - acc: 0.5055 - val_loss: 1.0157 - val_acc: 0.5457\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.2459 - acc: 0.5271 - val_loss: 0.9286 - val_acc: 0.6388\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1952 - acc: 0.5484 - val_loss: 0.9310 - val_acc: 0.6375\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1534 - acc: 0.5686 - val_loss: 0.8297 - val_acc: 0.6802\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1198 - acc: 0.5861 - val_loss: 0.7934 - val_acc: 0.7277\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.0700 - acc: 0.6063 - val_loss: 0.7759 - val_acc: 0.6990\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.0440 - acc: 0.6205 - val_loss: 0.7147 - val_acc: 0.7422\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.0073 - acc: 0.6439 - val_loss: 0.6642 - val_acc: 0.7405\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.9668 - acc: 0.6679 - val_loss: 0.6584 - val_acc: 0.7730\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 0.9263 - acc: 0.6883 - val_loss: 0.5509 - val_acc: 0.8540\n",
      "10000/10000 [==============================] - 3s 334us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 2.1911 - acc: 0.1815 - val_loss: 1.9103 - val_acc: 0.2967\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.8623 - acc: 0.3161 - val_loss: 1.4190 - val_acc: 0.4310\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.6369 - acc: 0.3754 - val_loss: 1.3025 - val_acc: 0.4440\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.5305 - acc: 0.4017 - val_loss: 1.1705 - val_acc: 0.5273\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.4550 - acc: 0.4201 - val_loss: 1.1449 - val_acc: 0.5030\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3927 - acc: 0.4374 - val_loss: 1.0832 - val_acc: 0.5417\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.3294 - acc: 0.4742 - val_loss: 0.9845 - val_acc: 0.5847\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.2646 - acc: 0.5022 - val_loss: 1.0034 - val_acc: 0.5597\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.2213 - acc: 0.5196 - val_loss: 0.9305 - val_acc: 0.5847\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.1738 - acc: 0.5393 - val_loss: 0.9307 - val_acc: 0.6253: 1.1738 - a\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.1366 - acc: 0.5599 - val_loss: 0.8411 - val_acc: 0.6435\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0811 - acc: 0.5784 - val_loss: 0.7895 - val_acc: 0.6858\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 86s 2ms/step - loss: 1.0426 - acc: 0.5961 - val_loss: 0.7910 - val_acc: 0.6593\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0739 - acc: 0.5937 - val_loss: 0.7843 - val_acc: 0.6813\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.0118 - acc: 0.6188 - val_loss: 0.7808 - val_acc: 0.7212\n",
      "10000/10000 [==============================] - 3s 333us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 2.1707 - acc: 0.1879 - val_loss: 1.8979 - val_acc: 0.2793\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 87s 2ms/step - loss: 1.9157 - acc: 0.2715 - val_loss: 1.6330 - val_acc: 0.3645\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 89s 2ms/step - loss: 1.7204 - acc: 0.3492 - val_loss: 1.3882 - val_acc: 0.4198\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.5528 - acc: 0.3921 - val_loss: 1.2597 - val_acc: 0.4192\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.4544 - acc: 0.4181 - val_loss: 1.1931 - val_acc: 0.4315\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.3751 - acc: 0.4313 - val_loss: 1.1190 - val_acc: 0.4732\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.3259 - acc: 0.4407 - val_loss: 1.0745 - val_acc: 0.4770\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2873 - acc: 0.4480 - val_loss: 1.0574 - val_acc: 0.4987\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2566 - acc: 0.4563 - val_loss: 1.0469 - val_acc: 0.4938\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 90s 2ms/step - loss: 1.2376 - acc: 0.4596 - val_loss: 1.0235 - val_acc: 0.5013\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.2063 - acc: 0.4659 - val_loss: 1.0285 - val_acc: 0.5103\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1835 - acc: 0.4759 - val_loss: 0.9935 - val_acc: 0.5475\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1776 - acc: 0.4825 - val_loss: 1.0194 - val_acc: 0.5100\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.1348 - acc: 0.5128 - val_loss: 0.9473 - val_acc: 0.6028\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 88s 2ms/step - loss: 1.0958 - acc: 0.5578 - val_loss: 0.8550 - val_acc: 0.6808\n",
      "10000/10000 [==============================] - 3s 335us/step\n",
      "0.8639\n",
      "\n",
      " \n",
      " Starting round with 32 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 115s 2ms/step - loss: 2.2819 - acc: 0.1619 - val_loss: 2.0311 - val_acc: 0.2308\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 2.0998 - acc: 0.2201 - val_loss: 1.9076 - val_acc: 0.2703\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 2.0102 - acc: 0.2480 - val_loss: 1.8020 - val_acc: 0.2720\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.9118 - acc: 0.2798 - val_loss: 1.6791 - val_acc: 0.3537\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.8303 - acc: 0.3080 - val_loss: 1.5650 - val_acc: 0.4035\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7538 - acc: 0.3427 - val_loss: 1.4796 - val_acc: 0.4688\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.6694 - acc: 0.3717 - val_loss: 1.3897 - val_acc: 0.5032\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.5914 - acc: 0.4072 - val_loss: 1.2499 - val_acc: 0.5707\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 102s 2ms/step - loss: 1.5251 - acc: 0.4347 - val_loss: 1.1472 - val_acc: 0.5955\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.4724 - acc: 0.4477 - val_loss: 1.1315 - val_acc: 0.5867\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4302 - acc: 0.4660 - val_loss: 1.0692 - val_acc: 0.6055\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.3794 - acc: 0.4866 - val_loss: 1.0372 - val_acc: 0.6585\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.3485 - acc: 0.4999 - val_loss: 1.0167 - val_acc: 0.6445\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.3117 - acc: 0.5146 - val_loss: 0.9546 - val_acc: 0.6678\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.2927 - acc: 0.5249 - val_loss: 1.0052 - val_acc: 0.6493\n",
      "10000/10000 [==============================] - 4s 375us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3233 - acc: 0.1530 - val_loss: 2.0805 - val_acc: 0.2280\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 2.1543 - acc: 0.2000 - val_loss: 2.0418 - val_acc: 0.2420\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 2.1086 - acc: 0.2196 - val_loss: 2.0094 - val_acc: 0.2450\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 2.0575 - acc: 0.2346 - val_loss: 1.9317 - val_acc: 0.2675\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.9923 - acc: 0.2468 - val_loss: 1.8413 - val_acc: 0.2805\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.9421 - acc: 0.2562 - val_loss: 1.7853 - val_acc: 0.3082\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.9036 - acc: 0.2664 - val_loss: 1.7303 - val_acc: 0.3182\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.8634 - acc: 0.2826 - val_loss: 1.6881 - val_acc: 0.3362\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.8381 - acc: 0.2965 - val_loss: 1.6552 - val_acc: 0.3648\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.7947 - acc: 0.3189 - val_loss: 1.5889 - val_acc: 0.4140\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7464 - acc: 0.3355 - val_loss: 1.5312 - val_acc: 0.4028\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.7009 - acc: 0.3528 - val_loss: 1.4869 - val_acc: 0.4340\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.6573 - acc: 0.3658 - val_loss: 1.4087 - val_acc: 0.4515\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 97s 2ms/step - loss: 1.6122 - acc: 0.3799 - val_loss: 1.4059 - val_acc: 0.4772\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.5790 - acc: 0.3910 - val_loss: 1.3455 - val_acc: 0.4585\n",
      "10000/10000 [==============================] - 4s 389us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3440 - acc: 0.1451 - val_loss: 2.1683 - val_acc: 0.1923\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 2.1421 - acc: 0.1992 - val_loss: 2.0372 - val_acc: 0.2317\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 2.0463 - acc: 0.2369 - val_loss: 1.8817 - val_acc: 0.2813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.9537 - acc: 0.2649 - val_loss: 1.7453 - val_acc: 0.3308\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.8740 - acc: 0.2913 - val_loss: 1.6371 - val_acc: 0.3460\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.7921 - acc: 0.3177 - val_loss: 1.5252 - val_acc: 0.3503\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 1.7234 - acc: 0.3306 - val_loss: 1.4995 - val_acc: 0.4037\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 100s 2ms/step - loss: 1.6706 - acc: 0.3464 - val_loss: 1.4149 - val_acc: 0.4100\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.6176 - acc: 0.3560 - val_loss: 1.3720 - val_acc: 0.4208\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.5825 - acc: 0.3633 - val_loss: 1.3573 - val_acc: 0.4270\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 101s 2ms/step - loss: 1.5512 - acc: 0.3689 - val_loss: 1.3447 - val_acc: 0.4137\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.5246 - acc: 0.3770 - val_loss: 1.3284 - val_acc: 0.4473\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4861 - acc: 0.3842 - val_loss: 1.3025 - val_acc: 0.4897\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4673 - acc: 0.3964 - val_loss: 1.2838 - val_acc: 0.4440\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 98s 2ms/step - loss: 1.4327 - acc: 0.4040 - val_loss: 1.2364 - val_acc: 0.5045\n",
      "10000/10000 [==============================] - 4s 377us/step\n",
      "0.6807\n",
      "\n",
      " \n",
      " Starting round with 35 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 129s 2ms/step - loss: 2.3206 - acc: 0.1087 - val_loss: 2.4899 - val_acc: 0.1103\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2866 - acc: 0.1236 - val_loss: 2.4299 - val_acc: 0.1445\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2670 - acc: 0.1369 - val_loss: 2.2762 - val_acc: 0.1548\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.2126 - acc: 0.1527 - val_loss: 2.1650 - val_acc: 0.1565\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.1497 - acc: 0.1638 - val_loss: 2.1472 - val_acc: 0.1928\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0887 - acc: 0.1785 - val_loss: 2.1148 - val_acc: 0.2087\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 2.0379 - acc: 0.1933 - val_loss: 1.9941 - val_acc: 0.2178\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9753 - acc: 0.2207 - val_loss: 1.8358 - val_acc: 0.2743\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9218 - acc: 0.2387 - val_loss: 1.8030 - val_acc: 0.2912\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8802 - acc: 0.2486 - val_loss: 1.7470 - val_acc: 0.2938\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.8531 - acc: 0.2619 - val_loss: 1.7311 - val_acc: 0.2942\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8284 - acc: 0.2679 - val_loss: 1.7019 - val_acc: 0.2927\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.8134 - acc: 0.2752 - val_loss: 1.6679 - val_acc: 0.3235\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 105s 2ms/step - loss: 1.7885 - acc: 0.2861 - val_loss: 1.6755 - val_acc: 0.3318\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.7678 - acc: 0.2904 - val_loss: 1.6069 - val_acc: 0.3257\n",
      "10000/10000 [==============================] - 4s 407us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 131s 2ms/step - loss: 2.3044 - acc: 0.1234 - val_loss: 2.1907 - val_acc: 0.1985\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.1771 - acc: 0.1711 - val_loss: 1.9751 - val_acc: 0.2460\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0610 - acc: 0.1982 - val_loss: 1.9094 - val_acc: 0.2515\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0053 - acc: 0.2098 - val_loss: 1.9039 - val_acc: 0.2578\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9649 - acc: 0.2273 - val_loss: 1.8167 - val_acc: 0.2627\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.9153 - acc: 0.2446 - val_loss: 1.7334 - val_acc: 0.3058\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 1.8718 - acc: 0.2654 - val_loss: 1.6716 - val_acc: 0.3475\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.8341 - acc: 0.2759 - val_loss: 1.6270 - val_acc: 0.3480\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.8006 - acc: 0.2867 - val_loss: 1.6032 - val_acc: 0.3518\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 111s 2ms/step - loss: 1.7556 - acc: 0.3045 - val_loss: 1.5421 - val_acc: 0.3590\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 111s 2ms/step - loss: 1.7121 - acc: 0.3175 - val_loss: 1.5208 - val_acc: 0.3545\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6728 - acc: 0.3298 - val_loss: 1.4790 - val_acc: 0.3820\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6411 - acc: 0.3360 - val_loss: 1.4205 - val_acc: 0.4005\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.6008 - acc: 0.3490 - val_loss: 1.4059 - val_acc: 0.3960\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.5652 - acc: 0.3568 - val_loss: 1.3918 - val_acc: 0.4108\n",
      "10000/10000 [==============================] - 4s 435us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 136s 3ms/step - loss: 2.2477 - acc: 0.1526 - val_loss: 2.1112 - val_acc: 0.1608\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.1402 - acc: 0.1908 - val_loss: 2.0318 - val_acc: 0.2263\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.0994 - acc: 0.2024 - val_loss: 2.0039 - val_acc: 0.2495\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 2.0617 - acc: 0.2170 - val_loss: 1.9338 - val_acc: 0.2687\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 106s 2ms/step - loss: 2.0225 - acc: 0.2309 - val_loss: 1.8295 - val_acc: 0.2763\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.9737 - acc: 0.2467 - val_loss: 1.7477 - val_acc: 0.3147\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.9305 - acc: 0.2583 - val_loss: 1.7199 - val_acc: 0.3173\n",
      "Epoch 8/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.8883 - acc: 0.2686 - val_loss: 1.7210 - val_acc: 0.3217\n",
      "Epoch 9/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.8561 - acc: 0.2765 - val_loss: 1.6704 - val_acc: 0.3455\n",
      "Epoch 10/15\n",
      "54000/54000 [==============================] - 107s 2ms/step - loss: 1.8218 - acc: 0.2840 - val_loss: 1.6118 - val_acc: 0.3823\n",
      "Epoch 11/15\n",
      "54000/54000 [==============================] - 109s 2ms/step - loss: 1.7898 - acc: 0.2917 - val_loss: 1.6146 - val_acc: 0.3540\n",
      "Epoch 12/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.7658 - acc: 0.2969 - val_loss: 1.5531 - val_acc: 0.3830\n",
      "Epoch 13/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.7373 - acc: 0.3104 - val_loss: 1.5237 - val_acc: 0.3972\n",
      "Epoch 14/15\n",
      "54000/54000 [==============================] - 108s 2ms/step - loss: 1.6989 - acc: 0.3224 - val_loss: 1.4617 - val_acc: 0.4075\n",
      "Epoch 15/15\n",
      "54000/54000 [==============================] - 110s 2ms/step - loss: 1.6567 - acc: 0.3301 - val_loss: 1.4072 - val_acc: 0.3852\n",
      "10000/10000 [==============================] - 5s 451us/step\n",
      "0.5834\n",
      "\n",
      " \n",
      " Starting round with 38 layers\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 150s 3ms/step - loss: 2.4095 - acc: 0.0971 - val_loss: 2.3024 - val_acc: 0.1012\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3120 - acc: 0.1052 - val_loss: 2.3020 - val_acc: 0.1017\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3048 - acc: 0.1069 - val_loss: 2.3025 - val_acc: 0.1172\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3036 - acc: 0.1075 - val_loss: 2.3014 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3028 - acc: 0.1079 - val_loss: 2.3022 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3025 - acc: 0.1087- ETA: 1s - loss: 2\n",
      "Epoch 00006: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3025 - acc: 0.1087 - val_loss: 2.3051 - val_acc: 0.1152\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3021 - acc: 0.1103 - val_loss: 2.3017 - val_acc: 0.1152\n",
      "Epoch 8/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1110\n",
      "Epoch 00008: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3018 - acc: 0.1110 - val_loss: 2.3016 - val_acc: 0.1152\n",
      "Epoch 00008: early stopping\n",
      "10000/10000 [==============================] - 5s 474us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 154s 3ms/step - loss: 2.4123 - acc: 0.1009 - val_loss: 2.3104 - val_acc: 0.1002\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 124s 2ms/step - loss: 2.3125 - acc: 0.1048 - val_loss: 2.3040 - val_acc: 0.1158\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3049 - acc: 0.1063 - val_loss: 2.3028 - val_acc: 0.1695\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3035 - acc: 0.1068 - val_loss: 2.3019 - val_acc: 0.1152\n",
      "Epoch 5/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3029 - acc: 0.1086 - val_loss: 2.3039 - val_acc: 0.1152\n",
      "Epoch 6/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3027 - acc: 0.1091\n",
      "Epoch 00006: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3027 - acc: 0.1091 - val_loss: 2.3068 - val_acc: 0.1152\n",
      "Epoch 7/15\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.3020 - acc: 0.1107 - val_loss: 2.3013 - val_acc: 0.1152\n",
      "Epoch 8/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3017 - acc: 0.1116\n",
      "Epoch 00008: reducing learning rate to 0.0012249999563209713.\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 2.3017 - acc: 0.1116 - val_loss: 2.3020 - val_acc: 0.1145\n",
      "Epoch 00008: early stopping\n",
      "10000/10000 [==============================] - 5s 488us/step\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "54000/54000 [==============================] - 155s 3ms/step - loss: 2.4102 - acc: 0.1015 - val_loss: 2.3220 - val_acc: 0.0852\n",
      "Epoch 2/15\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 2.3117 - acc: 0.1043 - val_loss: 2.3377 - val_acc: 0.1437\n",
      "Epoch 3/15\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 2.3038 - acc: 0.1096 - val_loss: 2.3004 - val_acc: 0.1152\n",
      "Epoch 4/15\n",
      "54000/54000 [==============================] - 118s 2ms/step - loss: 2.3029 - acc: 0.1118 - val_loss: 2.3157 - val_acc: 0.1190\n",
      "Epoch 5/15\n",
      "53984/54000 [============================>.] - ETA: 0s - loss: 2.3018 - acc: 0.1097\n",
      "Epoch 00005: reducing learning rate to 0.0034999999217689036.\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 2.3018 - acc: 0.1097 - val_loss: 2.3089 - val_acc: 0.1173\n",
      "Epoch 6/15\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 2.3013 - acc: 0.1110 - val_loss: 2.3172 - val_acc: 0.1170\n",
      "Epoch 7/15\n",
      "51520/54000 [===========================>..] - ETA: 5s - loss: 2.3011 - acc: 0.1122"
     ]
    }
   ],
   "source": [
    "act = \"relu\"\n",
    "\n",
    "logs_relu = []\n",
    "record_relu = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_relu.append([n, ensembled])\n",
    "    logs_relu.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs Relu: \", logs_relu)\n",
    "print(\"Record Relu: \", record_relu)\n",
    "\n",
    "    \n",
    "plot([[x[1] for x in logs_relu]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_relu = [\n",
    "    [23, 0.9717],\n",
    "    [26, 0.9253],\n",
    "    [29, 0.8639],\n",
    "    [32, 0.6807],\n",
    "    [35, 0.5834],\n",
    "    [38, ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = e_swish_2\n",
    "\n",
    "logs_e_swish_2 = []\n",
    "record_e_swish_2 = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_e_swish_2.append([n, ensembled])\n",
    "    logs_e_swish_2.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs e_swish_2: \", logs_e_swish_2)\n",
    "print(\"Record e_swish_2: \", record_e_swish_2)\n",
    "    \n",
    "plot([[x[1] for x in logs_relu], [x[1] for x in logs_e_swish_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = swish\n",
    "\n",
    "logs_swish = []\n",
    "record_swish = []\n",
    "for n in range(23,42,3):\n",
    "    ensembler = 0\n",
    "    logger = [n]\n",
    "    print(\"\\n \\n Starting round with {0} layers\".format(n))\n",
    "    for i in range(3):\n",
    "        # Garbage collector\n",
    "        gc.collect()\n",
    "        # Set optimizer\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        # Set callbacks (learning rate reducer and early stopping)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.35, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=5, verbose = 1)\n",
    "        # Common params \n",
    "        epochs = 15\n",
    "        batch_size = 128\n",
    "        # Create and compile the model\n",
    "        model = create(act, n)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        # Train the model\n",
    "        history = model.fit(X_train,Y_train, epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                            verbose = 1 , callbacks=[learning_rate_reduction, early_stop])\n",
    "        \n",
    "        # Record accuracy of each model and save it\n",
    "        logger.append(model.evaluate(X_test, Y_test)[1])\n",
    "        # Calculate probabilities of test data and sum them toghether\n",
    "        ensembler += model.predict_proba(X_test)\n",
    "        # Clear session (GPU MEMORY)\n",
    "        K.get_session().close()\n",
    "        K.set_session(K.tf.Session())\n",
    "        del model, history, learning_rate_reduction, early_stop, opt\n",
    "     \n",
    "    # Calculate the median accuracy\n",
    "    ensembled = accuracy(ensembler, Y_test)\n",
    "    print(ensembled)\n",
    "    # Save the ensembled accuracy and the three models accuracy\n",
    "    record_swish.append([n, ensembled])\n",
    "    logs_swish.append(logger)\n",
    "    del ensembler, ensembled\n",
    "    \n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Logs swish: \", logs_swish)\n",
    "print(\"Record swish: \", record_swish)\n",
    "    \n",
    "plot([[x[1] for x in logs_relu], [x[1] for x in logs_e_swish_2], [x[1] for x in logs_swish]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"RELU: \", logs_relu)\n",
    "print(\"E-SWISH: \", logs_e_swish_2)\n",
    "print(\"SWISH: \", logs_swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
